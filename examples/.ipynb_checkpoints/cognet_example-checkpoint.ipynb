{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of how we see \n",
    "# the package work. The functions listed here\n",
    "# are probably the only ones that should be exposed, ie documented.\n",
    "# others should br prepended with a double underscore\n",
    "#  \n",
    "# The cognet directory has the following \"modules\"\n",
    "# which are seprate .py files containing clases and functions\n",
    "# The modules are cognet.py, dataFormatter.py, model.py, util.py, viz.py\n",
    "# we will write the viz.py later.\n",
    "import sys\n",
    "\n",
    "from quasinet.qnet import qdistance\n",
    "from cognet.cognet import cognet as cg\n",
    "from cognet.dataFormatter import dataFormatter\n",
    "from cognet.model import model \n",
    "#import cognet.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "yr = '2018'\n",
    "POLEFILE='GSS/data/polar_vectors.csv'\n",
    "QPATH='GSS/data/gss_'+yr+'.joblib'\n",
    "IMMUTABLE_FILE='GSS/data/immutable.csv'\n",
    "GSSDATA = 'GSS/data/gss_'+yr+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            wrkstat HRS1 HRS2 evwork        wrkslf  wrkgovt OCC10 PRESTG10  \\\n",
      "0  temp not working    e    c    NaN  someone else  private     b        c   \n",
      "1  working fulltime    c    e    NaN  someone else  private     b        d   \n",
      "\n",
      "  PRESTG105PLUS INDUS10  ...    neisafe rlooks rgroomed rweight rhlthend wtss  \\\n",
      "0             c       c  ...  very safe    NaN      NaN     NaN      NaN    e   \n",
      "1             d       c  ...  very safe    NaN      NaN     NaN      NaN    c   \n",
      "\n",
      "  wtssnr wtssall vstrat vpsu  \n",
      "0      e       e   3301    1  \n",
      "1      c       c   3301    1  \n",
      "\n",
      "[2 rows x 1034 columns]\n",
      "(892, 1034)\n"
     ]
    }
   ],
   "source": [
    "# testing dataFormatter\n",
    "data = dataFormatter(samples=GSSDATA)\n",
    "# load the sample data\n",
    "# have option for test/train split\n",
    "# make checks to ensure we will not throw errors at qnet construction \n",
    "print(data.samples[:2])\n",
    "features,samples = data.format_samples('train') # default trains and tests using half\n",
    "all_samples = False\n",
    "if all_samples: # use all samples to train, instead of half\n",
    "    features,samples = data.Qnet_formatter()\n",
    "\n",
    "# format data for Qnet training and fitting\n",
    "print(samples.shape)\n",
    "\n",
    "# set mutable and immutable vars either from list or file\n",
    "im_vars_df = pd.read_csv(IMMUTABLE_FILE, names=['vars'])\n",
    "im_vars_list = im_vars_df.vars.to_list()\n",
    "mutable_vars, immutable_vars = data.mutable_variables(immutable_list=im_vars_list)\n",
    "mutable_vars, immutable_vars = data.mutable_variables(IMMUTABLE_FILE=IMMUTABLE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing model functionality\n",
    "# can either input features and samples directly, or infer from data obj\n",
    "model_ = model()\n",
    "\n",
    "# qnet construction parameters, \n",
    "# choose to either load or fit qnet from scratch\n",
    "# and to either load from url or local repo\n",
    "test_model_buildqnet = False\n",
    "url_load = True\n",
    "if test_model_buildqnet:\n",
    "        print(\"fitting\")\n",
    "        model_.fit(data_obj=data,\n",
    "                   min_samples_split=2,\n",
    "                   alpha=0.05,\n",
    "                   max_depth=-1,\n",
    "                   max_feats=-1,\n",
    "                   early_stopping=False,\n",
    "                   verbose=0,\n",
    "                   random_state=None,\n",
    "                   njobs=8)\n",
    "        print(\"fitted\")\n",
    "        model_.export_dot(\"GSS/results/tmp_dot_modelclass.dot\",\n",
    "                        generate_trees=True)\n",
    "        model_.save(\"GSS/results/tmp_nodelclass.joblib\")\n",
    "        #model_.load(\"tmp_nodelclass.joblib\")\n",
    "else:\n",
    "    if url_load:\n",
    "        QNETFILE = 'https://zenodo.org/record/5781768/files/gss_2018.joblib'\n",
    "    else:\n",
    "        QNETFILE = 'GSS/data/gss_2018.joblib'\n",
    "    model_.load(QNETFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034\n"
     ]
    }
   ],
   "source": [
    "# testing cognet\n",
    "# set some paramaters in instantiating cognet class \n",
    "# if loading from model obj, no need to use load_data func, otherwise, load_data\n",
    "Cg = cg()\n",
    "print(len(model_.features))\n",
    "Cg.load_from_model(model_, data, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class-computed distance: 0.12258070888571534\n",
      "actual:0.12289432245387237\n"
     ]
    }
   ],
   "source": [
    "# distance calculation for individual samples    \n",
    "# we have a nsteps parameter (for sample 1 and sample2)\n",
    "# which qsamples the sample1 and sample2 if set before\n",
    "# computing distance. Note qsampling must only \n",
    "# change mutable varaibles, so need to compute base-freq\n",
    "distance = Cg.distance(samples[1],samples[3],nsteps1=5, nsteps2=5)\n",
    "print(\"class-computed distance:\", distance)\n",
    "qdistance_ = qdistance(samples[1],samples[3],Cg.qnet,Cg.qnet)\n",
    "print(\"actual:{}\".format(qdistance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 pole features not found in sample features\n"
     ]
    }
   ],
   "source": [
    "# produce stats on how many column names actually match\n",
    "stats = Cg.set_poles(POLEFILE,\"R\",\"L\",steps=120, VERBOSE=True)\n",
    "\n",
    "# compute polar distance matrix\n",
    "dmatrix = Cg.polar_separation(nsteps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dissonance: [0. 0. 0. ... 0. 0. 0.]\n",
      "reconstruction results: 66.80881646121489 0.2919753086419753 0.591950775163615\n",
      "ideology: [0.04298189391629631, 0.09135036761482512, 0.08615011059018973, 0.12098715414361363]\n",
      "Dispersion: [0.047121043506798854, 0.12700043074314818]\n",
      "distance from poles: [0.021635271857159282, 0.022334688414062873]\n"
     ]
    }
   ],
   "source": [
    "#------------------\n",
    "# the following are for single samples\n",
    "\n",
    "# dissonance\n",
    "dissonance_array = Cg.dissonance(1)\n",
    "print(\"dissonance:\", dissonance_array)\n",
    "\n",
    "#ideology\n",
    "Cg.num_qsamples = 5\n",
    "ideology_index = Cg.ideology(3,pole_1=\"R\",pole_2=\"L\")\n",
    "print(\"ideology:\", ideology_index)\n",
    "\n",
    "# disperion\n",
    "dispersion_ = Cg.dispersion(3)\n",
    "print(\"Dispersion:\", dispersion_)\n",
    "\n",
    "# compute distance from each pole\n",
    "array_distances = Cg.polarDistance(1, returndict)\n",
    "print(\"distance from poles:\", array_distances)\n",
    "\n",
    "# random mask and reconstruction\n",
    "returndict = {}\n",
    "rederr,r_prob,rand_err,s,qs,s_rand,mask_ = Cg.randomMaskReconstruction(index=1, \n",
    "                                                                       return_dict=returndict,\n",
    "                                                                       index_colname=\"feature_names\",\n",
    "                                                                       output_dir=\"GSS/results/recon_results/\",\n",
    "                                                                       file_name=\"recon_tmp.csv\",\n",
    "                                                                       save_samples=True)# sample=np.array(samples[1]))\n",
    "print(\"reconstruction results:\", rederr, r_prob, rand_err)\n",
    "#-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the following are for arrays of samples\n",
    "# multiprocessing suffices\n",
    "\n",
    "# set sammple sizeN\n",
    "Cg.set_nsamples(40)\n",
    "    \n",
    "# computing polar_indices makes sure that dissonance matrix only takes in polar cols\n",
    "Cg.compute_polar_indices()\n",
    "dissonance_array = Cg.dissonance_matrix(outfile='GSS/results/DISSONANCE_matrix.csv')\n",
    "print(\"dissonance array:\", dissonance_array[:2])\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# random mask and reconstruction\n",
    "recon_df = Cg.randomMaskReconstruction_multiple('GSS/results/randomMaskRecon_test.csv')\n",
    "print(\"reconstruction results\", recon_df[:2])\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# ideology indices\n",
    "ideology_index = Cg.compute_DLI_samples('ideology','GSS/results/ideology.csv')\n",
    "print(\"ideology indices\", ideology_index)\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# dispersion\n",
    "local_dispersion = Cg.compute_DLI_samples('dispersion', 'GSS/results/dispersion_test.csv')\n",
    "print(\"dispersion array\", local_dispersion)\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# polar distances\n",
    "polar_array = Cg.polarDistance_multiple('GSS/results/polarDistance_multiple_test.csv')\n",
    "print(\"polar distances array\",polar_array)\n",
    "print('----------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "def mp_compute(Cg, \n",
    "               processes,\n",
    "               func, \n",
    "               cols,\n",
    "               outfile, \n",
    "               args=[]):\n",
    "    \"\"\"\n",
    "    Compute desired function through multiprocessing and save result to csv.\n",
    "\n",
    "    Args:\n",
    "      processes (int): number of processes to use.\n",
    "      func (func): function to compute using multiprocessing\n",
    "      cols (list): column names of resulting csv\n",
    "      outfile (str)): filepath + filename for resulting csv\n",
    "      args (list): list containing arguments for desired function. Defaults to empty list.\n",
    "    \"\"\"\n",
    "\n",
    "    # init mp.Manager and result dict\n",
    "    manager = mp.Manager()\n",
    "    return_dict = manager.dict()\n",
    "\n",
    "    # set processes as given, unless class parameter is set\n",
    "    max_processes = processes\n",
    "    if Cg.MAX_PROCESSES != 0:\n",
    "        max_processes = Cg.MAX_PROCESSES\n",
    "        print(\"Number of Processes {} has been set using class parameter\".format(Cg.MAX_PROCESSES))\n",
    "    num_processes = 0\n",
    "    process_list = []\n",
    "\n",
    "    # init mp.Processes for each individual sample\n",
    "    # run once collected processes hit max\n",
    "    for i in range(len(Cg.samples)):\n",
    "        params = tuple([i, return_dict] + args)\n",
    "        num_processes += 1\n",
    "        p = mp.Process(target=func,\n",
    "                    args=params)\n",
    "        process_list.append(p)\n",
    "        if num_processes == max_processes:\n",
    "            [x.start() for x in process_list]\n",
    "            [x.join() for x in process_list]\n",
    "            process_list = []\n",
    "            num_processes = 0\n",
    "\n",
    "    # compute remaining processes\n",
    "    if num_processes != 0:\n",
    "        [x.start() for x in process_list]\n",
    "        [x.join() for x in process_list]\n",
    "        process_list = []\n",
    "        num_processes = 0\n",
    "\n",
    "    # format and save resulting dict\n",
    "    result = pd.DataFrame(return_dict.values(), columns=cols, index=return_dict.keys()).sort_index()\n",
    "    #result=[x for x in return_dict.values()]\n",
    "    result.to_csv(outfile, index=None)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distfunc_multiples(Cg,\n",
    "                       outfile,\n",
    "                       processes=4):\n",
    "    \"\"\"compute distance matrix for all samples in the dataset\n",
    "\n",
    "    Args:\n",
    "      outfile (str): desired output filename and path\n",
    "\n",
    "    Returns:\n",
    "      return_dict: dictionary containing multiprocessing results\n",
    "    \"\"\"\n",
    "    if all(x is not None for x in [Cg.samples, Cg.features]):\n",
    "        cols = [i for i in range(len(Cg.samples))]\n",
    "        result = mp_compute(Cg,\n",
    "                             processes,\n",
    "                                    Cg.distfunc_line,\n",
    "                                    cols,\n",
    "                                    outfile)\n",
    "        # format and save resulting dict, and tranpose symmetrical distance matrix\n",
    "        # result1 = pd.DataFrame(result_,columns=cols).sort_index()\n",
    "        # result = pd.DataFrame(result,columns=cols, index=cols).sort_index(ascending=False)\n",
    "        result = result.to_numpy()\n",
    "        result = pd.DataFrame(np.maximum(result, result.transpose()))\n",
    "        result.to_csv(outfile, index=None)\n",
    "    else:\n",
    "        raise ValueError(\"load data first!\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.000000  0.091232  0.134658  0.113836  0.086175  0.120154  0.079885   \n",
      "1  0.091232  0.000000  0.108381  0.114186  0.079264  0.085646  0.086029   \n",
      "2  0.134658  0.108381  0.000000  0.129788  0.120588  0.076976  0.130525   \n",
      "3  0.113836  0.114186  0.129788  0.000000  0.109474  0.105337  0.127201   \n",
      "4  0.086175  0.079264  0.120588  0.109474  0.000000  0.101664  0.093314   \n",
      "5  0.120154  0.085646  0.076976  0.105337  0.101664  0.000000  0.115825   \n",
      "6  0.079885  0.086029  0.130525  0.127201  0.093314  0.115825  0.000000   \n",
      "7  0.079909  0.102618  0.145231  0.117701  0.075187  0.126603  0.094005   \n",
      "8  0.126323  0.098386  0.111161  0.093618  0.124169  0.094520  0.115584   \n",
      "9  0.096016  0.092799  0.139336  0.130243  0.066111  0.124740  0.110569   \n",
      "\n",
      "          7         8         9  \n",
      "0  0.079909  0.126323  0.096016  \n",
      "1  0.102618  0.098386  0.092799  \n",
      "2  0.145231  0.111161  0.139336  \n",
      "3  0.117701  0.093618  0.130243  \n",
      "4  0.075187  0.124169  0.066111  \n",
      "5  0.126603  0.094520  0.124740  \n",
      "6  0.094005  0.115584  0.110569  \n",
      "7  0.000000  0.134604  0.067742  \n",
      "8  0.134604  0.000000  0.136706  \n",
      "9  0.067742  0.136706  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# compute qdistance matrix for small set of samples\n",
    "# set nsamples first to set the number of samples to be included in matrix\n",
    "Cg.set_nsamples(10)\n",
    "distance_matrix=distfunc_multiples(Cg, \"GSS/results/distfunc_multiples_testing.csv\")\n",
    "print(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute qdistance matrix for small set of samples\n",
    "# set nsamples first to set the number of samples to be included in matrix\n",
    "distance_matrix=Cg.distfunc_multiples(\"GSS/results/distfunc_multiples_testing.csv\")\n",
    "print(\"local distance matrix:\", distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write files to compute qdistance matrix for large set of samples\n",
    "# execute generated shell script to run mpi parallelization on midway\n",
    "Cg.dmat_filewriter(\"GSS/GSS_cognet.py\", \"GSS/data/gss_2018.joblib\",\n",
    "                   MPI_SETUP_FILE=\"GSS/GSS_mpi_setup.sh\",\n",
    "                   MPI_RUN_FILE=\"GSS/GSS_mpi_run.sh\",\n",
    "                   MPI_LAUNCHER_FILE=\"GSS/GSS_mpi_launcher.sh\",\n",
    "                   YEARS='2018',NODES=4,T=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## embedding\n",
    "## embed generated Qdist Matrix\n",
    "Cg.year = '2018'\n",
    "Cg.embed('examples_results/distfunc_multiples_testing.csv', 'embed', 'examples_results/',EMBED_BINARY='cognet/cognet/bin/__embed__.so')\n",
    "#pd.read_csv('examples_results/embed_E_2018.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
