{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of how we see \n",
    "# the package work. The functions listed here\n",
    "# are probably the only ones that should be exposed, ie documented.\n",
    "# others should br prepended with a double underscore\n",
    "#  \n",
    "# The cognet directory has the following \"modules\"\n",
    "# which are seprate .py files containing clases and functions\n",
    "# The modules are cognet.py, dataFormatter.py, model.py, util.py, viz.py\n",
    "# we will write the viz.py later.\n",
    "import sys\n",
    "\n",
    "from quasinet.qnet import qdistance\n",
    "from cognet.cognet import cognet as cg\n",
    "from cognet.dataFormatter import dataFormatter\n",
    "from cognet.model import model \n",
    "#import cognet.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "yr = '2018'\n",
    "POLEFILE='GSS/data/polar_vectors.csv'\n",
    "QPATH='GSS/data/gss_'+yr+'.joblib'\n",
    "IMMUTABLE_FILE='GSS/data/immutable.csv'\n",
    "GSSDATA = 'GSS/data/gss_'+yr+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from quasinet.qnet import Qnet, qdistance, load_qnet, qdistance_matrix\n",
    "from quasinet.qsampling import qsample, targeted_qsample\n",
    "#from mpi4py.futures import MPIPoolExecutor\n",
    "import sys\n",
    "import subprocess\n",
    "from scipy.stats import entropy\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from cognet.util import embed_to_pca\n",
    "import pkgutil\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pqdm.threads import pqdm  \n",
    "\n",
    "class cognet:\n",
    "    \"\"\"Aggregate related Qnet functions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Init\n",
    "        \"\"\"\n",
    "        self.year = None\n",
    "        self.n_jobs = 28\n",
    "        self.qnet = None\n",
    "        self.steps = 120\n",
    "        self.num_qsamples = None\n",
    "        self.all_samples = None\n",
    "        self.samples = None\n",
    "        self.samples_as_strings = None\n",
    "        self.features = []\n",
    "        self.cols = []\n",
    "        self.immutable_vars = []\n",
    "        self.mutable_vars = []\n",
    "        self.poles = None\n",
    "        self.polar_features = None\n",
    "        self.polar_indices = None\n",
    "        self.poles_dict = {}\n",
    "        self.d0 = None\n",
    "        self.s_null = None\n",
    "        self.D_null = None\n",
    "        self.mask_prob = 0.5\n",
    "        self.variation_weight = None\n",
    "        self.polar_matrix = None\n",
    "        self.nsamples = None\n",
    "        self.restricted = False\n",
    "        self.MAX_PROCESSES = 0\n",
    "    \n",
    "    def load_from_model(self,\n",
    "                        model,\n",
    "                        data_obj,\n",
    "                        key,\n",
    "                        im_vars=None,\n",
    "                        m_vars=None,\n",
    "                        verbose=False):\n",
    "        \"\"\"load parameters from model object\n",
    "\n",
    "        Args:\n",
    "          model (Class): model obj for loading parameters\n",
    "          data_obj (class): instance of dataformatter class\n",
    "          key (str): 'all', 'train', or 'test', corresponding to sample type\n",
    "          im_vars (list[str], optional): Not implemented yet. Defaults to None.\n",
    "          m_vars (list[str], optional): Not implemented yet. Defaults to None.\n",
    "          verbos (bool, optional): Whether or not to print out model state. Defaults to False. \n",
    "        \"\"\"\n",
    "        if model is not None:\n",
    "            # inherit atrributes from model object\n",
    "            self.qnet = model.myQnet\n",
    "            featurenames, samples = data_obj.format_samples(key)\n",
    "            samples = pd.DataFrame(samples)\n",
    "            self.cols = np.array(featurenames)\n",
    "            self.features = pd.DataFrame(columns=np.array(featurenames))\n",
    "            \n",
    "            # inherit mutable and immutable variables from model obj\n",
    "            if any(x is not None for x in [model.immutable_vars, model.mutable_vars]):\n",
    "                if model.immutable_vars is not None:\n",
    "                    self.immutable_vars = model.immutable_vars\n",
    "                    self.mutable_vars = [x for x in self.features if x not in self.immutable_vars]\n",
    "                elif model.mutable_vars is not None:\n",
    "                    self.mutable_vars = model.mutable_vars\n",
    "                    self.immutable_vars = [x for x in self.features if x not in self.mutable_vars]\n",
    "            else:\n",
    "                self.mutable_vars = self.features\n",
    "            \n",
    "            # inherit and set class attributes.\n",
    "            self.samples = pd.DataFrame(samples).replace(\"nan\",\"\").fillna(\"\")\n",
    "            self.samples.columns = np.array(featurenames)\n",
    "            self.all_samples = self.samples\n",
    "            self.samples_as_strings = self.samples.fillna('').values.astype(str)[:]\n",
    "            self.s_null=['']*len(self.samples_as_strings[0])\n",
    "            self.D_null=self.qnet.predict_distributions(self.s_null)\n",
    "            variation_weight = []\n",
    "            for d in self.D_null:\n",
    "                v=[]\n",
    "                for val in d.values():\n",
    "                    v=np.append(v,val)\n",
    "                variation_weight.append(entropy(v,base=len(v)))\n",
    "            variation_weight = np.nan_to_num(variation_weight) # remove nans\n",
    "            self.variation_weight = variation_weight\n",
    "        if verbose:\n",
    "            print(\"total features: \" + str(len(self.features.columns)) + \"\\n\" \n",
    "                  + \"mutable features: \" + str(len(self.mutable_vars.columns)) + \"\\n\"\n",
    "                  + \"immutable features: \" + str(len(self.immutable_vars)))\n",
    "    \n",
    "    def load_from_dataformatter(self, \n",
    "                                data_obj,\n",
    "                                key):\n",
    "        \"\"\"read in either train or test data, specified by key, from data obj,\n",
    "        and inherit other attributes.\n",
    "\n",
    "        Args:\n",
    "          data_obj (class): instance of dataformatter class\n",
    "          key (str): 'all', 'train', or 'test', corresponding to sample type\n",
    "          \n",
    "        Returns:\n",
    "          featurenames, samples: formatted arrays\n",
    "        \"\"\"\n",
    "        # inherit attributes from dataformatter object\n",
    "        featurenames, samples = data_obj.format_samples(key)\n",
    "        if any(x is not None for x in [self.features, self.samples]):\n",
    "            print(\"replacing original features/samples with dataformatter data\")\n",
    "        self.cols = featurenames\n",
    "        self.features = pd.DataFrame(columns=self.cols)\n",
    "        self.samples = pd.DataFrame(samples,columns=self.features)\n",
    "        self.all_samples = self.samples\n",
    "        self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "        self.s_null=['']*len(self.samples_as_strings[0])\n",
    "        return featurenames, samples\n",
    "\n",
    "    def load_data(self,\n",
    "                  year,\n",
    "                  features_by_year,\n",
    "                  samples,\n",
    "                  Qnet):\n",
    "        '''load cols, features, samples, and qnet.\n",
    "\n",
    "        Args:\n",
    "          year (str): to identify cols/features.\n",
    "          features_by_year (str): file containing all features by year of the dataset.\n",
    "          samples (str): file of samples for that year.\n",
    "          Qnet (str): Qnet file location.\n",
    "        '''\n",
    "        # set attributes from given files and data\n",
    "        self.qnet = load_qnet(qnet)\n",
    "        self.year = year\n",
    "        self.cols = np.array((pd.read_csv(features_by_year,\n",
    "                            keep_default_na=True, \n",
    "                            index_col=0).set_index(\n",
    "                                'year')).loc[int(year)].apply(\n",
    "                                    eval).values[0])\n",
    "        self.features = pd.DataFrame(columns=self.cols)\n",
    "        self.mutable_vars = [x for x in self.cols]\n",
    "        #[self.cols].fillna('').values.astype(str)[:]\n",
    "\n",
    "        # read in samples and initialize related attributes\n",
    "        self.samples=pd.read_csv(samples)\n",
    "        self.samples = pd.concat([self.samples,self.features], axis=0)\n",
    "        self.all_samples = self.samples\n",
    "        self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "        self.s_null=['']*len(self.samples_as_strings[0])\n",
    "        self.D_null=self.qnet.predict_distributions(self.s_null)\n",
    "        variation_weight = []\n",
    "        for d in self.D_null:\n",
    "            v=[]\n",
    "            for val in d.values():\n",
    "                v=np.append(v,val)\n",
    "            variation_weight.append(entropy(v,base=len(v)))\n",
    "        self.variation_weight = variation_weight\n",
    "\n",
    "    def set_immutable_vars(self,\n",
    "                        IMMUTABLE_FILE):\n",
    "        '''set vars to immutable and mutable, \n",
    "        can prob combine this with the load_data func: only set the immutable vars if necessary\n",
    "\n",
    "        Args:\n",
    "          IMMUTABLE_FILE (str): file containing the immutable features/vars\n",
    "        '''\n",
    "        # set mutable and immutable variable attributes \n",
    "        if self.cols is None:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "        self.immutable_vars = pd.read_csv(IMMUTABLE_FILE,index_col=0).transpose()\n",
    "        self.mutable_vars = None\n",
    "        self.mutable_vars = [x for x in self.cols\n",
    "                            if x.upper() not in self.immutable_vars.columns]\n",
    "    \n",
    "    def model_state(self):\n",
    "        '''returns state of model\n",
    "        '''\n",
    "        immutable_var_len = 0\n",
    "        if self.immutable_vars:\n",
    "            immutabe_var_len =  len(self.immutable_vars.columns)\n",
    "        print(\"total features: \" + str(len(self.features.columns)) + \"\\n\" \n",
    "                + \"mutable features: \" + str(len(self.mutable_vars.columns)) + \"\\n\"\n",
    "                + \"immutable features: \" + str(immutable_var_len))\n",
    "        \n",
    "        print(\"total samples: \" + str(len(self.samples)))\n",
    "        \n",
    "        \n",
    "    def set_nsamples(self,\n",
    "                    num_samples,\n",
    "                    random=False,\n",
    "                    verbose=True):\n",
    "        '''select a subset of the samples\n",
    "\n",
    "        Args:\n",
    "          num_samples (int): Set num of samples to subset, default to None, resets to all samples\n",
    "          random (bool): take random sample if true, ordered sample if false. Defaults to False\n",
    "          verbose (bool): whether or not to print out model state regarding samples. Defaults to True.\n",
    "        '''\n",
    "        # each time function is called, reset samples to use_all_samples\n",
    "        # this allows us to call nsamples numerous times \n",
    "        self.samples = self.all_samples\n",
    "        if self.samples is not None:\n",
    "            # if a greater number of sample is selected than available, raise error\n",
    "            if all(x is not None for x in [num_samples, self.samples]):\n",
    "                if num_samples > len(self.samples.index):\n",
    "                    string = 'The number of selected samples ({}) ' + \\\n",
    "                        'is greater than the number of samples ({})!'\n",
    "                    string = string.format(num_samples, len(self.samples.index))\n",
    "                    raise ValueError(string)\n",
    "\n",
    "                # if the same number of samples is selected as available, print warning\n",
    "                if num_samples == len(self.samples.index):\n",
    "                    string = 'The number of selected samples ({}) ' + \\\n",
    "                        'is equal to the number of samples ({})!'\n",
    "                    string = string.format(num_samples, len(self.samples.index))\n",
    "                    print(string)\n",
    "                    \n",
    "                # if random is true, return random sample, otherwise return an ordered slice\n",
    "                if random:\n",
    "                    self.samples = self.samples.sample(num_samples)\n",
    "                else:\n",
    "                    self.samples = self.samples.iloc[:num_samples]\n",
    "                self.nsamples = num_samples\n",
    "                self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "                if verbose:\n",
    "                    if random:\n",
    "                        print(\"The number of random samples have been set to \" + str(num_samples))\n",
    "                    else:\n",
    "                        print(\"The number of samples have been set to \" + str(num_samples))\n",
    "                \n",
    "            elif self.samples is None:\n",
    "                raise ValueError(\"load_data first!\")\n",
    "            \n",
    "\n",
    "    def __variation_weight(self,\n",
    "                        index):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        d_=self.D_null[index]\n",
    "        v=[]\n",
    "        for val in d_.values():\n",
    "            v=np.append(v,val)\n",
    "        return entropy(v,base=len(v))\n",
    "    \n",
    "    def getBaseFrequency(self, \n",
    "                        sample):\n",
    "        '''get frequency of the variables\n",
    "        helper func for qsampling\n",
    "\n",
    "        Args:\n",
    "          sample (list[str]): vector of sample, must have the same num of features as the qnet\n",
    "        '''\n",
    "        # if variable is not mutable, set its base frequency to zero \n",
    "        MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()\n",
    "             \n",
    "        for m in self.mutable_vars:\n",
    "            MUTABLE[m]=1.0\n",
    "        mutable_x=MUTABLE.values[0]\n",
    "        base_frequency=mutable_x/mutable_x.sum()\n",
    "        \n",
    "        # otherwise, set base frequency weighted by variation weight\n",
    "        for i in range(len(base_frequency)):\n",
    "            if base_frequency[i]>0.0:\n",
    "                base_frequency[i]= self.variation_weight[i]*base_frequency[i]\n",
    "\n",
    "        return base_frequency/base_frequency.sum()\n",
    "    \n",
    "    def qsampling(self,\n",
    "                sample,\n",
    "                steps,\n",
    "                immutable=False):\n",
    "        '''perturb the sample based on the qnet distributions and number of steps\n",
    "\n",
    "        Args:\n",
    "          sample (1d array-like): sample vector, must have the same num of features as the qnet\n",
    "          steps (int): number of steps to qsample\n",
    "          immutable (bool): are there variables that are immutable?\n",
    "        '''\n",
    "        # immutable, check that mutable variables have been initialized\n",
    "        if immutable == True:\n",
    "            if all(x is not None for x in [self.mutable_vars, sample]):\n",
    "                return qsample(sample,self.qnet,steps,self.getBaseFrequency(self.samples))\n",
    "            elif self.mutable_vars is None:\n",
    "                raise ValueError(\"set mutable and immutable variables first!\")\n",
    "        else:\n",
    "            return qsample(sample,self.qnet,steps)\n",
    "\n",
    "    def random_sample(self,\n",
    "                      type=\"prob\",\n",
    "                      df=None,\n",
    "                      n=1,\n",
    "                      steps=200,\n",
    "                      n_jobs=3):\n",
    "        '''compute a random sample from the underlying distributions of the dataset, by column.\n",
    "        \n",
    "        \n",
    "        Args:\n",
    "          type (str): How to randomly draw samples. Can take on \"null\", \"uniform\", or \"prob\". Deafults to \"prob\".\n",
    "          df (pandas.DataFrame): Desired data to take random sample of. Defaults to None, in which case qnet samples are used.\n",
    "          n (int): number of random samples to take. Defaults to 1.\n",
    "          steps (int): number of steps to qsample. Defaults to 1000\n",
    "          \n",
    "        Returns:\n",
    "          return_df (pd.DataFrame): Drawn random sample.\n",
    "        '''\n",
    "        # check if a new dataset was given\n",
    "        if df is None:\n",
    "            samples_ = self.samples\n",
    "        else:\n",
    "            samples_ = df\n",
    "\n",
    "        return_df = pd.DataFrame()\n",
    "        # take random sample from each of the columns based on their probability distribution\n",
    "        if type == \"prob\":\n",
    "            for col in samples_.columns:\n",
    "                return_df[col] = samples_[col].sample(n=n, replace=True).values\n",
    "                \n",
    "        # random sampling using Qnet qsampling\n",
    "        elif type == \"null\":\n",
    "            null_array = np.zeros((len(samples_.columns),), dtype=str)\n",
    "            args = [[null_array, steps] for i in range(n)]\n",
    "            qsamples = pqdm(args, self.qsampling, n_jobs=n_jobs, argument_type='args') \n",
    "            \n",
    "            # for i in range(n):\n",
    "            #     qsamples.append(self.qsampling(null_array, steps))\n",
    "            return_df = pd.DataFrame(qsamples, columns=samples_.columns)\n",
    "            \n",
    "        # random sampling using uniform distribution of values by Columns\n",
    "        elif type == \"uniform\":\n",
    "            for col in samples_.columns:\n",
    "                # get unqiue values for each column and draw n values randomly\n",
    "                values = samples_[col].unique().astype(str)\n",
    "                return_df[col]=np.random.choice(values, size=n, replace=True)\n",
    "        else:\n",
    "            raise ValueError(\"Type is not supported!\")\n",
    "        return return_df\n",
    "    \n",
    "    def set_poles(self,\n",
    "                  POLEFILE,\n",
    "                  pole_1,\n",
    "                  pole_2,\n",
    "                  steps=0,\n",
    "                  mutable=False,\n",
    "                  VERBOSE=False,\n",
    "                  restrict=False,\n",
    "                  nsamples = None,\n",
    "                  random=False):\n",
    "        '''set the poles and samples such that the samples contain features in poles\n",
    "\n",
    "        Args:\n",
    "          steps (int): number of steps to qsample\n",
    "          POLEFILE (str): file containing poles samples and features\n",
    "          pole_1 (str): column name for first pole\n",
    "          pole_2 (str): column name for second pole\n",
    "          mutable (bool): Whether or not to set poles as the only mutable_vars\n",
    "          VERBOSE (bool): boolean flag prints number of pole features not found in sample features if True\n",
    "          restrict (bool): boolean flag restricts the sample features to polar features if True. Defaults to False.\n",
    "          random (bool): boolean flag takes random sample of all_samples\n",
    "        '''\n",
    "        invalid_count = 0\n",
    "        if all(x is not None for x in [self.samples, self.qnet]):\n",
    "            # read and set poles\n",
    "            poles = pd.read_csv(POLEFILE, index_col=0)\n",
    "            self.poles=poles.transpose()\n",
    "            self.polar_features = pd.concat([self.features, self.poles], axis=0).fillna('')\n",
    "            poles_dict = {}\n",
    "            for column in poles:\n",
    "                p_ = self.polar_features.loc[column][self.cols].fillna('').values.astype(str)[:]\n",
    "                # qsample poles to qnet\n",
    "                poles_dict[column] = self.qsampling(p_,steps)\n",
    "            self.poles_dict = poles_dict\n",
    "            self.pL = self.poles_dict[pole_1]\n",
    "            self.pR = self.poles_dict[pole_2]\n",
    "            self.d0 = qdistance(self.pL, self.pR, self.qnet, self.qnet)\n",
    "            \n",
    "            # restrict sample columns to polar columns\n",
    "            if restrict:\n",
    "                cols = [x for x in self.poles.columns if x in self.samples.columns]\n",
    "                self.samples=self.samples[cols]\n",
    "                self.restricted = True\n",
    "                self.samples = pd.concat([self.features,self.samples], axis=0).replace(\"nan\",\"\").fillna('')\n",
    "                self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "                \n",
    "            # if restrict==False, unrestrict it and set original\n",
    "            else:\n",
    "                self.restricted = False\n",
    "                self.samples = self.all_samples\n",
    "                if self.nsamples is not None:\n",
    "                    self.set_nsamples(nsamples, random)\n",
    "            \n",
    "            # identify pole features that were excluded due to sample features restriction\n",
    "            if VERBOSE:\n",
    "                for x in self.poles.columns:\n",
    "                    if x not in self.samples.columns:\n",
    "                        invalid_count += 1\n",
    "                        #self.samples[x]=''\n",
    "            \n",
    "            if mutable:\n",
    "                self.mutable_vars=[x for x in self.cols if x in self.poles.columns]\n",
    "        elif self.samples is None:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "\n",
    "        if VERBOSE:\n",
    "            print(\"{} pole features not found in sample features\".format(invalid_count))\n",
    "    \n",
    "    def polarDistance(self,\n",
    "                i,\n",
    "                return_dict=None):\n",
    "        \"\"\"return the distances from a single sample to the poles\n",
    "\n",
    "        Args:\n",
    "            i (int): index of sample to take\n",
    "            return_dict (dict): dictionary containing multiprocessing results\n",
    "\n",
    "        Returns:\n",
    "            distances: float, distance from sample to each pole\n",
    "        \"\"\"\n",
    "        p = self.samples_as_strings[i]\n",
    "        distances = []\n",
    "        # calculate from each pole to the sample, and append to array\n",
    "        for index, row in self.polar_features[self.cols].iterrows():\n",
    "            row = row.fillna('').values.astype(str)[:]\n",
    "            distances.append(qsampled_distance(p, np.array(row), self.qnet, self.qnet, 10, 10))\n",
    "        if return_dict is not None:\n",
    "            return_dict[i] = distances\n",
    "        return distances\n",
    "   \n",
    "    def polarDistance_multiple(self,\n",
    "                               outfile,\n",
    "                               processes=6):\n",
    "        \"\"\"return the distance from all samples to the poles\n",
    "\n",
    "        Args:\n",
    "          outfile (str): desired output filename and path\n",
    "          \n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing polar distance results\n",
    "        \"\"\"\n",
    "        if all(x is not None for x in [self.samples, self.cols,\n",
    "                                    self.polar_features]):\n",
    "            # get the column names\n",
    "            pole_names = []\n",
    "            for index, row in self.polar_features[self.cols].iterrows():\n",
    "                pole_names.append(index)\n",
    "            result = mp_compute(processes,\n",
    "                                        self.polarDistance,\n",
    "                                        pole_names,\n",
    "                                        outfile)\n",
    "        else:\n",
    "            raise ValueError(\"load data first!\")\n",
    "        return result\n",
    "    \n",
    "    def polar_separation(self,\n",
    "                        nsteps=0):\n",
    "        \"\"\"calculates the distance between poles as a qdistance matrix\n",
    "\n",
    "        Args:\n",
    "          nsteps (int, optional): [description]. Defaults to 0.\n",
    "          \n",
    "        Returns:\n",
    "          self.polar_matrix: dictionary containing multiprocessing results\n",
    "        \"\"\"\n",
    "        # vectorize and qsample poles\n",
    "        polar_arraydata = self.polar_features[self.cols].values.astype(str)[:]\n",
    "        samples_ = []\n",
    "        for vector in polar_arraydata:\n",
    "            bp = self.getBaseFrequency(vector)\n",
    "            sample = qsample(vector, self.qnet, nsteps, baseline_prob=bp)\n",
    "            samples_.append(sample)\n",
    "        samples_ = np.array(samples_)\n",
    "        # calculate distance matrix for poles\n",
    "        self.polar_matrix = qdistance_matrix(samples_, samples_, self.qnet, self.qnet)\n",
    "        return self.polar_matrix\n",
    "        \n",
    "    def embed(self,\n",
    "            infile,\n",
    "            name_pref,\n",
    "            out_dir,\n",
    "            pca_model=False,\n",
    "            EMBED_BINARY=None):\n",
    "        '''\n",
    "        embed data\n",
    "\n",
    "        Args:\n",
    "          infile (str): input file to be embedded\n",
    "          name_pref (str): preferred name for output file\n",
    "          out_dir (str): output dir for results\n",
    "          pca_model (bool): whether or not to generate PCA model\n",
    "          EMBED_BINARY (os.path.abspath): path to embed binary\n",
    "        '''\n",
    "        # if all(x is not None for x in [self.year]):\n",
    "            # init file names \n",
    "        yr = ''\n",
    "        if self.year is not None:\n",
    "            yr = self.year\n",
    "        PREF = name_pref\n",
    "        FILE = infile\n",
    "        DATAFILE = out_dir + 'data_' +yr\n",
    "        EFILE = out_dir + PREF + '_E_' +yr\n",
    "        DFILE = out_dir + PREF + '_D_' +yr\n",
    "        \n",
    "        # set embed binary directory\n",
    "        if EMBED_BINARY is None:\n",
    "            EMBED = pkgutil.get_data(\"cognet.bin\", \"__embed__.so\") \n",
    "        else:\n",
    "            EMBED = EMBED_BINARY\n",
    "        \n",
    "        # embed data files\n",
    "        pd.read_csv(FILE, header=None).to_csv(DATAFILE,sep=' ',header=None,index=None)\n",
    "        STR=EMBED+' -f '+DATAFILE+' -E '+EFILE+' -D '+DFILE\n",
    "        subprocess.call(STR,shell=True)\n",
    "        if pca_model:\n",
    "            embed_to_pca(EFILE, EFILE+'_PCA')\n",
    "        # elif self.year is None:\n",
    "        #    raise ValueError(\"load_data first!\")\n",
    "    \n",
    "    def __calc_d0(self,\n",
    "                pole_1,\n",
    "                pole_2):\n",
    "        \"\"\"calculate distance between two poles\n",
    "\n",
    "        Args:\n",
    "          pole_1 (list[str]): a polar vector, must have same number of features as qnet\n",
    "          pole_2 (list[str]): a polar vector, must have same number of features as qnet\n",
    "        \"\"\"\n",
    "        self.pL = self.poles_dict[pole_1]\n",
    "        self.pR = self.poles_dict[pole_2]\n",
    "        self.d0 = qdistance(self.pL, self.pR, self.qnet, self.qnet)\n",
    "        \n",
    "    def ideology(self,\n",
    "                i,\n",
    "                return_dict=None,\n",
    "                pole_1=None,\n",
    "                pole_2=None):\n",
    "        \"\"\"return ideology index (left-leaning or right-leaning) for a singular sample\n",
    "\n",
    "        Args:\n",
    "          i (int): index of sample\n",
    "          pole_1 (int): index of Pole One to calc as base distance. Defaults to 0.\n",
    "          pole_2 (int): index of Pole Two to calc as base distance. Defaults to 1.\n",
    "          return_dict (dict, optional): dict containing results\n",
    "          \n",
    "        Returns:\n",
    "          [ideology_index, dR, dL, self.d0]: which way the sample leans,\n",
    "                                             distance from the right pole,\n",
    "                                             distance from the left pole,\n",
    "                                             and distance between poles, respectively\n",
    "        \"\"\"\n",
    "        # calculate base distance between two poles\n",
    "        if pole_1 is not None or pole_2 is not None:\n",
    "            self.__calc_d0(pole_1, pole_2)\n",
    "        \n",
    "        # calculate distances between sample and the two poles\n",
    "        p = self.samples_as_strings[i]\n",
    "        dR = qdistance(self.pR, p, self.qnet, self.qnet)\n",
    "        dL = qdistance(self.pL, p, self.qnet, self.qnet)\n",
    "        \n",
    "        ideology_index = (dR-dL)/self.d0\n",
    "        if return_dict is not None:\n",
    "            return_dict[i] = [ideology_index, dR, dL, self.d0]\n",
    "        return [ideology_index, dR, dL, self.d0]\n",
    "\n",
    "    def dispersion(self,\n",
    "                   i,\n",
    "                   return_dict=None):\n",
    "        \"\"\"qsamples a sample n times and takes distance matrix \n",
    "        to determine max and std of distances between qsamples\n",
    "\n",
    "        Args:\n",
    "          i (int): index of sample\n",
    "          return_dict (dict): dictionary containing multiprocessing results\n",
    "\n",
    "        Returns:\n",
    "          list[float]: std and max of the distances btwn qsamples\n",
    "        \"\"\"\n",
    "        # qsample sample num_qsample times\n",
    "        p = self.samples_as_strings[i]\n",
    "        Qset = [qsample(p, self.qnet, self.steps) for j in np.arange(self.num_qsamples)]\n",
    "        Qset = np.array(Qset)\n",
    "\n",
    "        # calculate qdistance matrix for qsampled samples\n",
    "        matrix = (qdistance_matrix(Qset, Qset, self.qnet, self.qnet))\n",
    "        Q = matrix.max()\n",
    "        Qsd = matrix.std()\n",
    "        \n",
    "        if return_dict is not None:\n",
    "            return_dict[i] = [Qsd, Q]\n",
    "        return [Qsd, Q]\n",
    "    \n",
    "    def compute_DLI_samples(self,\n",
    "                        type,\n",
    "                        outfile,\n",
    "                        num_qsamples=40,\n",
    "                        steps=120,\n",
    "                        n_jobs=28,\n",
    "                        pole_1=0,\n",
    "                        pole_2=1,\n",
    "                        processes=6):\n",
    "        \"\"\"compute and save ideology index or dispersion for all samples\n",
    "\n",
    "        Args:\n",
    "          num_qsamples (int): number of qsamples to compute\n",
    "          outfile (str): output file for results\n",
    "          type (str): whether to calc dispersion or ideology\n",
    "          steps (int): number of steps to qsample\n",
    "          n_jobs (int, optional): sets the number of jobs for parallelization. Defaults to 28.\n",
    "          pole_1 (int, optional): index of Pole One to calc as base distance. Defaults to 0.\n",
    "          pole_2 (int, optional): index of Pole Two to calc as base distance. Defaults to 1.\n",
    "\n",
    "        Raises:\n",
    "          ValueError: set poles if poles are not set\n",
    "          ValueError: load data if samples or features are not present\n",
    "            \n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing multiprocessing results\n",
    "        \"\"\"\n",
    "        if all(x is not None for x in [self.samples, self.features,\n",
    "                                    self.pL, self.pR]):\n",
    "            # init vars\n",
    "            self.num_qsamples = num_qsamples\n",
    "            self.steps = steps\n",
    "            if pole_1 != 0 or pole_2 != 1:\n",
    "                self.__calc_d0(pole_1, pole_2)\n",
    "            \n",
    "            if type == 'ideology':\n",
    "                func_ = self.ideology\n",
    "                cols=['ideology', 'dR', 'dL', 'd0']\n",
    "            elif type == 'dispersion':\n",
    "                func_ = self.dispersion\n",
    "                cols=['Qsd', 'Qmax']\n",
    "            else:\n",
    "                raise ValueError(\"Type must be either dispersion or ideology!\")\n",
    "            \n",
    "            result = mp_compute(processes,\n",
    "                                     func_,\n",
    "                                     cols,\n",
    "                                     outfile)\n",
    "        elif self.pL is None or self.pR is None:\n",
    "            raise ValueError(\"set_poles first!\")\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "        return result\n",
    "\n",
    "    def compute_polar_indices(self,\n",
    "                              num_samples=None,\n",
    "                              polar_comp=False,\n",
    "                              POLEFILE=None,\n",
    "                              steps=5):\n",
    "        '''set up polar indices for dissonance func\n",
    "\n",
    "        Args:\n",
    "          num_samples (int): subset of samples to take\n",
    "          polar_comp (bool): whether or not to set poles\n",
    "          POLEFILE (None): file containing pole samples and features\n",
    "          steps (int): number of steps to qsample\n",
    "        '''\n",
    "        if all(x is not None for x in [self.samples, self.features, self.poles]):\n",
    "            if num_samples is not None:\n",
    "                self.set_nsamples(num_samples)\n",
    "\n",
    "            if polar_comp:\n",
    "                self.set_poles(self.qnet, steps, POLEFILE)\n",
    "            \n",
    "            # calculate polar indices\n",
    "            polar_features = pd.concat([self.features, self.poles], axis=0)\n",
    "            self.polar_indices=np.where(polar_features[self.cols].fillna('XXXX').values[0]!='XXXX')[0]\n",
    "        \n",
    "        elif self.poles is None:\n",
    "            raise ValueError(\"set_poles first!\")\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "\n",
    "    def dissonance(self,\n",
    "                    sample_index=0,\n",
    "                    return_dict=None,\n",
    "                    MISSING_VAL=0.0,\n",
    "                    sample=None):\n",
    "        '''compute dissonance for a single sample, helper function for all_dissonance\n",
    "        \n",
    "        Args:\n",
    "          sample_index (int): index of the sample to compute dissonance. Defaults to 0.\n",
    "          return_dict (dict): dictionary containing multiprocessing results\n",
    "          MISSING_VAL (float): default dissonance value\n",
    "          sample (1D array): sample to compute dissonance of, instead of using sample index. Defaults to None.\n",
    "          \n",
    "        Returns: \n",
    "          diss[self.polar_indices]: ndarray containing dissonance for sample\n",
    "        '''\n",
    "        if all(x is not None for x in [self.samples, self.features]):\n",
    "            if sample is None:\n",
    "                s = self.samples_as_strings[sample_index]\n",
    "            else:\n",
    "                s = sample\n",
    "            if self.polar_indices is None:\n",
    "                self.polar_indices = range(len(s))\n",
    "\n",
    "            # init vars and calculate dissonance for sample\n",
    "            Ds=self.qnet.predict_distributions(s)\n",
    "            diss=np.ones(len(Ds))*MISSING_VAL\n",
    "            for i in self.polar_indices:\n",
    "                if s[i] != '':\n",
    "                    if s[i] in Ds[i].keys():\n",
    "                        diss[i]=1-Ds[i][s[i]]/np.max(\n",
    "                            list(Ds[i].values())) \n",
    "                    else:\n",
    "                        diss[i]=1.0\n",
    "            if return_dict is not None:\n",
    "                return_dict[sample_index] = diss[self.polar_indices]\n",
    "            return diss[self.polar_indices]\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "    \n",
    "    def dissonance_matrix(self,\n",
    "                        outfile='/example_results/DISSONANCE_matrix.csv',\n",
    "                        processes=6):\n",
    "        '''get the dissonance for all samples\n",
    "\n",
    "        Args:\n",
    "          output_file (str): directory and/or file for output\n",
    "          processes (int): max number of processes. Defaults to 6.\n",
    "\n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing dissonances for each sample\n",
    "        '''\n",
    "        # set columns\n",
    "        if self.polar_indices is not None:\n",
    "            polar_features = pd.concat([self.features, self.poles], axis=0)\n",
    "            cols = polar_features[self.cols].dropna(axis=1).columns\n",
    "        else:\n",
    "            cols = self.cols\n",
    "        \n",
    "        result = mp_compute(processes,\n",
    "                                    self.dissonance,\n",
    "                                    cols,\n",
    "                                    outfile)\n",
    "        return result\n",
    "    \n",
    "    def __choose_one(self,\n",
    "                X):\n",
    "        '''returns a random element of X\n",
    "\n",
    "        Args:\n",
    "          X (1D array-like): vector from which random element is to be chosen\n",
    "        \n",
    "        Returns:\n",
    "          X: random element of sample\n",
    "          None: if X has len 0\n",
    "        '''\n",
    "        X=list(X)\n",
    "        if len(X)>0:\n",
    "            return X[np.random.randint(len(X))]\n",
    "        return None\n",
    "\n",
    "    def getMaskedSample(self,\n",
    "                        s,\n",
    "                        mask_prob=0.5,\n",
    "                        allow_all_mutable=False):\n",
    "        '''inputs a sample and randomly mask elements of the sample\n",
    "\n",
    "        Args:\n",
    "          s (list[str]): vector of sample, must have the same num of features as the qnet.\n",
    "          mask_prob (float): float btwn 0 and 1, prob to mask element of sample. Defaults to 0.5\n",
    "          allow_all_mutable (bool): whether or not all variables are mutable. Defaults to False.\n",
    "          \n",
    "        Returns:\n",
    "          s1,\n",
    "          base_frequency,\n",
    "          MASKrand,\n",
    "          np.where(base_frequency)[0],\n",
    "          np.mean(rnd_match_prob),\n",
    "          np.mean(max_match_prob),\n",
    "          random_sample\n",
    "        '''\n",
    "        if self.samples is not None:\n",
    "            # init random mutable variable masking\n",
    "            s0=s.copy()\n",
    "            s0=np.array(s0)   \n",
    "            # double check, because code seems to imply that masking happens in order,\n",
    "            # i.e. limited to the first 100 features, if there are only 100 mutable features\n",
    "            MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()\n",
    "            WITHVAL=[x for x in self.cols[np.where(s0)[0]] if x in self.mutable_vars ]\n",
    "            MASKrand=[x for x in WITHVAL if random.random() < mask_prob ]\n",
    "            for m in MASKrand:\n",
    "                MUTABLE[m]=1.0\n",
    "            \n",
    "            mutable_x=MUTABLE.values[0]\n",
    "            base_frequency=mutable_x/mutable_x.sum()\n",
    "\n",
    "            # if np.isnan(base_frequency).any():\n",
    "            #     return np.nan,np.nan,np.nan\n",
    "            #     return self.getMaskedSample(s)\n",
    "\n",
    "            # mask sample according to masking (base_frequency)\n",
    "            s1=s.copy()\n",
    "            for i in range(len(base_frequency)):\n",
    "                if base_frequency[i]>0.0001:\n",
    "                    s1[i]=''\n",
    "                \n",
    "            # create a random sample to test reconstruction effectiveness\n",
    "            random_sample=np.copy(s)\n",
    "            rnd_match_prob=[]        \n",
    "            max_match_prob=[]        \n",
    "            D=self.qnet.predict_distributions(s)\n",
    "            for i in MASKrand:\n",
    "                random_sample[np.where(\n",
    "                    self.cols==i)[0][0]]=self.__choose_one(\n",
    "                        self.D_null[np.where(self.cols==i)[0][0]].keys())\n",
    "                    \n",
    "                rnd_match_prob=np.append(rnd_match_prob,1/len(\n",
    "                    self.D_null[np.where(self.cols==i)[0][0]].keys()))\n",
    "                \n",
    "                max_match_prob=np.append(\n",
    "                    max_match_prob,np.max(\n",
    "                        list(D[np.where(\n",
    "                            self.cols==i)[0][0]].values())))\n",
    "            \n",
    "            # calculate base_frequency if all variables are mutable\n",
    "            if allow_all_mutable:\n",
    "                WITHVAL=[x for x in self.cols[np.where(s0)[0]]]\n",
    "                MASKrand=[x for x in WITHVAL if random.random() < mask_prob ]\n",
    "                for m in MASKrand:\n",
    "                    MUTABLE[m]=1.0\n",
    "                mutable_x=MUTABLE.values[0]\n",
    "                base_frequency=mutable_x/mutable_x.sum()\n",
    "                s1=s.copy()\n",
    "                for i in range(len(base_frequency)):\n",
    "                    if base_frequency[i]>0.0001:\n",
    "                        s1[i]=''\n",
    "\n",
    "            return s1,base_frequency,MASKrand,np.where(\n",
    "                base_frequency)[0],np.mean(rnd_match_prob),np.mean(max_match_prob),random_sample\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "\n",
    "    def randomMaskReconstruction(self,\n",
    "                                index=None,\n",
    "                                sample=None,\n",
    "                                index_colname=\"feature_names\",\n",
    "                                output_dir=\"recon_results/\",\n",
    "                                file_name=\"recon_tmp.csv\",\n",
    "                                mask_prob=0.5,\n",
    "                                allow_all_mutable=False,\n",
    "                                save_samples=False,\n",
    "                                save_output=True,\n",
    "                                return_dict=None):\n",
    "        \"\"\"reconstruct the masked sample by qsampling and comparing to original\n",
    "        set self.mask_prob and self.steps if needed\n",
    "\n",
    "        Args:\n",
    "          index (int): index of sample to take.\n",
    "          return_dict (dict): dictionary containing multiprocessing results. Defaults to None.\n",
    "          sample (list[str], optional): sample vector, must have the same num of features as the qnet. Defaults to None.\n",
    "          index_colname (str): column name for index. Defaults to \"feature_names\"\n",
    "          output_dir (str): directory name for output files. Defaults to \"recon_results/\".\n",
    "          file_name (str): base file name for output files Defaults to \"recon_tmp.csv\".\n",
    "          mask_prob (float): float btwn 0 and 1, prob to mask element of sample. Defaults to 0.5\n",
    "          allow_all_mutable (bool): whether or not all variables are mutable. Defaults to False.\n",
    "          save_samples (bool): whether to include sample vectors in the savefile. Defaults to False.\n",
    "          save_output (bool): whether or not to save output df to file. Defaults to True.\n",
    "\n",
    "        Raises:\n",
    "          ValueError: Neither sample or index were given\n",
    "          ValueError: Both sample and index were given\n",
    "          \n",
    "        Returns:\n",
    "          return_values:(1 - (dqestim/dactual))*100,\n",
    "                            rmatch_u,\n",
    "                            rmatch,\n",
    "                            s,\n",
    "                            qs,\n",
    "                            random_sample,\n",
    "                            mask_\n",
    "        \"\"\"\n",
    "        if all(x is None for x in [sample, index]):\n",
    "            raise ValueError(\"Must input either sample or index!\")\n",
    "        elif all(x is not None for x in [sample, index]):\n",
    "            raise ValueError(\"Must input either sample or index not both!\")\n",
    "        elif sample is not None:\n",
    "            s=sample#np.array(pd.DataFrame(sample).fillna('').values.astype(str)[:])\n",
    "        elif index is not None:\n",
    "            s=self.samples_as_strings[index]\n",
    "        \n",
    "        # calculate masked sample and get variables\n",
    "        s1,bp,mask_,maskindex,rmatch_u,rmatch,random_sample=self.getMaskedSample(s, \n",
    "                                                                        mask_prob=mask_prob,\n",
    "                                                                        allow_all_mutable=allow_all_mutable)\n",
    "        # if base_frequency is nan, set return_dict to nans\n",
    "        if np.isnan(bp).any():\n",
    "            return_dict[index] = np.nan,np.nan,np.nan\n",
    "            return np.nan,np.nan,np.nan\n",
    "        \n",
    "        # make directories\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "\n",
    "        # qsample sample and calculate distances between original vs qsampled and masked\n",
    "        qs=qsample(s1,self.qnet,self.steps,bp)\n",
    "        dqestim=qdistance(s,qs,self.qnet,self.qnet)\n",
    "        dmask=qdistance(s,s1,self.qnet,self.qnet)\n",
    "        \n",
    "        # format and save sample, qsample statistics and values\n",
    "        cmpf=pd.DataFrame([s,qs,random_sample],\n",
    "                          columns=self.cols,\n",
    "                          index=['sample','qsampled','random_sample'])[mask_].transpose()\n",
    "        cmpf.index.name= index_colname\n",
    "        if save_output:\n",
    "            file_name = file_name.replace(\"tmp\", str(index))\n",
    "            cmpf.to_csv(output_dir+file_name)\n",
    "            \n",
    "        if save_samples:\n",
    "            return_values = (1 - (dqestim/dmask))*100,rmatch_u,rmatch,mask_,s,qs,random_sample\n",
    "        else:\n",
    "            return_values = (1 - (dqestim/dmask))*100,rmatch_u,rmatch,mask_\n",
    "        \n",
    "        if return_dict is not None:\n",
    "            return_dict[index] = return_values\n",
    "            return return_dict[index]\n",
    "        return return_values\n",
    "\n",
    "    def randomMaskReconstruction_multiple(self,\n",
    "                                          outfile,\n",
    "                                          steps=200,\n",
    "                                          processes=6,\n",
    "                                          index_colname=\"feature_names\",\n",
    "                                          output_dir=\"recon_results/\",\n",
    "                                          file_name=\"recon_tmp.csv\",\n",
    "                                          mask_prob=0.5,\n",
    "                                          allow_all_mutable=False,\n",
    "                                          save_samples=False,\n",
    "                                          save_output=True):\n",
    "        '''runs and saves the results of the predicted masked sample\n",
    "\n",
    "        Args:\n",
    "          output_file (str): directory and/or file for output.\n",
    "          processes (int): max number of processes. Defaults to 6.\n",
    "          index_colname=\"feature_names\",\n",
    "          output_dir=\"recon_results/\",\n",
    "          file_name=\"recon_tmp.csv\",\n",
    "          mask_prob (float): float btwn 0 and 1, prob to mask element of sample. Defaults to 0.5\n",
    "          allow_all_mutable (bool): whether or not all variables are mutable. Defaults to False.\n",
    "          save_samples (boolean): whether or not to save the generated qsamples, random samples, etc. Defaults to False.\n",
    "          save_output (bool): whether or not to save output df to file. Defaults to True.\n",
    "          \n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing masking and reconstruction results.\n",
    "        '''\n",
    "        # set columns for mp_compute\n",
    "        if save_samples:\n",
    "            cols = ['rederr','r_prob','rand_err','mask_','sample','qsampled','random_sample']\n",
    "        else:\n",
    "            cols = ['rederr','r_prob','rand_err','mask_']\n",
    "        \n",
    "        # update class steps\n",
    "        self.steps = steps\n",
    "        \n",
    "        # set args\n",
    "        args=[None, index_colname, output_dir,\n",
    "              file_name, mask_prob, allow_all_mutable, \n",
    "              save_samples, save_output]\n",
    "\n",
    "        result = mp_compute(processes,\n",
    "                                    self.randomMaskReconstruction,\n",
    "                                    cols,\n",
    "                                    outfile,\n",
    "                                    args=args)\n",
    "        return result\n",
    "    \n",
    "    def dmat_filewriter(self,\n",
    "                        QNETPATH,\n",
    "                        mpi_path=\"mpi_tmp/\",\n",
    "                        pyfile=\"cognet_qdistmatrix.py\",\n",
    "                        MPI_SETUP_FILE=\"mpi_setup.sh\",\n",
    "                        MPI_RUN_FILE=\"mpi_run.sh\",\n",
    "                        MPI_LAUNCHER_FILE=\"../launcher.sh\",\n",
    "                        YEARS='2016',\n",
    "                        NODES=4,\n",
    "                        T=12,\n",
    "                        num_samples=None,\n",
    "                        OUTFILE='tmp_distmatrix.csv',\n",
    "                        tmp_samplesfile=\"tmp_samples_as_strings.csv\"):\n",
    "        \"\"\"generate files to compute qdistance matrix using mpi parallelization\n",
    "\n",
    "        Args:\n",
    "          QNETPATH (str): Qnet filepath\n",
    "          pyfile (str, optional): Name of generated python file. Defaults to \"cognet_qdistmatrix.py\".\n",
    "          MPI_SETUP_FILE (str, optional): Name of mpi setup script. Defaults to \"mpi_setup.sh\".\n",
    "          MPI_RUN_FILE (str, optional): Name of mpi run script. Defaults to \"mpi_run.sh\".\n",
    "          MPI_LAUNCHER_FILE (str, optional): Launcher script filepath. Defaults to \"launcher.sh\".\n",
    "          YEARS (str, optional): If looping by year, not currently implemented. Defaults to '2016'.\n",
    "          NODES (int, optional): Number of nodes to use. Defaults to 4.\n",
    "          T (int, optional): Number of hours to reserve nodes for. Defaults to 12.\n",
    "          num_samples ([type], optional): How many samples to take. Defaults to None.\n",
    "          OUTFILE (str, optional): CSV File to write computed qdist matrix. Defaults to 'tmp_distmatrix.csv'.\n",
    "          tmp_samplesfile (str, optional): CSV File to write samples as strings. Defaults to \"tmp_samples_as_strings.csv\".\n",
    "\n",
    "        Raises:\n",
    "            ValueError: load data if qnet, features, or samples are not present]\n",
    "        \"\"\"\n",
    "        if all(x is not None for x in [self.samples,self.features,\n",
    "                                       self.qnet, self.cols]):\n",
    "            if num_samples is not None:\n",
    "                self.set_nsamples(num_samples)\n",
    "            \n",
    "            # init and make tmp dir \n",
    "            tmp_path = mpi_path\n",
    "            if not os.path.exists(tmp_path):\n",
    "                os.makedirs(tmp_path)\n",
    "            \n",
    "            pd.DataFrame(self.samples_as_strings).to_csv(tmp_path+tmp_samplesfile, header=None, index=None)\n",
    "            \n",
    "            w = self.samples.index.size\n",
    "            \n",
    "            # writing python file\n",
    "            with open(tmp_path+pyfile, 'w+') as f:\n",
    "                f.writelines([\"from mpi4py.futures import MPIPoolExecutor\\n\",\n",
    "                              \"import numpy as np\\n\",\n",
    "                              \"import pandas as pd\\n\",\n",
    "                              \"from quasinet.qnet import Qnet, qdistance, load_qnet, qdistance_matrix\\n\",\n",
    "                              \"from quasinet.qsampling import qsample, targeted_qsample\\n\\n\",\n",
    "                              \"qnet=load_qnet(\\'{}\\')\\n\".format(QNETPATH)])\n",
    "\n",
    "                f.writelines([\"w = {}\\n\".format(w),\n",
    "                              \"h = w\\n\",\n",
    "                              \"p_all = pd.read_csv(\\\"{}\\\", header=None).values.astype(str)[:]\\n\\n\".format(tmp_samplesfile)])\n",
    "\n",
    "                f.writelines([\"def distfunc(x,y):\\n\",\n",
    "                              \"\\td=qdistance(x,y,qnet,qnet)\\n\",\n",
    "                              \"\\treturn d\\n\\n\"])\n",
    "\n",
    "                f.writelines([\"def dfunc_line(k):\\n\",\n",
    "                              \"\\tline = np.zeros(w)\\n\",\n",
    "                              \"\\ty = p_all[k]\\n\",\n",
    "                              \"\\tfor j in range(w):\\n\",\n",
    "                              \"\\t\\tif j > k:\\n\",\n",
    "                              \"\\t\\t\\tx = p_all[j]\\n\",\n",
    "                              \"\\t\\t\\tline[j] = distfunc(x, y)\\n\",\n",
    "                              \"\\treturn line\\n\\n\"])\n",
    "\n",
    "                f.writelines([\"if __name__ == '__main__':\\n\",\n",
    "                              \"\\twith MPIPoolExecutor() as executor:\\n\",\n",
    "                              \"\\t\\tresult = executor.map(dfunc_line, range(h))\\n\",\n",
    "                              \"\\tresult = pd.DataFrame(result)\\n\",\n",
    "\t                          \"\\tresult = result.to_numpy()\\n\",\n",
    "                              \"\\tresult = pd.DataFrame(np.maximum(result, result.transpose()))\\n\"\n",
    "                              \"\\tresult.to_csv(\\'{}\\',index=None,header=None)\".format(OUTFILE)])\n",
    "            \n",
    "            # writing MPI setup file\n",
    "            with open(tmp_path+MPI_SETUP_FILE, 'w+') as ms:\n",
    "                ms.writelines([\"#!/bin/bash\\n\",\n",
    "                               \"YEAR=$1\\n\\n\",\n",
    "                               \"if [ $# -gt 1 ] ; then\\n\",\n",
    "                               \"\\tNODES=$2\\n\",\n",
    "                               \"else\\n\",\n",
    "                               \"\\tNODES=3\\n\",\n",
    "                               \"fi\\n\",\n",
    "                               \"if [ $# -gt 2 ] ; then\\n\",\n",
    "                               \"\\tNUM=$3\\n\",\n",
    "                               \"else\\n\",\n",
    "                               \"\\tNUM='all'\\n\",\n",
    "                               \"fi\\n\",\n",
    "                               \"if [ $# -gt 3 ] ; then\\n\",\n",
    "                               \"\\tPROG=$4\\n\",\n",
    "                               \"else\\n\",\n",
    "                               \"\\tPROG=$(tty)\\n\",\n",
    "                               \"fi\\n\\n\",\n",
    "                               \"NUMPROC=`expr 28 \\* $NODES`\\n\",\n",
    "                               \"echo \\\"module load midway2\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module unload python\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module unload openmpi\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module load python/anaconda-2020.02\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module load mpi4py\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"date; mpiexec -n \\\"$NUMPROC\\\" python3 -m mpi4py.futures {}; date\\\"  >> $PROG\\n\".format(pyfile),\n",
    "                                ])\n",
    "\n",
    "            # writing MPI run file\n",
    "            with open(tmp_path+MPI_RUN_FILE, 'w+') as mr:\n",
    "                mr.writelines([\"#!/bin/bash\\n\",\n",
    "                               \"YEARS=\\'{}\\'\\n\".format(YEARS),\n",
    "                               \"# nodes requested\\n\",\n",
    "                               \"NODES={}\\n\".format(NODES),\n",
    "                               \"# time requested\\n\",\n",
    "                               \"T={}\\n\".format(T),\n",
    "                               \"NUM=\\'all\\'\\n\",\n",
    "                               \"LAUNCH=./\\'{}\\'\\n\\n\".format(MPI_LAUNCHER_FILE),\n",
    "                               \"for yr in `echo $YEARS`\\n\",\n",
    "                               \"do\\n\",\n",
    "                               \"\\techo $yr\\n\",\n",
    "                               \"\\t./{} $yr $NODES $NUM tmp_\\\"$yr\\\"\\n\".format(MPI_SETUP_FILE),\n",
    "                               \"\\t$LAUNCH -P tmp_\\\"$yr\\\" -F -T $T -N \\\"$NODES\\\" -C 28 -p broadwl -J MPI_TMP_\\\"$yr\\\" -M 56\\n\",\n",
    "                               \"done\\n\",\n",
    "                               \"rm tmp_\\\"$yr\\\"*\\n\"])\n",
    "            os.system(\"cp {} {}\".format(MPI_LAUNCHER_FILE,tmp_path+'mpi_launcher.sh'))\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"load data first!\")\n",
    "\n",
    "def mp_compute(samples,\n",
    "               max_processes,\n",
    "               func, \n",
    "               cols,\n",
    "               outfile, \n",
    "               args=[]):\n",
    "    \"\"\"\n",
    "    Compute desired function through multiprocessing and save result to csv.\n",
    "\n",
    "    Args:\n",
    "        samples (2d array): 2 dimensional numpy array\n",
    "        processes (int): number of processes to use.\n",
    "        func (func): function to compute using multiprocessing\n",
    "        cols (list): column names of resulting csv\n",
    "        outfile (str)): filepath + filename for resulting csv\n",
    "        args (list): list containing arguments for desired function. Defaults to empty list.\n",
    "    \"\"\"\n",
    "\n",
    "    # init mp.Manager and result dict\n",
    "    manager = mp.Manager()\n",
    "    return_dict = manager.dict()\n",
    "\n",
    "    num_processes = 0\n",
    "    process_list = []\n",
    "    \n",
    "    # init mp.Processes for each individual sample\n",
    "    # run once collected processes hit max\n",
    "    for i in range(len(samples)):\n",
    "        params = tuple([i] + args + [return_dict])\n",
    "        num_processes += 1\n",
    "        p = mp.Process(target=func,\n",
    "                    args=params)\n",
    "        process_list.append(p)\n",
    "        if num_processes == max_processes:\n",
    "            [x.start() for x in process_list]\n",
    "            [x.join() for x in process_list]\n",
    "            process_list = []\n",
    "            num_processes = 0\n",
    "            \n",
    "    # compute remaining processes\n",
    "    if num_processes != 0:\n",
    "        [x.start() for x in process_list]\n",
    "        [x.join() for x in process_list]\n",
    "        process_list = []\n",
    "        num_processes = 0\n",
    "    \n",
    "    # format and save resulting dict\n",
    "    result = pd.DataFrame(return_dict.values(), columns=cols, index=return_dict.keys()).sort_index()\n",
    "    result.to_csv(outfile, index=None)\n",
    "    return result\n",
    "        \n",
    "def qsampled_distance(sample1,\n",
    "                      sample2,\n",
    "                      qnet1,\n",
    "                      qnet2,\n",
    "                      nsteps1=0,\n",
    "                      nsteps2=0):\n",
    "    \"\"\"qsamples each sample set num of steps, then takes qdistance\n",
    "\n",
    "    Args:\n",
    "        sample1 (list[str]): sample vector 1, must have the same num of features as the qnet\n",
    "        sample2 (list[str]): sample vector 2, must have the same num of features as the qnet\n",
    "        qnet1 (quasinet object): quasinet object 1\n",
    "        qnet2 (quasinet object): quasinet object 2\n",
    "        nsteps1 (int, optional): number of steps to qsample for sample1\n",
    "        nsteps2 (int, optional): number of steps to qsample for sample2\n",
    "\n",
    "    Returns:\n",
    "        qdistance: float, distance between two samples\n",
    "    \"\"\"\n",
    "    sample1 = qsample(sample1, qnet1, nsteps1)\n",
    "    sample2 = qsample(sample2, qnet2, nsteps2)\n",
    "    return qdistance(sample1, sample2, qnet1, qnet2)\n",
    "\n",
    "def __distfunc(sample1, sample2, qnet1, qnet2):\n",
    "    '''Compute distance between two samples\n",
    "\n",
    "    Args:\n",
    "        sample1 (list[str]): sample vector 1, must have the same num of features as the qnet\n",
    "        sample2 (list[str]): sample vector 2, must have the same num of features as the qnet\n",
    "        qnet1 (quasinet object): quasinet object 1\n",
    "        qnet2 (quasinet object): quasinet object 2\n",
    "        \n",
    "    Returns:\n",
    "        d: qdistance\n",
    "    '''\n",
    "    return qdistance(sample1, sample2, qnet1, qnet2)\n",
    "\n",
    "def distfunc_line(index, \n",
    "                  samples_as_strings,\n",
    "                  return_dict=None):\n",
    "    '''compute the distance for a single sample against all other samples\n",
    "\n",
    "    Args:\n",
    "        i (int): index\n",
    "        return_dict (dict): dictionary containing multiprocessing results\n",
    "    \n",
    "    Return:\n",
    "        line: float, numpy.ndarray\n",
    "    '''\n",
    "    sample_size = samples_as_strings.size\n",
    "    line = np.zeros(sample_size)\n",
    "    sample_string = samples_as_strings[index]\n",
    "    # calculate qdistance for one line of the diagonal matrix\n",
    "    for j in range(sample_size):\n",
    "        if j > index:\n",
    "            line[j] = __distfunc(samples_as_strings[j], sample_string)\n",
    "    \n",
    "    if return_dict is not None:\n",
    "        return_dict[index] = line\n",
    "        \n",
    "    return line\n",
    "\n",
    "def distfunc_multiples(outfile,\n",
    "                       samples,\n",
    "                       processes=6):\n",
    "    \"\"\"compute distance matrix for all samples in the dataset\n",
    "\n",
    "    Args:\n",
    "        outfile (str): desired output filename and path\n",
    "        processes (int): Number of processes to run in parallel. Defaults to 6.\n",
    "        samples (2D array): Dataset from which to calculate qdist matrix. Defaults to None.\n",
    "        \n",
    "    Returns:\n",
    "        result: pandas.DataFrame containing distance matrix\n",
    "    \"\"\"\n",
    "    samples = samples.fillna(\"\").values.astype(str)\n",
    "    samples_as_strings = samples\n",
    "    cols = [i for i in range(len(samples))]\n",
    "    result = mp_compute(processes,\n",
    "                        distfunc_line,\n",
    "                        cols,\n",
    "                        outfile,\n",
    "                        args=[samples_as_strings])\n",
    "    \n",
    "    # format and save resulting dict, and tranpose symmetrical distance matrix\n",
    "    result = result.to_numpy()\n",
    "    result = pd.DataFrame(np.maximum(result, result.transpose()))\n",
    "    result.to_csv(outfile, index=None, header=None)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            wrkstat HRS1 HRS2 evwork        wrkslf  wrkgovt OCC10 PRESTG10  \\\n",
      "0  temp not working    e    c    NaN  someone else  private     b        c   \n",
      "1  working fulltime    c    e    NaN  someone else  private     b        d   \n",
      "\n",
      "  PRESTG105PLUS INDUS10  ...    neisafe rlooks rgroomed rweight rhlthend wtss  \\\n",
      "0             c       c  ...  very safe    NaN      NaN     NaN      NaN    e   \n",
      "1             d       c  ...  very safe    NaN      NaN     NaN      NaN    c   \n",
      "\n",
      "  wtssnr wtssall vstrat vpsu  \n",
      "0      e       e   3301    1  \n",
      "1      c       c   3301    1  \n",
      "\n",
      "[2 rows x 1034 columns]\n",
      "(1784, 1034)\n"
     ]
    }
   ],
   "source": [
    "# testing dataFormatter\n",
    "data = dataFormatter(samples=GSSDATA)\n",
    "# load the sample data\n",
    "# have option for test/train split\n",
    "# make checks to ensure we will not throw errors at qnet construction \n",
    "print(data.samples[:2])\n",
    "features,samples = data.format_samples('train') # default trains and tests using half\n",
    "all_samples = True\n",
    "if all_samples: # use all samples to train, instead of half\n",
    "    features,samples = data.Qnet_formatter()\n",
    "\n",
    "# format data for Qnet training and fitting\n",
    "print(samples.shape)\n",
    "\n",
    "# set mutable and immutable vars either from list or file\n",
    "im_vars_df = pd.read_csv(IMMUTABLE_FILE, names=['vars'])\n",
    "im_vars_list = im_vars_df.vars.to_list()\n",
    "mutable_vars, immutable_vars = data.mutable_variables(immutable_list=im_vars_list)\n",
    "mutable_vars, immutable_vars = data.mutable_variables(IMMUTABLE_FILE=IMMUTABLE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing model functionality\n",
    "# can either input features and samples directly, or infer from data obj\n",
    "model_ = model()\n",
    "\n",
    "# qnet construction parameters, \n",
    "# choose to either load or fit qnet from scratch\n",
    "# and to either load from url or local repo\n",
    "test_model_buildqnet = False\n",
    "url_load = True\n",
    "if test_model_buildqnet:\n",
    "        print(\"fitting\")\n",
    "        model_.fit(data_obj=data,\n",
    "                   min_samples_split=2,\n",
    "                   alpha=0.05,\n",
    "                   max_depth=-1,\n",
    "                   max_feats=-1,\n",
    "                   early_stopping=False,\n",
    "                   verbose=0,\n",
    "                   random_state=None,\n",
    "                   njobs=2)\n",
    "        print(\"fitted\")\n",
    "        #model_.export_dot(\"GSS/results/tmp_dot_modelclass.dot\",\n",
    "        #                generate_trees=True)\n",
    "        #model_.save(\"GSS/results/tmp_nodelclass.joblib\")\n",
    "        #model_.load(\"tmp_nodelclass.joblib\")\n",
    "else:\n",
    "    if url_load:\n",
    "        QNETFILE = 'https://zenodo.org/record/5781768/files/gss_2018.joblib'\n",
    "    else:\n",
    "        QNETFILE = 'GSS/data/gss_2018.joblib'\n",
    "    model_.load(QNETFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034\n"
     ]
    }
   ],
   "source": [
    "# testing cognet\n",
    "# set some paramaters in instantiating cognet class \n",
    "# if loading from model obj, no need to use load_data func, otherwise, load_data\n",
    "Cg = cg()\n",
    "print(len(model_.features))\n",
    "Cg.load_from_model(model_, data, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class-computed distance: 0.11418596000727718\n",
      "actual:0.11418596000727718\n"
     ]
    }
   ],
   "source": [
    "# distance calculation for individual samples    \n",
    "# we have a nsteps parameter (for sample 1 and sample2)\n",
    "# which qsamples the sample1 and sample2 if set before\n",
    "# computing distance. Note qsampling must only \n",
    "# change mutable varaibles, so need to compute base-freq\n",
    "distance = qsampled_distance(samples[1],samples[3],Cg.qnet,Cg.qnet,nsteps1=0, nsteps2=0)\n",
    "print(\"class-computed distance:\", distance)\n",
    "qdistance_ = qdistance(samples[1],samples[3],Cg.qnet,Cg.qnet)\n",
    "print(\"actual:{}\".format(qdistance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce stats on how many column names actually match\n",
    "stats = Cg.set_poles(POLEFILE,\"L\",\"R\", steps=25, VERBOSE=True, restrict=True) # steps=120\n",
    "\n",
    "# compute polar distance matrix\n",
    "dmatrix = Cg.polar_separation(nsteps=0)\n",
    "dmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cg.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance calculation for individual samples after setting poles\n",
    "print(\"distance calculations\")\n",
    "distance = Cg.distance(Cg.samples.fillna('').values.astype(str)[3],Cg.samples.iloc[5].values.astype(str),nsteps1=0, nsteps2=0)\n",
    "print(\"class-computed distance:\", distance)\n",
    "qdistance_ = qdistance(samples[3],samples[5],Cg.qnet,Cg.qnet)\n",
    "print(\"actual:{}\".format(qdistance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dissonance: [0. 0. 0. ... 0. 0. 0.]\n",
      "ideology: [0.09588734152684872, 0.04156695908794076, 0.035403060899776705, 0.06428271020985754]\n",
      "Dispersion: [0.04560526637909075, 0.12550698664640406]\n",
      "distance from poles: [0.021635271857159282, 0.022334688414062866]\n",
      "reconstruction results: 56.841097308886056 0.29393939393939394 0.5370033765577625\n"
     ]
    }
   ],
   "source": [
    "#------------------\n",
    "# the following are for single samples\n",
    "\n",
    "# dissonance\n",
    "dissonance_array = Cg.dissonance(1)\n",
    "print(\"dissonance:\", dissonance_array)\n",
    "\n",
    "#ideology\n",
    "ideology_index = Cg.ideology(4,pole_1=\"R\",pole_2=\"L\")\n",
    "print(\"ideology:\", ideology_index)\n",
    "\n",
    "# disperion\n",
    "Cg.num_qsamples = 5\n",
    "dispersion_ = Cg.dispersion(3)\n",
    "print(\"Dispersion:\", dispersion_)\n",
    "\n",
    "# compute distance from each pole\n",
    "array_distances = Cg.polarDistance(1)\n",
    "print(\"distance from poles:\", array_distances)\n",
    "\n",
    "# random mask and reconstruction\n",
    "returndict = {}\n",
    "rederr,r_prob,rand_err,s,qs,s_rand,mask_ = Cg.randomMaskReconstruction(index=1, \n",
    "                                                                       return_dict=returndict,\n",
    "                                                                       index_colname=\"feature_names\",\n",
    "                                                                       output_dir=\"GSS/results/recon_results/\",\n",
    "                                                                       file_name=\"recon_tmp.csv\",\n",
    "                                                                       save_samples=True)# sample=np.array(samples[1]))\n",
    "print(\"reconstruction results:\", rederr, r_prob, rand_err)\n",
    "#-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Processes 2 has been set using class parameter\n",
      "dissonance array:    spkcom  colcom  libcom  spkmil  colmil  libmil  libhomo  libmslm  gunlaw  \\\n",
      "0     0.0     0.0     0.0     0.0     0.0     0.0      0.0      0.0     0.0   \n",
      "1     0.0     0.0     0.0     0.0     0.0     0.0      0.0      0.0     0.0   \n",
      "\n",
      "   grass  ...  shotgun  rowngun  viruses  intmil   abpoorw  godchnge  \\\n",
      "0    0.0  ...      0.0      0.0      0.0     0.0  0.000000  0.853822   \n",
      "1    0.0  ...      0.0      0.0      0.0     0.0  0.769949  0.916401   \n",
      "\n",
      "   prayfreq  religcon  religint  comfort  \n",
      "0  0.000000  0.000000  0.827436      0.0  \n",
      "1  0.960481  0.323764  0.000000      0.0  \n",
      "\n",
      "[2 rows x 35 columns]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Number of Processes 2 has been set using class parameter\n",
      "reconstruction results       rederr    r_prob  rand_err  \\\n",
      "0  27.801338  0.310224  0.669250   \n",
      "1  34.239480  0.296225  0.672663   \n",
      "\n",
      "                                               mask_  \n",
      "0  [HRS1, PRESTG10, PRESTG105PLUS, INDUS10, marit...  \n",
      "1  [wrkstat, HRS1, HRS2, OCC10, PRESTG10, INDUS10...  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Number of Processes 2 has been set using class parameter\n",
      "ideology indices    ideology        dR        dL        d0\n",
      "0  0.049716  0.147007  0.140722  0.126419\n",
      "1  0.036782  0.143921  0.139271  0.126419\n",
      "2  0.000005  0.154495  0.154495  0.126419\n",
      "3 -0.002458  0.149592  0.149903  0.126419\n",
      "4  0.097282  0.145801  0.133502  0.126419\n",
      "5  0.015682  0.146139  0.144157  0.126419\n",
      "6  0.019338  0.147174  0.144730  0.126419\n",
      "7  0.086977  0.143228  0.132232  0.126419\n",
      "8 -0.108200  0.135837  0.149515  0.126419\n",
      "9  0.090477  0.149277  0.137839  0.126419\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Number of Processes 2 has been set using class parameter\n",
      "dispersion array         Qsd      Qmax\n",
      "0  0.005190  0.036439\n",
      "1  0.004654  0.031958\n",
      "2  0.005518  0.039033\n",
      "3  0.006230  0.039771\n",
      "4  0.005585  0.038620\n",
      "5  0.004694  0.034126\n",
      "6  0.005239  0.034750\n",
      "7  0.006416  0.044660\n",
      "8  0.004529  0.031279\n",
      "9  0.006526  0.045652\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Number of Processes 2 has been set using class parameter\n",
      "polar distances array           R         L\n",
      "0  0.133419  0.138813\n",
      "1  0.131138  0.138176\n",
      "2  0.147701  0.155682\n",
      "3  0.139177  0.142951\n",
      "4  0.125565  0.134898\n",
      "5  0.135593  0.143826\n",
      "6  0.136802  0.137866\n",
      "7  0.122264  0.130302\n",
      "8  0.134717  0.136087\n",
      "9  0.128460  0.138303\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the following are for arrays of samples\n",
    "# multiprocessing suffices\n",
    "\n",
    "# set sammple sizeN\n",
    "Cg.set_nsamples(10)\n",
    "Cg.MAX_PROCESSES = 2\n",
    "# computing polar_indices makes sure that dissonance matrix only takes in polar cols\n",
    "Cg.compute_polar_indices()\n",
    "dissonance_array = Cg.dissonance_matrix(outfile='GSS/results/DISSONANCE_matrix.csv')\n",
    "print(\"dissonance array:\", dissonance_array[:2])\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# random mask and reconstruction\n",
    "recon_df = Cg.randomMaskReconstruction_multiple('GSS/results/randomMaskRecon_test.csv')\n",
    "print(\"reconstruction results\", recon_df[:2])\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# ideology indices\n",
    "ideology_index = Cg.compute_DLI_samples('ideology','GSS/results/ideology.csv')\n",
    "print(\"ideology indices\", ideology_index)\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# dispersion\n",
    "local_dispersion = Cg.compute_DLI_samples('dispersion', 'GSS/results/dispersion_test.csv')\n",
    "print(\"dispersion array\", local_dispersion)\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# polar distances\n",
    "polar_array = Cg.polarDistance_multiple('GSS/results/polarDistance_multiple_test.csv')\n",
    "print(\"polar distances array\",polar_array)\n",
    "print('----------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Processes 2 has been set using class parameter\n",
      "ideology indices       ideology        dR        dL        d0\n",
      "0    -0.280151  0.030485  0.049533  0.067991\n",
      "1    -0.141590  0.037044  0.046671  0.067991\n",
      "2    -0.272653  0.031553  0.050091  0.067991\n",
      "3    -0.169343  0.034574  0.046088  0.067991\n",
      "4    -0.193166  0.033283  0.046417  0.067991\n",
      "...        ...       ...       ...       ...\n",
      "1779 -0.274000  0.032207  0.050837  0.067991\n",
      "1780 -0.131350  0.036454  0.045384  0.067991\n",
      "1781  0.073439  0.041729  0.036735  0.067991\n",
      "1782 -0.320890  0.030146  0.051964  0.067991\n",
      "1783 -0.327382  0.030358  0.052618  0.067991\n",
      "\n",
      "[1784 rows x 4 columns]\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Cg.MAX_PROCESSES = 2\n",
    "\n",
    "# ideology indices\n",
    "ideology_index = Cg.compute_DLI_samples('ideology','GSS/results/ideology.csv', \n",
    "                        num_qsamples=20,\n",
    "                        steps=25,\n",
    "                        n_jobs=2,\n",
    "                        pole_1=0,\n",
    "                        pole_2=1,\n",
    "                        processes=2)\n",
    "print(\"ideology indices\", ideology_index)\n",
    "print('----------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Processes 2 has been set using class parameter\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0   0.000000  0.091232  0.134658  0.113836  0.086175  0.120154  0.079885   \n",
      "1   0.091232  0.000000  0.108381  0.114186  0.079264  0.085646  0.086029   \n",
      "2   0.134658  0.108381  0.000000  0.129788  0.120588  0.076976  0.130525   \n",
      "3   0.113836  0.114186  0.129788  0.000000  0.109474  0.105337  0.127201   \n",
      "4   0.086175  0.079264  0.120588  0.109474  0.000000  0.101664  0.093314   \n",
      "5   0.120154  0.085646  0.076976  0.105337  0.101664  0.000000  0.115825   \n",
      "6   0.079885  0.086029  0.130525  0.127201  0.093314  0.115825  0.000000   \n",
      "7   0.079909  0.102618  0.145231  0.117701  0.075187  0.126603  0.094005   \n",
      "8   0.126323  0.098386  0.111161  0.093618  0.124169  0.094520  0.115584   \n",
      "9   0.096016  0.092799  0.139336  0.130243  0.066111  0.124740  0.110569   \n",
      "10  0.129384  0.100322  0.089773  0.110758  0.102230  0.081354  0.124399   \n",
      "11  0.103177  0.106363  0.138114  0.155118  0.114404  0.132110  0.116830   \n",
      "12  0.116900  0.120828  0.115195  0.074535  0.106124  0.084442  0.121339   \n",
      "13  0.082154  0.074048  0.123569  0.107592  0.093545  0.100500  0.090322   \n",
      "14  0.092560  0.060109  0.109689  0.121968  0.066548  0.092881  0.086058   \n",
      "15  0.085952  0.097353  0.132033  0.130947  0.092136  0.123267  0.058423   \n",
      "16  0.066717  0.069478  0.113838  0.118380  0.080580  0.089718  0.079967   \n",
      "17  0.139611  0.139414  0.144361  0.105204  0.130694  0.136056  0.125357   \n",
      "18  0.064737  0.085192  0.129329  0.102928  0.070809  0.108239  0.071541   \n",
      "19  0.101893  0.090379  0.140320  0.140431  0.081825  0.119732  0.092255   \n",
      "20  0.102944  0.104283  0.116842  0.068524  0.103595  0.093994  0.108896   \n",
      "21  0.120867  0.104750  0.112003  0.118870  0.111933  0.096579  0.125671   \n",
      "22  0.133677  0.123588  0.113960  0.096965  0.130422  0.101758  0.130163   \n",
      "23  0.089007  0.077593  0.117593  0.142087  0.080649  0.103872  0.105954   \n",
      "24  0.072045  0.083779  0.131697  0.098360  0.077665  0.116807  0.075180   \n",
      "25  0.088196  0.086236  0.119395  0.126051  0.057488  0.116220  0.101854   \n",
      "26  0.113825  0.097555  0.101005  0.085766  0.115226  0.078937  0.106352   \n",
      "27  0.067147  0.086743  0.132981  0.119069  0.072449  0.113700  0.081263   \n",
      "28  0.086746  0.061954  0.110758  0.113821  0.063798  0.084101  0.084846   \n",
      "29  0.105272  0.128194  0.161190  0.130405  0.103400  0.151912  0.120138   \n",
      "\n",
      "          7         8         9   ...        20        21        22        23  \\\n",
      "0   0.079909  0.126323  0.096016  ...  0.102944  0.120867  0.133677  0.089007   \n",
      "1   0.102618  0.098386  0.092799  ...  0.104283  0.104750  0.123588  0.077593   \n",
      "2   0.145231  0.111161  0.139336  ...  0.116842  0.112003  0.113960  0.117593   \n",
      "3   0.117701  0.093618  0.130243  ...  0.068524  0.118870  0.096965  0.142087   \n",
      "4   0.075187  0.124169  0.066111  ...  0.103595  0.111933  0.130422  0.080649   \n",
      "5   0.126603  0.094520  0.124740  ...  0.093994  0.096579  0.101758  0.103872   \n",
      "6   0.094005  0.115584  0.110569  ...  0.108896  0.125671  0.130163  0.105954   \n",
      "7   0.000000  0.134604  0.067742  ...  0.110998  0.095422  0.109291  0.077169   \n",
      "8   0.134604  0.000000  0.136706  ...  0.077927  0.121398  0.096142  0.125070   \n",
      "9   0.067742  0.136706  0.000000  ...  0.115035  0.095607  0.117317  0.071241   \n",
      "10  0.107144  0.108070  0.094286  ...  0.104996  0.067181  0.081077  0.081975   \n",
      "11  0.087201  0.128629  0.098476  ...  0.130706  0.105871  0.109444  0.072470   \n",
      "12  0.124429  0.090364  0.120931  ...  0.069963  0.131169  0.103511  0.131346   \n",
      "13  0.089305  0.101108  0.104995  ...  0.108127  0.103147  0.121952  0.088533   \n",
      "14  0.097884  0.105981  0.082435  ...  0.097801  0.101398  0.115678  0.066642   \n",
      "15  0.101180  0.117655  0.106191  ...  0.116711  0.132705  0.135939  0.107763   \n",
      "16  0.080470  0.103868  0.104053  ...  0.102816  0.105582  0.114185  0.073469   \n",
      "17  0.108193  0.104722  0.124050  ...  0.093733  0.106655  0.070415  0.122603   \n",
      "18  0.060256  0.115505  0.093680  ...  0.094666  0.112085  0.121483  0.090557   \n",
      "19  0.073908  0.140490  0.058963  ...  0.122568  0.091820  0.113328  0.065316   \n",
      "20  0.110998  0.077927  0.115035  ...  0.000000  0.111405  0.088514  0.120568   \n",
      "21  0.095422  0.121398  0.095607  ...  0.111405  0.000000  0.079691  0.070018   \n",
      "22  0.109291  0.096142  0.117317  ...  0.088514  0.079691  0.000000  0.101740   \n",
      "23  0.077169  0.125070  0.071241  ...  0.120568  0.070018  0.101740  0.000000   \n",
      "24  0.073815  0.123311  0.098874  ...  0.104730  0.116768  0.136493  0.100417   \n",
      "25  0.086047  0.130283  0.082704  ...  0.114491  0.116058  0.134710  0.085295   \n",
      "26  0.125696  0.072492  0.132631  ...  0.068733  0.103837  0.070437  0.108631   \n",
      "27  0.066598  0.127226  0.093507  ...  0.105184  0.120947  0.121894  0.089184   \n",
      "28  0.091494  0.105314  0.089551  ...  0.104433  0.107804  0.125270  0.073357   \n",
      "29  0.071030  0.146061  0.095919  ...  0.137792  0.109171  0.126682  0.099268   \n",
      "\n",
      "          24        25        26        27        28        29  \n",
      "0   0.072045  0.088196  0.113825  0.067147  0.086746  0.105272  \n",
      "1   0.083779  0.086236  0.097555  0.086743  0.061954  0.128194  \n",
      "2   0.131697  0.119395  0.101005  0.132981  0.110758  0.161190  \n",
      "3   0.098360  0.126051  0.085766  0.119069  0.113821  0.130405  \n",
      "4   0.077665  0.057488  0.115226  0.072449  0.063798  0.103400  \n",
      "5   0.116807  0.116220  0.078937  0.113700  0.084101  0.151912  \n",
      "6   0.075180  0.101854  0.106352  0.081263  0.084846  0.120138  \n",
      "7   0.073815  0.086047  0.125696  0.066598  0.091494  0.071030  \n",
      "8   0.123311  0.130283  0.072492  0.127226  0.105314  0.146061  \n",
      "9   0.098874  0.082704  0.132631  0.093507  0.089551  0.095919  \n",
      "10  0.115286  0.119077  0.087063  0.118957  0.099954  0.132351  \n",
      "11  0.117369  0.103886  0.128099  0.097591  0.107020  0.092428  \n",
      "12  0.111823  0.116438  0.069716  0.109213  0.111497  0.142546  \n",
      "13  0.071005  0.101781  0.101261  0.079801  0.082227  0.109818  \n",
      "14  0.090769  0.077536  0.095933  0.085978  0.062161  0.124664  \n",
      "15  0.078662  0.098529  0.117228  0.086778  0.089425  0.119632  \n",
      "16  0.072087  0.084812  0.090377  0.064313  0.062181  0.116115  \n",
      "17  0.143222  0.128013  0.100327  0.124666  0.129622  0.126377  \n",
      "18  0.053563  0.075440  0.100049  0.044324  0.071236  0.094282  \n",
      "19  0.109115  0.089731  0.128730  0.096152  0.085958  0.112379  \n",
      "20  0.104730  0.114491  0.068733  0.105184  0.104433  0.137792  \n",
      "21  0.116768  0.116058  0.103837  0.120947  0.107804  0.109171  \n",
      "22  0.136493  0.134710  0.070437  0.121894  0.125270  0.126682  \n",
      "23  0.100417  0.085295  0.108631  0.089184  0.073357  0.099268  \n",
      "24  0.000000  0.089881  0.111395  0.056354  0.083677  0.091479  \n",
      "25  0.089881  0.000000  0.123381  0.066843  0.074128  0.101020  \n",
      "26  0.111395  0.123381  0.000000  0.108134  0.099345  0.146527  \n",
      "27  0.056354  0.066843  0.108134  0.000000  0.077945  0.088487  \n",
      "28  0.083677  0.074128  0.099345  0.077945  0.000000  0.122655  \n",
      "29  0.091479  0.101020  0.146527  0.088487  0.122655  0.000000  \n",
      "\n",
      "[30 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# compute qdistance matrix for small set of samples\n",
    "# set nsamples first to set the number of samples to be included in matrix\n",
    "Cg.MAX_PROCESSES = 2\n",
    "Cg.set_nsamples(30)\n",
    "distance_matrix=Cg.distfunc_multiples(\"GSS/results/distfunc_multiples_testing.csv\")\n",
    "print(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Processes 2 has been set using class parameter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091232</td>\n",
       "      <td>0.134658</td>\n",
       "      <td>0.113836</td>\n",
       "      <td>0.086175</td>\n",
       "      <td>0.120154</td>\n",
       "      <td>0.079885</td>\n",
       "      <td>0.079909</td>\n",
       "      <td>0.126323</td>\n",
       "      <td>0.096016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.091232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108381</td>\n",
       "      <td>0.114186</td>\n",
       "      <td>0.079264</td>\n",
       "      <td>0.085646</td>\n",
       "      <td>0.086029</td>\n",
       "      <td>0.102618</td>\n",
       "      <td>0.098386</td>\n",
       "      <td>0.092799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.134658</td>\n",
       "      <td>0.108381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129788</td>\n",
       "      <td>0.120588</td>\n",
       "      <td>0.076976</td>\n",
       "      <td>0.130525</td>\n",
       "      <td>0.145231</td>\n",
       "      <td>0.111161</td>\n",
       "      <td>0.139336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.113836</td>\n",
       "      <td>0.114186</td>\n",
       "      <td>0.129788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109474</td>\n",
       "      <td>0.105337</td>\n",
       "      <td>0.127201</td>\n",
       "      <td>0.117701</td>\n",
       "      <td>0.093618</td>\n",
       "      <td>0.130243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086175</td>\n",
       "      <td>0.079264</td>\n",
       "      <td>0.120588</td>\n",
       "      <td>0.109474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101664</td>\n",
       "      <td>0.093314</td>\n",
       "      <td>0.075187</td>\n",
       "      <td>0.124169</td>\n",
       "      <td>0.066111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.120154</td>\n",
       "      <td>0.085646</td>\n",
       "      <td>0.076976</td>\n",
       "      <td>0.105337</td>\n",
       "      <td>0.101664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115825</td>\n",
       "      <td>0.126603</td>\n",
       "      <td>0.094520</td>\n",
       "      <td>0.124740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.079885</td>\n",
       "      <td>0.086029</td>\n",
       "      <td>0.130525</td>\n",
       "      <td>0.127201</td>\n",
       "      <td>0.093314</td>\n",
       "      <td>0.115825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094005</td>\n",
       "      <td>0.115584</td>\n",
       "      <td>0.110569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.079909</td>\n",
       "      <td>0.102618</td>\n",
       "      <td>0.145231</td>\n",
       "      <td>0.117701</td>\n",
       "      <td>0.075187</td>\n",
       "      <td>0.126603</td>\n",
       "      <td>0.094005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134604</td>\n",
       "      <td>0.067742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.126323</td>\n",
       "      <td>0.098386</td>\n",
       "      <td>0.111161</td>\n",
       "      <td>0.093618</td>\n",
       "      <td>0.124169</td>\n",
       "      <td>0.094520</td>\n",
       "      <td>0.115584</td>\n",
       "      <td>0.134604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.096016</td>\n",
       "      <td>0.092799</td>\n",
       "      <td>0.139336</td>\n",
       "      <td>0.130243</td>\n",
       "      <td>0.066111</td>\n",
       "      <td>0.124740</td>\n",
       "      <td>0.110569</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>0.136706</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.091232  0.134658  0.113836  0.086175  0.120154  0.079885   \n",
       "1  0.091232  0.000000  0.108381  0.114186  0.079264  0.085646  0.086029   \n",
       "2  0.134658  0.108381  0.000000  0.129788  0.120588  0.076976  0.130525   \n",
       "3  0.113836  0.114186  0.129788  0.000000  0.109474  0.105337  0.127201   \n",
       "4  0.086175  0.079264  0.120588  0.109474  0.000000  0.101664  0.093314   \n",
       "5  0.120154  0.085646  0.076976  0.105337  0.101664  0.000000  0.115825   \n",
       "6  0.079885  0.086029  0.130525  0.127201  0.093314  0.115825  0.000000   \n",
       "7  0.079909  0.102618  0.145231  0.117701  0.075187  0.126603  0.094005   \n",
       "8  0.126323  0.098386  0.111161  0.093618  0.124169  0.094520  0.115584   \n",
       "9  0.096016  0.092799  0.139336  0.130243  0.066111  0.124740  0.110569   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.079909  0.126323  0.096016  \n",
       "1  0.102618  0.098386  0.092799  \n",
       "2  0.145231  0.111161  0.139336  \n",
       "3  0.117701  0.093618  0.130243  \n",
       "4  0.075187  0.124169  0.066111  \n",
       "5  0.126603  0.094520  0.124740  \n",
       "6  0.094005  0.115584  0.110569  \n",
       "7  0.000000  0.134604  0.067742  \n",
       "8  0.134604  0.000000  0.136706  \n",
       "9  0.067742  0.136706  0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute qdistance matrix for small set of samples different from qnet samples\n",
    "samples = Cg.samples.iloc[:10]\n",
    "Cg.distfunc_multiples(\"GSS/results/distfunc_multiples_samplestesting.csv\", samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Processes 2 has been set using class parameter\n",
      "local distance matrix:           0         1         2         3         4         5         6   \\\n",
      "0   0.000000  0.091232  0.134658  0.113836  0.086175  0.120154  0.079885   \n",
      "1   0.091232  0.000000  0.108381  0.114186  0.079264  0.085646  0.086029   \n",
      "2   0.134658  0.108381  0.000000  0.129788  0.120588  0.076976  0.130525   \n",
      "3   0.113836  0.114186  0.129788  0.000000  0.109474  0.105337  0.127201   \n",
      "4   0.086175  0.079264  0.120588  0.109474  0.000000  0.101664  0.093314   \n",
      "5   0.120154  0.085646  0.076976  0.105337  0.101664  0.000000  0.115825   \n",
      "6   0.079885  0.086029  0.130525  0.127201  0.093314  0.115825  0.000000   \n",
      "7   0.079909  0.102618  0.145231  0.117701  0.075187  0.126603  0.094005   \n",
      "8   0.126323  0.098386  0.111161  0.093618  0.124169  0.094520  0.115584   \n",
      "9   0.096016  0.092799  0.139336  0.130243  0.066111  0.124740  0.110569   \n",
      "10  0.129384  0.100322  0.089773  0.110758  0.102230  0.081354  0.124399   \n",
      "11  0.103177  0.106363  0.138114  0.155118  0.114404  0.132110  0.116830   \n",
      "12  0.116900  0.120828  0.115195  0.074535  0.106124  0.084442  0.121339   \n",
      "13  0.082154  0.074048  0.123569  0.107592  0.093545  0.100500  0.090322   \n",
      "14  0.092560  0.060109  0.109689  0.121968  0.066548  0.092881  0.086058   \n",
      "15  0.085952  0.097353  0.132033  0.130947  0.092136  0.123267  0.058423   \n",
      "16  0.066717  0.069478  0.113838  0.118380  0.080580  0.089718  0.079967   \n",
      "17  0.139611  0.139414  0.144361  0.105204  0.130694  0.136056  0.125357   \n",
      "18  0.064737  0.085192  0.129329  0.102928  0.070809  0.108239  0.071541   \n",
      "19  0.101893  0.090379  0.140320  0.140431  0.081825  0.119732  0.092255   \n",
      "20  0.102944  0.104283  0.116842  0.068524  0.103595  0.093994  0.108896   \n",
      "21  0.120867  0.104750  0.112003  0.118870  0.111933  0.096579  0.125671   \n",
      "22  0.133677  0.123588  0.113960  0.096965  0.130422  0.101758  0.130163   \n",
      "23  0.089007  0.077593  0.117593  0.142087  0.080649  0.103872  0.105954   \n",
      "24  0.072045  0.083779  0.131697  0.098360  0.077665  0.116807  0.075180   \n",
      "25  0.088196  0.086236  0.119395  0.126051  0.057488  0.116220  0.101854   \n",
      "26  0.113825  0.097555  0.101005  0.085766  0.115226  0.078937  0.106352   \n",
      "27  0.067147  0.086743  0.132981  0.119069  0.072449  0.113700  0.081263   \n",
      "28  0.086746  0.061954  0.110758  0.113821  0.063798  0.084101  0.084846   \n",
      "29  0.105272  0.128194  0.161190  0.130405  0.103400  0.151912  0.120138   \n",
      "\n",
      "          7         8         9   ...        20        21        22        23  \\\n",
      "0   0.079909  0.126323  0.096016  ...  0.102944  0.120867  0.133677  0.089007   \n",
      "1   0.102618  0.098386  0.092799  ...  0.104283  0.104750  0.123588  0.077593   \n",
      "2   0.145231  0.111161  0.139336  ...  0.116842  0.112003  0.113960  0.117593   \n",
      "3   0.117701  0.093618  0.130243  ...  0.068524  0.118870  0.096965  0.142087   \n",
      "4   0.075187  0.124169  0.066111  ...  0.103595  0.111933  0.130422  0.080649   \n",
      "5   0.126603  0.094520  0.124740  ...  0.093994  0.096579  0.101758  0.103872   \n",
      "6   0.094005  0.115584  0.110569  ...  0.108896  0.125671  0.130163  0.105954   \n",
      "7   0.000000  0.134604  0.067742  ...  0.110998  0.095422  0.109291  0.077169   \n",
      "8   0.134604  0.000000  0.136706  ...  0.077927  0.121398  0.096142  0.125070   \n",
      "9   0.067742  0.136706  0.000000  ...  0.115035  0.095607  0.117317  0.071241   \n",
      "10  0.107144  0.108070  0.094286  ...  0.104996  0.067181  0.081077  0.081975   \n",
      "11  0.087201  0.128629  0.098476  ...  0.130706  0.105871  0.109444  0.072470   \n",
      "12  0.124429  0.090364  0.120931  ...  0.069963  0.131169  0.103511  0.131346   \n",
      "13  0.089305  0.101108  0.104995  ...  0.108127  0.103147  0.121952  0.088533   \n",
      "14  0.097884  0.105981  0.082435  ...  0.097801  0.101398  0.115678  0.066642   \n",
      "15  0.101180  0.117655  0.106191  ...  0.116711  0.132705  0.135939  0.107763   \n",
      "16  0.080470  0.103868  0.104053  ...  0.102816  0.105582  0.114185  0.073469   \n",
      "17  0.108193  0.104722  0.124050  ...  0.093733  0.106655  0.070415  0.122603   \n",
      "18  0.060256  0.115505  0.093680  ...  0.094666  0.112085  0.121483  0.090557   \n",
      "19  0.073908  0.140490  0.058963  ...  0.122568  0.091820  0.113328  0.065316   \n",
      "20  0.110998  0.077927  0.115035  ...  0.000000  0.111405  0.088514  0.120568   \n",
      "21  0.095422  0.121398  0.095607  ...  0.111405  0.000000  0.079691  0.070018   \n",
      "22  0.109291  0.096142  0.117317  ...  0.088514  0.079691  0.000000  0.101740   \n",
      "23  0.077169  0.125070  0.071241  ...  0.120568  0.070018  0.101740  0.000000   \n",
      "24  0.073815  0.123311  0.098874  ...  0.104730  0.116768  0.136493  0.100417   \n",
      "25  0.086047  0.130283  0.082704  ...  0.114491  0.116058  0.134710  0.085295   \n",
      "26  0.125696  0.072492  0.132631  ...  0.068733  0.103837  0.070437  0.108631   \n",
      "27  0.066598  0.127226  0.093507  ...  0.105184  0.120947  0.121894  0.089184   \n",
      "28  0.091494  0.105314  0.089551  ...  0.104433  0.107804  0.125270  0.073357   \n",
      "29  0.071030  0.146061  0.095919  ...  0.137792  0.109171  0.126682  0.099268   \n",
      "\n",
      "          24        25        26        27        28        29  \n",
      "0   0.072045  0.088196  0.113825  0.067147  0.086746  0.105272  \n",
      "1   0.083779  0.086236  0.097555  0.086743  0.061954  0.128194  \n",
      "2   0.131697  0.119395  0.101005  0.132981  0.110758  0.161190  \n",
      "3   0.098360  0.126051  0.085766  0.119069  0.113821  0.130405  \n",
      "4   0.077665  0.057488  0.115226  0.072449  0.063798  0.103400  \n",
      "5   0.116807  0.116220  0.078937  0.113700  0.084101  0.151912  \n",
      "6   0.075180  0.101854  0.106352  0.081263  0.084846  0.120138  \n",
      "7   0.073815  0.086047  0.125696  0.066598  0.091494  0.071030  \n",
      "8   0.123311  0.130283  0.072492  0.127226  0.105314  0.146061  \n",
      "9   0.098874  0.082704  0.132631  0.093507  0.089551  0.095919  \n",
      "10  0.115286  0.119077  0.087063  0.118957  0.099954  0.132351  \n",
      "11  0.117369  0.103886  0.128099  0.097591  0.107020  0.092428  \n",
      "12  0.111823  0.116438  0.069716  0.109213  0.111497  0.142546  \n",
      "13  0.071005  0.101781  0.101261  0.079801  0.082227  0.109818  \n",
      "14  0.090769  0.077536  0.095933  0.085978  0.062161  0.124664  \n",
      "15  0.078662  0.098529  0.117228  0.086778  0.089425  0.119632  \n",
      "16  0.072087  0.084812  0.090377  0.064313  0.062181  0.116115  \n",
      "17  0.143222  0.128013  0.100327  0.124666  0.129622  0.126377  \n",
      "18  0.053563  0.075440  0.100049  0.044324  0.071236  0.094282  \n",
      "19  0.109115  0.089731  0.128730  0.096152  0.085958  0.112379  \n",
      "20  0.104730  0.114491  0.068733  0.105184  0.104433  0.137792  \n",
      "21  0.116768  0.116058  0.103837  0.120947  0.107804  0.109171  \n",
      "22  0.136493  0.134710  0.070437  0.121894  0.125270  0.126682  \n",
      "23  0.100417  0.085295  0.108631  0.089184  0.073357  0.099268  \n",
      "24  0.000000  0.089881  0.111395  0.056354  0.083677  0.091479  \n",
      "25  0.089881  0.000000  0.123381  0.066843  0.074128  0.101020  \n",
      "26  0.111395  0.123381  0.000000  0.108134  0.099345  0.146527  \n",
      "27  0.056354  0.066843  0.108134  0.000000  0.077945  0.088487  \n",
      "28  0.083677  0.074128  0.099345  0.077945  0.000000  0.122655  \n",
      "29  0.091479  0.101020  0.146527  0.088487  0.122655  0.000000  \n",
      "\n",
      "[30 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# compute qdistance matrix for small set of samples\n",
    "# set nsamples first to set the number of samples to be included in matrix\n",
    "distance_matrix=Cg.distfunc_multiples(\"GSS/results/distfunc_multiples_testing.csv\")\n",
    "print(\"local distance matrix:\", distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write files to compute qdistance matrix for large set of samples\n",
    "# execute generated shell script to run mpi parallelization on midway\n",
    "Cg.dmat_filewriter(\"GSS/GSS_cognet.py\",\n",
    "                   MPI_SETUP_FILE=\"GSS_mpi_setup.sh\",\n",
    "                   MPI_RUN_FILE=\"GSS_mpi_run.sh\",\n",
    "                   MPI_LAUNCHER_FILE=\"GSS_mpi_launcher.sh\",\n",
    "                   YEARS='2018',NODES=4,T=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## embedding\n",
    "## embed generated Qdist Matrix\n",
    "Cg.year = '2018'\n",
    "Cg.embed('examples_results/distfunc_multiples_testing.csv', 'embed', 'examples_results/',EMBED_BINARY='cognet/cognet/bin/__embed__.so')\n",
    "#pd.read_csv('examples_results/embed_E_2018.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
