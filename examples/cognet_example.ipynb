{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of how we see \n",
    "# the package work. The functions listed here\n",
    "# are probably the only ones that should be exposed, ie documented.\n",
    "# others should br prepended with a double underscore\n",
    "#  \n",
    "# The cognet directory has the following \"modules\"\n",
    "# which are seprate .py files containing clases and functions\n",
    "# The modules are cognet.py, dataFormatter.py, model.py, util.py, viz.py\n",
    "# we will write the viz.py later.\n",
    "import sys\n",
    "\n",
    "from quasinet.qnet import qdistance\n",
    "from cognet.cognet import cognet as cg\n",
    "from cognet.dataFormatter import dataFormatter\n",
    "from cognet.model import model \n",
    "#import cognet.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "yr = '2018'\n",
    "POLEFILE='examples_data/polar_vectors.csv'\n",
    "QPATH='examples_data/gss_'+yr+'.joblib'\n",
    "IMMUTABLE_FILE='examples_data/immutable.csv'\n",
    "GSSDATA = 'examples_data/gss_'+yr+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cognet.util import assert_None, assert_array_dimension\n",
    "class dataFormatter:\n",
    "    \"\"\"format data to be suitable for Qnet training and testing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 samples):\n",
    "        \"\"\"init\n",
    "\n",
    "        Args:\n",
    "            samples ([str], optional): 2D array with rows as observations and columns as features.\n",
    "        \"\"\"\n",
    "        self.samples = pd.read_csv(samples)\n",
    "        self.features = {}\n",
    "        self.nan_cols = []\n",
    "        self.immutable_vars = None\n",
    "        self.mutable_vars = None\n",
    "        self.test_size = None\n",
    "        self.random_state = None\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "\n",
    "    def __train_test_split(self,\n",
    "                           test_size,\n",
    "                           train_size=None,\n",
    "                           random_state=None):\n",
    "        \"\"\"split the samples into training and testing samples\n",
    "\n",
    "        Args:\n",
    "          test_size (float): fraction of sample to take as test_size.\n",
    "          train_size (float): fraction of sample to take as train_size. Defaults to None, and 1-test_size\n",
    "          random_state (int, optional): random seed to split samples dataset . Defaults to None.\n",
    "        \"\"\"\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.train_data, self.test_data = train_test_split(self.samples,\n",
    "                                                           test_size=test_size,\n",
    "                                                           train_size=train_size,\n",
    "                                                           random_state=random_state)\n",
    "    \n",
    "    def Qnet_formatter(self,\n",
    "                         samples=None,\n",
    "                         key=None):\n",
    "        \"\"\"format data for Qnet input\n",
    "\n",
    "        Args:\n",
    "          samples ([str], optional): 2D array with rows as observations and columns as features.\n",
    "          key (str): Either 'train' or 'test' key, to determine which set of features\n",
    "        \n",
    "        Returns:\n",
    "            features and samples of either the train and test dataset\n",
    "        \"\"\"\n",
    "        # if not isinstance(samples, np.ndarray):\n",
    "        #     raise ValueError('Samples must be in numpy array form!')\n",
    "        if samples is None:\n",
    "            samples = self.samples\n",
    "        features = np.array(samples.columns.astype(str)[:])\n",
    "        samples = samples.values.astype(str)[:]\n",
    "        # remove columns that are all NaNs\n",
    "        not_all_nan_cols = ~np.all(samples == '', axis=0)\n",
    "        self.nan_cols = np.all(samples == '', axis=0)\n",
    "\n",
    "        samples = samples[:, not_all_nan_cols]\n",
    "        \n",
    "        features = features[not_all_nan_cols]\n",
    "        features = list(features)\n",
    "        if key is not None:\n",
    "            self.features[key] = features\n",
    "        return features, samples\n",
    "\n",
    "    def format_samples(self,\n",
    "                       key,\n",
    "                       test_size=.5):\n",
    "        \"\"\"formats samples and featurenames, either all, train, or test\n",
    "        \n",
    "        Args:\n",
    "          key (str): 'all', 'train', or 'test', corresponding to sample type\n",
    "\n",
    "        Returns:\n",
    "            samples and featurenames: formatted\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        if all(x is None for x in [self.train_data,\n",
    "                                       self.test_data,\n",
    "                                       self.samples]):\n",
    "            raise ValueError(\"Split samples into test and train datasets or input samples first!\")\n",
    "        if key == 'train':\n",
    "            self.__train_test_split(1-test_size)\n",
    "            samples = self.train_data\n",
    "        elif key == 'test':\n",
    "            self.__train_test_split(test_size)\n",
    "            samples = self.test_data\n",
    "        elif key == 'all':\n",
    "            samples = self.samples\n",
    "        else:\n",
    "            raise ValueError(\"Invalid key, key must be either 'all', 'test', or 'train\")\n",
    "        \n",
    "        return self.Qnet_formatter(samples, key=key)\n",
    "    \n",
    "    def __set_varcase(self,\n",
    "                      lower,\n",
    "                      key='train',\n",
    "                      vars=None):\n",
    "        \"\"\"set the features to all upper or lowercase\n",
    "\n",
    "        Args:\n",
    "          lower (bool): If true, set vars to lowercase, else to uppercase\n",
    "          key (str, optional): Whether to set train or test features. Defaults to 'train'.\n",
    "          vars ([str]): Mutable and immutable vars/features. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "          features, vars: formatted to either upper or lower case\n",
    "        \"\"\"\n",
    "        if lower:\n",
    "            features = [x.lower() for x in self.features[key]]\n",
    "            if var is not None:\n",
    "                vars = [x.lower() for x in vars]\n",
    "        else:\n",
    "            features = [x.upper() for x in self.features[key]]\n",
    "            if vars is not None:\n",
    "                vars = [x.upper() for x in vars]\n",
    "        return features, vars\n",
    "\n",
    "    def __interpretvars(self,\n",
    "                        lower,\n",
    "                        IMMUTABLE,\n",
    "                        FILE=None,\n",
    "                        LIST=None):\n",
    "        \"\"\"read in vars from file and set mutable, immutable\n",
    "\n",
    "        Args:\n",
    "          lower (bool): Whether to set variables to lowercase (True) or not (False)\n",
    "          IMMUTABLE (book): IMMUTABLE if True, MUTABLE otherwise\n",
    "          FILE (str, optional): file with vars in singular column. Defaults to None.\n",
    "          LIST ([str], optional): 1D array of vars. Defaults to None.\n",
    "          \n",
    "        Returns:\n",
    "          mutable vars, immutable vars: list\n",
    "        \"\"\"\n",
    "        if IMMUTABLE:\n",
    "            immutable_vars = np.array(LIST)\n",
    "            if FILE is not None:\n",
    "                immutable_vars = pd.read_csv(FILE,index_col=0).transpose()\n",
    "            #assert_array_dimension(immutable_vars, 1)\n",
    "            features, immutable_vars = self.__set_varcase(lower,\n",
    "                                                          vars=immutable_vars)\n",
    "            mutable_vars = [x for x in features\n",
    "                            if x not in immutable_vars]\n",
    "            immutable_vars = [x for x in immutable_vars\n",
    "                              if x in features]\n",
    "            invalid_vars = [x for x in immutable_vars\n",
    "                            if x not in features]\n",
    "        else:\n",
    "            mutable_vars = LIST\n",
    "            if FILE is not None:\n",
    "                mutable_vars = pd.read_csv(FILE,index_col=0).transpose()\n",
    "            #assert_array_dimension(mutable_vars, 1)\n",
    "            features, mutable_vars = self.__set_varcase(lower,\n",
    "                                                        vars=mutable_vars)\n",
    "            immutable_vars = [x for x in features\n",
    "                              if x not in mutable_vars]\n",
    "            mutable_vars = [x for x in mutable_vars\n",
    "                            if x in features]\n",
    "            invalid_vars = [x for x in mutable_vars\n",
    "                            if x not in features]\n",
    "        if len(invalid_vars) != 0:\n",
    "            print(\"{} vars not found\".format(len(invalid_vars)))\n",
    "            print(\"vars not found:{}\".format(invalid_vars))\n",
    "        return mutable_vars, immutable_vars\n",
    "\n",
    "    def mutable_variables(self,\n",
    "                immutable_list=None,\n",
    "                IMMUTABLE_FILE=None,\n",
    "                mutable_list=None,\n",
    "                MUTABLE_FILE=None,\n",
    "                lower=False):\n",
    "        \"\"\"set variables to be mutable or immutable\n",
    "\n",
    "        Args:\n",
    "          immutable_list (list)): 1D array of immutable variables. Defaults to None.\n",
    "          IMMUTABLE_FILE (str, optional): file with immutable vars in singular column. Defaults to None.\n",
    "          mutable_list (list, optional): 1D array of immutable variables. Defaults to None.\n",
    "          MUTABLE_FILE (str, optional): file with mutable vars in singular column. Defaults to None.\n",
    "          \n",
    "        Returns:\n",
    "          mutable_vars, immutable_vars: list\n",
    "        \"\"\"\n",
    "        list_None = assert_None([immutable_list,mutable_list], raise_error=False)\n",
    "        file_None = assert_None([IMMUTABLE_FILE,MUTABLE_FILE], raise_error=False)\n",
    "        num_None = assert_None([immutable_list,mutable_list,\n",
    "                                IMMUTABLE_FILE,MUTABLE_FILE], raise_error=False)\n",
    "        if list_None == 0 or file_None == 0:\n",
    "            raise ValueError(\"Only input either IMMUTABLE or MUTABLE vars, not both!\")\n",
    "        elif num_None == 4:\n",
    "            raise ValueError(\"Too few inputs! One argument needed\")\n",
    "        elif num_None != 3:\n",
    "            raise ValueError(\"Too many inputs! Only one argument needed\")\n",
    "        else:\n",
    "            if IMMUTABLE_FILE is not None:\n",
    "                mutable_vars, immutable_vars = self.__interpretvars(lower,\n",
    "                                                                    IMMUTABLE=True,\n",
    "                                                                    FILE=IMMUTABLE_FILE)\n",
    "            elif MUTABLE_FILE is not None:\n",
    "                mutable_vars, immutable_vars = self.__interpretvars(lower,\n",
    "                                                                    IMMUTABLE=False,\n",
    "                                                                    FILE=MUTABLE_FILE)\n",
    "            elif immutable_list is not None:\n",
    "                mutable_vars, immutable_vars = self.__interpretvars(lower,\n",
    "                                                                    IMMUTABLE=True,\n",
    "                                                                    LIST=immutable_list)\n",
    "            elif mutable_list is not None:\n",
    "                mutable_vars, immutable_vars = self.__interpretvars(lower,\n",
    "                                                                    IMMUTABLE=False,\n",
    "                                                                    LIST=mutable_list)\n",
    "        self.mutable_vars, self.immutable_vars = mutable_vars, immutable_vars\n",
    "        return mutable_vars, immutable_vars            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quasinet.qnet import Qnet, load_qnet, save_qnet\n",
    "from quasinet.qnet import export_qnet_tree, export_qnet_graph\n",
    "from cognet.util import assert_None\n",
    "\n",
    "class model:\n",
    "    \"\"\"Facilitate training and constructing Qnet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Init\n",
    "        \"\"\"\n",
    "        self.myQnet = None\n",
    "        self.features = None\n",
    "        self.immutable_vars = None\n",
    "        self.mutable_vars = None\n",
    "        self.data_obj = None\n",
    "\n",
    "    def fit(self,\n",
    "            featurenames=None,\n",
    "            samples=None,\n",
    "            data_obj=None,\n",
    "            min_samples_split=2,\n",
    "            alpha=0.05,\n",
    "            max_depth=-1,\n",
    "            max_feats=-1,\n",
    "            early_stopping=False,\n",
    "            verbose=0,\n",
    "            random_state=None,\n",
    "            n_jobs=4):\n",
    "        \"\"\"fit Quasinet Qnet model\n",
    "\n",
    "        Args:\n",
    "          featurenames ([str], optional): names of the model features. Defaults to None.\n",
    "          samples ([str], optional): 2D array with rows as observations and columns as features. Defaults to None.\n",
    "          data_obj (obj, optional): Build Qnet directly from data obj without other inputs. Defaults to None.\n",
    "          njobs (int, optional): Number of jobs used to fit Qnet. Defaults to 2.\n",
    "        \"\"\"\n",
    "        num_None = assert_None([featurenames,samples,data_obj], raise_error=False)\n",
    "        if num_None == 0:\n",
    "            raise ValueError(\"input either samples and features or data object, not both!\")\n",
    "        elif data_obj is not None:\n",
    "            featurenames, samples=data_obj.Qnet_formatter() # returns the training data\n",
    "            print(len(samples))\n",
    "            self.immutable_vars, self.mutable_vars = data_obj.immutable_vars, data_obj.mutable_vars\n",
    "        elif num_None > 1:\n",
    "            raise ValueError(\"input both samples and features or data object!\")\n",
    "        print(\"training Qnet -------------\")\n",
    "        self.myQnet = Qnet(n_jobs=njobs, feature_names=featurenames,\n",
    "                           min_samples_split=min_samples_split, alpha=alpha,\n",
    "                           max_depth=max_depth, max_feats=max_feats)\n",
    "        self.myQnet.fit(samples)\n",
    "        print(\"Qnet trained --------------\")\n",
    "        self.features = featurenames\n",
    "\n",
    "    def save(self,\n",
    "             file_path=None):\n",
    "        \"\"\"save qnet\n",
    "\n",
    "        Args:\n",
    "          file_path (str, optional): Desired Qnet filename. Defaults to None.\n",
    "        \"\"\"\n",
    "        assert_None([self.myQnet])\n",
    "        if file_path is None:\n",
    "            file_path = 'tmp_Qnet.joblib'\n",
    "        save_qnet(self.myQnet, file_path)\n",
    "    \n",
    "    def load(self,\n",
    "             file_path,\n",
    "             VERBOSE=False):\n",
    "        \"\"\"load Qnet from file\n",
    "\n",
    "        Args:\n",
    "          file_path (str): path to Qnet savefile\n",
    "          VERBOSE (bool): boolean to turn on verbose\n",
    "\n",
    "        Returns:\n",
    "          [Qnet]: Qnet object\n",
    "        \"\"\"\n",
    "        if VERBOSE:\n",
    "            print(\"loading..\")\n",
    "        self.myQnet = load_qnet(file_path)\n",
    "        self.features = self.myQnet.feature_names\n",
    "        if VERBOSE:\n",
    "            print(\"done\")\n",
    "        return self.myQnet\n",
    "\n",
    "    def export_dot(self,\n",
    "                   filename,\n",
    "                   index=[3],\n",
    "                   path='',\n",
    "                   generate_trees=False,\n",
    "                   threshold=0.2):\n",
    "        \"\"\"export Qnet trees\n",
    "\n",
    "        Args:\n",
    "          filename (str): Desired tree savefile\n",
    "          index (list, optional): list of indices to generate trees. Defaults to [3].\n",
    "          path (str, optional): Desired tree savefile path. Defaults to ''.\n",
    "          generate_trees (bool, optional): Whether or not to generate individual trees. \n",
    "                                             Defaults to False, or to generate individual trees.\n",
    "          threshold (float, optional): Numeric cutoff for edge weights. If the edge weights exceed \n",
    "                                         this cutoff, then we include it into the graph. Defaults to 0.2.\n",
    "        \"\"\"\n",
    "        if not generate_trees:\n",
    "            export_qnet_graph(self.myQnet, \n",
    "                              threshold, path+filename)\n",
    "        else:\n",
    "            for i in index:\n",
    "                export_qnet_tree(self.myQnet,\n",
    "                                 i, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            wrkstat HRS1 HRS2 evwork        wrkslf  wrkgovt OCC10 PRESTG10  \\\n",
      "0  temp not working    e    c    NaN  someone else  private     b        c   \n",
      "1  working fulltime    c    e    NaN  someone else  private     b        d   \n",
      "\n",
      "  PRESTG105PLUS INDUS10  ...    neisafe rlooks rgroomed rweight rhlthend wtss  \\\n",
      "0             c       c  ...  very safe    NaN      NaN     NaN      NaN    e   \n",
      "1             d       c  ...  very safe    NaN      NaN     NaN      NaN    c   \n",
      "\n",
      "  wtssnr wtssall vstrat vpsu  \n",
      "0      e       e   3301    1  \n",
      "1      c       c   3301    1  \n",
      "\n",
      "[2 rows x 1034 columns]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# testing dataFormatter\n",
    "data = dataFormatter(samples=GSSDATA)\n",
    "# load the sample data\n",
    "# have option for test/train split\n",
    "# make checks to ensure we will not throw errors at qnet construction \n",
    "# data.train() returns training data\n",
    "# data.test() returns test data\n",
    "print(data.samples[:2])\n",
    "features,samples = data.format_samples('train')\n",
    "\n",
    "# we can set mutable and immutable vars from list or file\n",
    "im_vars_df = pd.read_csv(IMMUTABLE_FILE, names=['vars'])\n",
    "im_vars_list = im_vars_df.vars.to_list()\n",
    "mutable_vars, immutable_vars = data.mutable_variables(immutable_list=im_vars_list)\n",
    "mutable_vars, immutable_vars = data.mutable_variables(IMMUTABLE_FILE=IMMUTABLE_FILE)\n",
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting\n",
      "1784\n",
      "training Qnet -------------\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------\n",
    "# testing model functionality\n",
    "# can either input features and samples directly, or infer from data obj\n",
    "model_ = model()\n",
    "\n",
    "# qnet construction parameters\n",
    "test_model_buildqnet = True\n",
    "# infer qnet\n",
    "if test_model_buildqnet:\n",
    "        print(\"fitting\")\n",
    "        model_.fit(data_obj=data, njobs=6)\n",
    "        print(\"fitted\")\n",
    "        model_.export_dot(\"tmp_dot_modelclass.dot\",\n",
    "                        generate_trees=True)\n",
    "        model_.save(\"tmp_nodelclass.joblib\")\n",
    "        #model_.load(\"tmp_nodelclass.joblib\")\n",
    "else:\n",
    "    model_.load(\"examples_data/gss_2018.joblib\")\n",
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# testing cognet\n",
    "# set some paramaters in instantiating cognet class \n",
    "# if loading from model obj, no need to load_data, otherwise, load_data\n",
    "\n",
    "Cg = cg()\n",
    "print(len(model_.features))\n",
    "Cg.load_from_model(model_, data, 'all')\n",
    "\n",
    "# distance calculation for individual samples    \n",
    "# we have a nsteps parameter (for sample 1 and sample2)\n",
    "# which qsamples the sample1 and sample2 if set before\n",
    "# computing distance. Note qsampling must only \n",
    "# change mutable varaibles, so need to compute base-freq\n",
    "distance = Cg.distance(samples[1],samples[3],nsteps1=5, nsteps2=5)\n",
    "print(distance)\n",
    "qdistance_ = qdistance(samples[1],samples[3],Cg.qnet,Cg.qnet)\n",
    "print(\"actual:{}\".format(qdistance_))\n",
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------\n",
    "# produce stats on how many column names actually match\n",
    "stats = Cg.set_poles(POLEFILE,\"R\",\"L\",steps=120)\n",
    "\n",
    "# compute polar distance matrix\n",
    "dmatrix = Cg.polar_separation(nsteps=0)\n",
    "#------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------------------\n",
    "# the following are for single samples\n",
    "dissonance_array = Cg.dissonance(1)\n",
    "returndict = {}\n",
    "rederr,r_prob,rand_err,s,qs,s_rand,mask_ = Cg.randomMaskReconstruction(1, returndict)# sample=np.array(samples[1]))\n",
    "\n",
    "#ideology_index = Cg.compute_DLI_sample(3)\n",
    "Cg.num_qsamples = 5\n",
    "ideology_index = Cg.ideology(3,pole_1=\"R\",pole_2=\"L\")\n",
    "\n",
    "# get dispersion of an individual sample\n",
    "Dispersion_ = Cg.dispersion(3)\n",
    "print(Dispersion_)\n",
    "# compute distance from each pole\n",
    "array_distances = Cg.polarDistance(1, returndict)\n",
    "#-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-------------------\n",
    "# the following are for arrays of samples\n",
    "# multiprocessing suffices\n",
    "count = 0\n",
    "if count == 0:\n",
    "    Cg.set_nsamples(10)\n",
    "    count +=1\n",
    "# computing polar_indices makes sure that dissonance matrix only takes in polar cols\n",
    "Cg.compute_polar_indices()\n",
    "dissonance_array = Cg.dissonance_matrix(output_file='examples_results/DISSONANCE_matrix.csv')\n",
    "# multiprocessing suffices\n",
    "dataframes,error_array = Cg.randomMaskReconstruction_multiple('examples_results/randomMaskRecon_test.csv')\n",
    "# multiprocessing suffices\n",
    "ideology_index = Cg.compute_DLI_samples('ideology','examples_results/ideology.csv')\n",
    "# multiprocessing suffices\n",
    "local_dispersion = Cg.compute_DLI_samples('dispersion', 'examples_results/dispersion_test.csv')\n",
    "# compute distance from each pole\n",
    "# multiprocessing suffices\n",
    "array_distances = Cg.polarDistance_multiple('examples_results/polarDistance_multiple_test.csv')\n",
    "#-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute qdistance matrix for small set of samples\n",
    "# set nsamples first to set the number of samples to be included in matrix\n",
    "distance_matrix=Cg.distfunc_multiples(\"examples_results/distfunc_multiples_testing.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write files to compute qdistance matrix for large set of samples\n",
    "# execute generated shell script to run mpi parallelization on midway\n",
    "Cg.dmat_filewriter(\"GSS_cognet.py\", \"examples_data/gss_2018.joblib\",\n",
    "                   MPI_SETUP_FILE=\"GSS_mpi_setup.sh\",\n",
    "                   MPI_RUN_FILE=\"GSS_mpi_run.sh\",\n",
    "                   MPI_LAUNCHER_FILE=\"GSS_mpi_launcher.sh\",\n",
    "                   YEARS='2018',NODES=4,T=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## embedding\n",
    "## embed generated Qdist Matrix\n",
    "Cg.year = '2018'\n",
    "Cg.embed('examples_results/distfunc_multiples_testing.csv', 'embed', 'examples_results/',EMBED_BINARY='cognet/cognet/bin/__embed__.so')\n",
    "#pd.read_csv('examples_results/embed_E_2018.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
