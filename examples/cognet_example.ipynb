{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of how we see \n",
    "# the package work. The functions listed here\n",
    "# are probably the only ones that should be exposed, ie documented.\n",
    "# others should br prepended with a double underscore\n",
    "#  \n",
    "# The cognet directory has the following \"modules\"\n",
    "# which are seprate .py files containing clases and functions\n",
    "# The modules are cognet.py, dataFormatter.py, model.py, util.py, viz.py\n",
    "# we will write the viz.py later.\n",
    "import sys\n",
    "\n",
    "from quasinet.qnet import qdistance\n",
    "from cognet.cognet import cognet as cg\n",
    "from cognet.dataFormatter import dataFormatter\n",
    "from cognet.model import model \n",
    "#import cognet.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "yr = '2018'\n",
    "POLEFILE='GSS/data/polar_vectors.csv'\n",
    "QPATH='GSS/data/gss_'+yr+'.joblib'\n",
    "IMMUTABLE_FILE='GSS/data/immutable.csv'\n",
    "GSSDATA = 'GSS/data/gss_'+yr+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            wrkstat HRS1 HRS2 evwork        wrkslf  wrkgovt OCC10 PRESTG10  \\\n",
      "0  temp not working    e    c    NaN  someone else  private     b        c   \n",
      "1  working fulltime    c    e    NaN  someone else  private     b        d   \n",
      "\n",
      "  PRESTG105PLUS INDUS10  ...    neisafe rlooks rgroomed rweight rhlthend wtss  \\\n",
      "0             c       c  ...  very safe    NaN      NaN     NaN      NaN    e   \n",
      "1             d       c  ...  very safe    NaN      NaN     NaN      NaN    c   \n",
      "\n",
      "  wtssnr wtssall vstrat vpsu  \n",
      "0      e       e   3301    1  \n",
      "1      c       c   3301    1  \n",
      "\n",
      "[2 rows x 1034 columns]\n",
      "(1784, 1034)\n"
     ]
    }
   ],
   "source": [
    "# testing dataFormatter\n",
    "data = dataFormatter(samples=GSSDATA)\n",
    "# load the sample data\n",
    "# have option for test/train split\n",
    "# make checks to ensure we will not throw errors at qnet construction \n",
    "print(data.samples[:2])\n",
    "features,samples = data.format_samples('train') # default trains and tests using half\n",
    "all_samples = True\n",
    "if all_samples: # use all samples to train, instead of half\n",
    "    features,samples = data.Qnet_formatter()\n",
    "\n",
    "# format data for Qnet training and fitting\n",
    "print(samples.shape)\n",
    "\n",
    "# set mutable and immutable vars either from list or file\n",
    "im_vars_df = pd.read_csv(IMMUTABLE_FILE, names=['vars'])\n",
    "im_vars_list = im_vars_df.vars.to_list()\n",
    "mutable_vars, immutable_vars = data.mutable_variables(immutable_list=im_vars_list)\n",
    "mutable_vars, immutable_vars = data.mutable_variables(IMMUTABLE_FILE=IMMUTABLE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing model functionality\n",
    "# can either input features and samples directly, or infer from data obj\n",
    "model_ = model()\n",
    "\n",
    "# qnet construction parameters, \n",
    "# choose to either load or fit qnet from scratch\n",
    "# and to either load from url or local repo\n",
    "test_model_buildqnet = False\n",
    "url_load = True\n",
    "if test_model_buildqnet:\n",
    "        print(\"fitting\")\n",
    "        model_.fit(data_obj=data,\n",
    "                   min_samples_split=2,\n",
    "                   alpha=0.05,\n",
    "                   max_depth=-1,\n",
    "                   max_feats=-1,\n",
    "                   early_stopping=False,\n",
    "                   verbose=0,\n",
    "                   random_state=None,\n",
    "                   njobs=8)\n",
    "        print(\"fitted\")\n",
    "        model_.export_dot(\"GSS/results/tmp_dot_modelclass.dot\",\n",
    "                        generate_trees=True)\n",
    "        model_.save(\"GSS/results/tmp_nodelclass.joblib\")\n",
    "        #model_.load(\"tmp_nodelclass.joblib\")\n",
    "else:\n",
    "    if url_load:\n",
    "        QNETFILE = 'https://zenodo.org/record/5781768/files/gss_2018.joblib'\n",
    "    else:\n",
    "        QNETFILE = 'GSS/data/gss_2018.joblib'\n",
    "    model_.load(QNETFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from quasinet.qnet import Qnet, qdistance, load_qnet, qdistance_matrix\n",
    "from quasinet.qsampling import qsample, targeted_qsample\n",
    "#from mpi4py.futures import MPIPoolExecutor\n",
    "import sys\n",
    "import subprocess\n",
    "from scipy.stats import entropy\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from cognet.util import embed_to_pca\n",
    "import pkgutil\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "class cognet:\n",
    "    \"\"\"Aggregate related Qnet functions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Init\n",
    "        \"\"\"\n",
    "        self.year = None\n",
    "        self.n_jobs = 28\n",
    "        self.qnet = None\n",
    "        self.steps = 120\n",
    "        self.num_qsamples = None\n",
    "        self.all_samples = None\n",
    "        self.samples = None\n",
    "        self.samples_as_strings = None\n",
    "        self.features = None\n",
    "        self.cols = None\n",
    "        self.immutable_vars = None\n",
    "        self.mutable_vars = None\n",
    "        self.poles = None\n",
    "        self.polar_features = None\n",
    "        self.polar_indices = None\n",
    "        self.poles_dict = {}\n",
    "        self.d0 = None\n",
    "        self.s_null = None\n",
    "        self.D_null = None\n",
    "        self.mask_prob = 0.5\n",
    "        self.variation_weight = None\n",
    "        self.polar_matrix = None\n",
    "        self.nsamples = None\n",
    "        self.restricted = False\n",
    "        self.MAX_PROCESSES = 0\n",
    "    \n",
    "    def load_from_model(self,\n",
    "                        model,\n",
    "                        data_obj,\n",
    "                        key,\n",
    "                        im_vars=None,\n",
    "                        m_vars=None):\n",
    "        \"\"\"load parameters from model object\n",
    "\n",
    "        Args:\n",
    "          model (Class): model obj for loading parameters\n",
    "          data_obj (class): instance of dataformatter class\n",
    "          key (str): 'all', 'train', or 'test', corresponding to sample type\n",
    "          im_vars (list[str], optional): Not implemented yet. Defaults to None.\n",
    "          m_vars (list[str], optional): Not implemented yet. Defaults to None.\n",
    "        \"\"\"\n",
    "        if model is not None:\n",
    "            # inherit atrributes from model object\n",
    "            self.qnet = model.myQnet\n",
    "            featurenames, samples = data_obj.format_samples(key)\n",
    "            samples = pd.DataFrame(samples)\n",
    "            self.cols = np.array(featurenames)\n",
    "            self.features = pd.DataFrame(columns=np.array(featurenames))\n",
    "            \n",
    "            # inherit mutable and immutable variables from model obj\n",
    "            if any(x is not None for x in [model.immutable_vars, model.mutable_vars]):\n",
    "                if model.immutable_vars is not None:\n",
    "                    self.immutable_vars = model.immutable_vars\n",
    "                    self.mutable_vars = [x for x in self.features if x not in self.immutable_vars]\n",
    "                elif model.mutable_vars is not None:\n",
    "                    self.mutable_vars = model.mutable_vars\n",
    "                    self.immutable_vars = [x for x in self.features if x not in self.mutable_vars]\n",
    "            else:\n",
    "                self.mutable_vars = self.features\n",
    "            \n",
    "            # inherit and set class attributes.\n",
    "            self.samples = pd.DataFrame(samples).replace(\"nan\",\"\").fillna(\"\")\n",
    "            self.samples.columns = np.array(featurenames)\n",
    "            self.all_samples = self.samples\n",
    "            self.samples_as_strings = self.samples.fillna('').values.astype(str)[:]\n",
    "            self.s_null=['']*len(self.samples_as_strings[0])\n",
    "            self.D_null=self.qnet.predict_distributions(self.s_null)\n",
    "            variation_weight = []\n",
    "            for d in self.D_null:\n",
    "                v=[]\n",
    "                for val in d.values():\n",
    "                    v=np.append(v,val)\n",
    "                variation_weight.append(entropy(v,base=len(v)))\n",
    "            variation_weight = np.nan_to_num(variation_weight) # remove nans\n",
    "            self.variation_weight = variation_weight\n",
    "    \n",
    "    def load_from_dataformatter(self, \n",
    "                                data_obj,\n",
    "                                key):\n",
    "        \"\"\"read in either train or test data, specified by key, from data obj,\n",
    "        and inherit other attributes.\n",
    "\n",
    "        Args:\n",
    "          data_obj (class): instance of dataformatter class\n",
    "          key (str): 'all', 'train', or 'test', corresponding to sample type\n",
    "          \n",
    "        Returns:\n",
    "          featurenames, samples: formatted arrays\n",
    "        \"\"\"\n",
    "        # inherit attributes from dataformatter object\n",
    "        featurenames, samples = data_obj.format_samples(key)\n",
    "        if any(x is not None for x in [self.features, self.samples]):\n",
    "            print(\"replacing original features/samples with dataformatter data\")\n",
    "        self.cols = featurenames\n",
    "        self.features = pd.DataFrame(columns=self.cols)\n",
    "        self.samples = pd.DataFrame(samples,columns=self.features)\n",
    "        self.all_samples = self.samples\n",
    "        self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "        self.s_null=['']*len(self.samples_as_strings[0])\n",
    "        return featurenames, samples\n",
    "\n",
    "    def load_data(self,\n",
    "                  year,\n",
    "                  features_by_year,\n",
    "                  samples,\n",
    "                  Qnet):\n",
    "        '''load cols, features, samples, and qnet.\n",
    "\n",
    "        Args:\n",
    "          year (str): to identify cols/features.\n",
    "          features_by_year (str): file containing all features by year of the dataset.\n",
    "          samples (str): file of samples for that year.\n",
    "          Qnet (str): Qnet file location.\n",
    "        '''\n",
    "        # set attributes from given files and data\n",
    "        self.qnet = load_qnet(qnet)\n",
    "        self.year = year\n",
    "        self.cols = np.array((pd.read_csv(features_by_year,\n",
    "                            keep_default_na=True, \n",
    "                            index_col=0).set_index(\n",
    "                                'year')).loc[int(year)].apply(\n",
    "                                    eval).values[0])\n",
    "        self.features = pd.DataFrame(columns=self.cols)\n",
    "        self.mutable_vars = [x for x in self.cols]\n",
    "        #[self.cols].fillna('').values.astype(str)[:]\n",
    "\n",
    "        # read in samples and initialize related attributes\n",
    "        self.samples=pd.read_csv(samples)\n",
    "        self.samples = pd.concat([self.samples,self.features], axis=0)\n",
    "        self.all_samples = self.samples\n",
    "        self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "        self.s_null=['']*len(self.samples_as_strings[0])\n",
    "        self.D_null=self.qnet.predict_distributions(self.s_null)\n",
    "        variation_weight = []\n",
    "        for d in self.D_null:\n",
    "            v=[]\n",
    "            for val in d.values():\n",
    "                v=np.append(v,val)\n",
    "            variation_weight.append(entropy(v,base=len(v)))\n",
    "        self.variation_weight = variation_weight\n",
    "\n",
    "    def set_immutable_vars(self,\n",
    "                        IMMUTABLE_FILE):\n",
    "        '''set vars to immutable and mutable, \n",
    "        can prob combine this with the load_data func: only set the immutable vars if necessary\n",
    "\n",
    "        Args:\n",
    "          IMMUTABLE_FILE (str): file containing the immutable features/vars\n",
    "        '''\n",
    "        # set mutable and immutable variable attributes \n",
    "        if self.cols is None:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "        self.immutable_vars = pd.read_csv(IMMUTABLE_FILE,index_col=0).transpose()\n",
    "        self.mutable_vars = None\n",
    "        self.mutable_vars = [x for x in self.cols\n",
    "                            if x.upper() not in self.immutable_vars.columns]\n",
    "    \n",
    "    def set_nsamples(self,\n",
    "                    num_samples,\n",
    "                    random=False):\n",
    "        '''select a subset of the samples\n",
    "\n",
    "        Args:\n",
    "          num_samples (int): Set num of samples to subset, default to None, resets to all samples\n",
    "          random (bool): take random sample if true, ordered sample if false\n",
    "        '''\n",
    "        # each time function is called, reset samples to use_all_samples\n",
    "        # this allows us to call nsamples numerous times \n",
    "        self.samples = self.all_samples\n",
    "        if self.samples is not None:\n",
    "            # if a greater number of sample is selected than available, raise error\n",
    "            if all(x is not None for x in [num_samples, self.samples]):\n",
    "                if num_samples > len(self.samples.index):\n",
    "                    string = 'The number of selected samples ({}) ' + \\\n",
    "                        'is greater than the number of samples ({})!'\n",
    "                    string = string.format(num_samples, len(self.samples.index))\n",
    "                    raise ValueError(string)\n",
    "\n",
    "                # if the same number of samples is selected as available, print warning\n",
    "                if num_samples == len(self.samples.index):\n",
    "                    string = 'The number of selected samples ({}) ' + \\\n",
    "                        'is equal to the number of samples ({})!'\n",
    "                    string = string.format(num_samples, len(self.samples.index))\n",
    "                    print(string)\n",
    "                    \n",
    "                # if random is true, return random sample, otherwise return an ordered slice\n",
    "                if random:\n",
    "                    self.samples = self.samples.sample(num_samples)\n",
    "                else:\n",
    "                    self.samples = self.samples.iloc[:num_samples]\n",
    "                self.nsamples = num_samples\n",
    "                self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "                \n",
    "            elif self.samples is None:\n",
    "                raise ValueError(\"load_data first!\")\n",
    "\n",
    "    def __variation_weight(self,\n",
    "                        index):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        d_=self.D_null[index]\n",
    "        v=[]\n",
    "        for val in d_.values():\n",
    "            v=np.append(v,val)\n",
    "        return entropy(v,base=len(v))\n",
    "    \n",
    "    def getBaseFrequency(self, \n",
    "                        sample):\n",
    "        '''get frequency of the variables\n",
    "        helper func for qsampling\n",
    "\n",
    "        Args:\n",
    "          sample (list[str]): vector of sample, must have the same num of features as the qnet\n",
    "        '''\n",
    "        # if variable is not mutable, set its base frequency to zero \n",
    "        MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()\n",
    "             \n",
    "        for m in self.mutable_vars:\n",
    "            MUTABLE[m]=1.0\n",
    "        mutable_x=MUTABLE.values[0]\n",
    "        base_frequency=mutable_x/mutable_x.sum()\n",
    "        \n",
    "        # otherwise, set base frequency weighted by variation weight\n",
    "        for i in range(len(base_frequency)):\n",
    "            if base_frequency[i]>0.0:\n",
    "                base_frequency[i]= self.variation_weight[i]*base_frequency[i]\n",
    "\n",
    "        return base_frequency/base_frequency.sum()\n",
    "    \n",
    "    def qsampling(self,\n",
    "                sample,\n",
    "                steps,\n",
    "                immutable=False):\n",
    "        '''perturb the sample based on the qnet distributions and number of steps\n",
    "\n",
    "        Args:\n",
    "          sample (1d array-like): sample vector, must have the same num of features as the qnet\n",
    "          steps (int): number of steps to qsample\n",
    "          immutable (bool): are there variables that are immutable?\n",
    "        '''\n",
    "        # immutable, check that mutable variables have been initialized\n",
    "        if immutable == True:\n",
    "            if all(x is not None for x in [self.mutable_vars, sample]):\n",
    "                return qsample(sample,self.qnet,steps,self.getBaseFrequency(self.samples))\n",
    "            elif self.mutable_vars is None:\n",
    "                raise ValueError(\"set mutable and immutable variables first!\")\n",
    "        else:\n",
    "            return qsample(sample,self.qnet,steps)\n",
    "\n",
    "    def random_sample(self,\n",
    "                      df=None,\n",
    "                      n=1):\n",
    "        '''compute a random sample from the underlying distributions of the dataset, by column.\n",
    "        \n",
    "        \n",
    "        Args:\n",
    "          df (pandas.DataFrame): Desired data to take random sample of. Defaults to None, in which case qnet samples are used.\n",
    "          n (int): number of random samples to take. Defaults to 1.\n",
    "          \n",
    "        Returns:\n",
    "          return_df (pd.DataFrame): Random sample drawn from underlying distribution of each column.\n",
    "        '''\n",
    "        # check if a new dataset was inputted\n",
    "        if df is None:\n",
    "            samples_ = self.samples\n",
    "        else:\n",
    "            samples_ = df\n",
    "\n",
    "        # take random sample from each of the columns based on their distribution\n",
    "        return_df = pd.DataFrame()\n",
    "        for col in samples_.columns:\n",
    "            return_df[col] = samples_[col].sample(n=n, replace=True).values\n",
    "            \n",
    "        return return_df\n",
    "    \n",
    "    def set_poles(self,\n",
    "                  POLEFILE,\n",
    "                  pole_1,\n",
    "                  pole_2,\n",
    "                  steps=0,\n",
    "                  mutable=False,\n",
    "                  VERBOSE=False,\n",
    "                  restrict=False,\n",
    "                  nsamples = None,\n",
    "                  random=False):\n",
    "        '''set the poles and samples such that the samples contain features in poles\n",
    "\n",
    "        Args:\n",
    "          steps (int): number of steps to qsample\n",
    "          POLEFILE (str): file containing poles samples and features\n",
    "          pole_1 (str): column name for first pole\n",
    "          pole_2 (str): column name for second pole\n",
    "          mutable (bool): Whether or not to set poles as the only mutable_vars\n",
    "          VERBOSE (bool): boolean flag prints number of pole features not found in sample features if True\n",
    "          restrict (bool): boolean flag restricts the sample features to polar features if True. Defaults to False.\n",
    "          random (bool): boolean flag takes random sample of all_samples\n",
    "        '''\n",
    "        invalid_count = 0\n",
    "        if all(x is not None for x in [self.samples, self.qnet]):\n",
    "            # read and set poles\n",
    "            poles = pd.read_csv(POLEFILE, index_col=0)\n",
    "            self.poles=poles.transpose()\n",
    "            self.polar_features = pd.concat([self.features, self.poles], axis=0).fillna('')\n",
    "            poles_dict = {}\n",
    "            for column in poles:\n",
    "                p_ = self.polar_features.loc[column][self.cols].fillna('').values.astype(str)[:]\n",
    "                # qsample poles to qnet\n",
    "                poles_dict[column] = self.qsampling(p_,steps)\n",
    "            self.poles_dict = poles_dict\n",
    "            self.pL = self.poles_dict[pole_1]\n",
    "            self.pR = self.poles_dict[pole_2]\n",
    "            self.d0 = qdistance(self.pL, self.pR, self.qnet, self.qnet)\n",
    "            \n",
    "            # restrict sample columns to polar columns\n",
    "            if restrict:\n",
    "                cols = [x for x in self.poles.columns if x in self.samples.columns]\n",
    "                self.samples=self.samples[cols]\n",
    "                self.restricted = True\n",
    "                self.samples = pd.concat([self.features,self.samples], axis=0).replace(\"nan\",\"\").fillna('')\n",
    "                self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "                \n",
    "            # if restrict==False, unrestrict it and set original\n",
    "            else:\n",
    "                self.restricted = False\n",
    "                self.samples = self.all_samples\n",
    "                if self.nsamples is not None:\n",
    "                    self.set_nsamples(nsamples, random)\n",
    "            \n",
    "            # identify pole features that were excluded due to sample features restriction\n",
    "            if VERBOSE:\n",
    "                for x in self.poles.columns:\n",
    "                    if x not in self.samples.columns:\n",
    "                        invalid_count += 1\n",
    "                        #self.samples[x]=''\n",
    "            \n",
    "            if mutable:\n",
    "                self.mutable_vars=[x for x in self.cols if x in self.poles.columns]\n",
    "        elif self.samples is None:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "\n",
    "        if VERBOSE:\n",
    "            print(\"{} pole features not found in sample features\".format(invalid_count))\n",
    "\n",
    "    def mp_compute(self, \n",
    "                   processes,\n",
    "                   func, \n",
    "                   cols,\n",
    "                   outfile, \n",
    "                   args=[]):\n",
    "        \"\"\"\n",
    "        Compute desired function through multiprocessing and save result to csv.\n",
    "\n",
    "        Args:\n",
    "          processes (int): number of processes to use.\n",
    "          func (func): function to compute using multiprocessing\n",
    "          cols (list): column names of resulting csv\n",
    "          outfile (str)): filepath + filename for resulting csv\n",
    "          args (list): list containing arguments for desired function. Defaults to empty list.\n",
    "        \"\"\"\n",
    "\n",
    "        # init mp.Manager and result dict\n",
    "        manager = mp.Manager()\n",
    "        return_dict = manager.dict()\n",
    "\n",
    "        # set processes as given, unless class parameter is set\n",
    "        max_processes = processes\n",
    "        if self.MAX_PROCESSES != 0:\n",
    "            max_processes = self.MAX_PROCESSES\n",
    "            print(\"Number of Processes {} has been set using class parameter\".format(self.MAX_PROCESSES))\n",
    "        num_processes = 0\n",
    "        process_list = []\n",
    "        \n",
    "        # init mp.Processes for each individual sample\n",
    "        # run once collected processes hit max\n",
    "        for i in range(len(self.samples)):\n",
    "            params = tuple([i, return_dict] + args)\n",
    "            num_processes += 1\n",
    "            p = mp.Process(target=func,\n",
    "                        args=params)\n",
    "            process_list.append(p)\n",
    "            if num_processes == max_processes:\n",
    "                [x.start() for x in process_list]\n",
    "                [x.join() for x in process_list]\n",
    "                process_list = []\n",
    "                num_processes = 0\n",
    "                \n",
    "        # compute remaining processes\n",
    "        if num_processes != 0:\n",
    "            [x.start() for x in process_list]\n",
    "            [x.join() for x in process_list]\n",
    "            process_list = []\n",
    "            num_processes = 0\n",
    "        \n",
    "        # format and save resulting dict\n",
    "        result = pd.DataFrame(return_dict.values(), columns=cols, index=return_dict.keys()).sort_index()\n",
    "        result.to_csv(outfile, index=None)\n",
    "        return result\n",
    "    \n",
    "    def distance(self,\n",
    "                sample1,\n",
    "                sample2,\n",
    "                nsteps1=0,\n",
    "                nsteps2=0):\n",
    "        \"\"\"qsamples each sample set num of steps, then takes qdistance\n",
    "\n",
    "        Args:\n",
    "          sample1 (list[str]): sample vector 1, must have the same num of features as the qnet\n",
    "          sample2 (list[str]): sample vector 2, must have the same num of features as the qnet\n",
    "          nsteps1 (int, optional): number of steps to qsample for sample1\n",
    "          nsteps2 (int, optional): number of steps to qsample for sample2\n",
    "\n",
    "        Returns:\n",
    "          qdistance: float, distance between two samples\n",
    "        \"\"\"\n",
    "        if self.qnet is None:\n",
    "            raise ValueError(\"load qnet first!\")\n",
    "        #bp1 = self.getBaseFrequency(sample1)\n",
    "        #bp2 = self.getBaseFrequency(sample2)\n",
    "        # qsample samples\n",
    "        sample1 = qsample(sample1, self.qnet, nsteps1)#, baseline_prob=bp1)\n",
    "        sample2 = qsample(sample2, self.qnet, nsteps2)#, baseline_prob=bp2)\n",
    "        return qdistance(sample1, sample2, self.qnet, self.qnet)\n",
    "    \n",
    "    def __distfunc(self, \n",
    "                   x, \n",
    "                   y):\n",
    "        '''Compute distance between two samples\n",
    "\n",
    "        Args:\n",
    "          x (list[str]): first sample\n",
    "          y (list[str]): second sample\n",
    "          \n",
    "        Returns:\n",
    "         d: qdistance\n",
    "        '''\n",
    "        d=qdistance(x,y,self.qnet,self.qnet)\n",
    "        return d\n",
    "    \n",
    "    def distfunc_line(self,\n",
    "                    i,\n",
    "                    return_dict=None):\n",
    "        '''compute the distance for a single sample against all other samples\n",
    "\n",
    "        Args:\n",
    "          i (int): row\n",
    "          return_dict (dict): dictionary containing multiprocessing results\n",
    "        \n",
    "        Return:\n",
    "          line: float, numpy.ndarray\n",
    "        '''\n",
    "        if all(x is not None for x in [self.samples, self.features]):\n",
    "            w = self.samples.index.size\n",
    "            line = np.zeros(w)\n",
    "            y = self.samples_as_strings[i]\n",
    "            for j in range(w):\n",
    "                # only compute half of the distance matrix\n",
    "                if j > i:\n",
    "                    x = self.samples_as_strings[j]\n",
    "                    line[j] = self.__distfunc(x, y)\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "        if return_dict is not None:\n",
    "            return_dict[i] = line\n",
    "        return line\n",
    "    \n",
    "    def distfunc_multiples(self,\n",
    "                           outfile,\n",
    "                           processes=6,\n",
    "                           samples=None):\n",
    "        \"\"\"compute distance matrix for all samples in the dataset\n",
    "\n",
    "        Args:\n",
    "          outfile (str): desired output filename and path\n",
    "          processes (int): Number of processes to run in parallel. Defaults to 6.\n",
    "          samples (2D array): Dataset from which to calculate qdist matrix. Defaults to None.\n",
    "          \n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing distance matrix\n",
    "        \"\"\"\n",
    "        if all(x is not None for x in [self.samples, self.features]):\n",
    "            # if exterior dataset is given, temporarily replace class attributes\n",
    "            if samples is not None:\n",
    "                original_samples = self.samples\n",
    "                original_samples_as_strings = self.samples_as_strings\n",
    "                self.samples = samples\n",
    "                samples = samples.fillna(\"\").values.astype(str)\n",
    "                self.samples_as_strings = samples\n",
    "            cols = [i for i in range(len(self.samples))]\n",
    "            result = self.mp_compute(processes,\n",
    "                                        self.distfunc_line,\n",
    "                                        cols,\n",
    "                                        outfile)\n",
    "            \n",
    "            # format and save resulting dict, and tranpose symmetrical distance matrix\n",
    "            result = result.to_numpy()\n",
    "            result = pd.DataFrame(np.maximum(result, result.transpose()))\n",
    "            result.to_csv(outfile, index=None, header=None)\n",
    "            \n",
    "            # replace class attributes with originals\n",
    "            if samples is not None:\n",
    "                self.samples = original_samples\n",
    "                self.samples_as_strings = original_samples_as_strings\n",
    "        else:\n",
    "            raise ValueError(\"load data first!\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def polarDistance(self,\n",
    "                    i,\n",
    "                    return_dict=None):\n",
    "        \"\"\"return the distances from a single sample to the poles\n",
    "\n",
    "        Args:\n",
    "          i (int): index of sample to take\n",
    "          return_dict (dict): dictionary containing multiprocessing results\n",
    "\n",
    "        Returns:\n",
    "          distances: float, distance from sample to each pole\n",
    "        \"\"\"\n",
    "        p = self.samples_as_strings[i]\n",
    "        distances = []\n",
    "        # calculate from each pole to the sample, and append to array\n",
    "        for index, row in self.polar_features[self.cols].iterrows():\n",
    "            row = row.fillna('').values.astype(str)[:]\n",
    "            distances.append(self.distance(p, np.array(row)))\n",
    "        if return_dict is not None:\n",
    "            return_dict[i] = distances\n",
    "        return distances\n",
    "            \n",
    "    def polarDistance_multiple(self,\n",
    "                               outfile,\n",
    "                               processes=6):\n",
    "        \"\"\"return the distance from all samples to the poles\n",
    "\n",
    "        Args:\n",
    "          outfile (str): desired output filename and path\n",
    "          \n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing polar distance results\n",
    "        \"\"\"\n",
    "        if all(x is not None for x in [self.samples, self.cols,\n",
    "                                    self.polar_features]):\n",
    "            # get the column names\n",
    "            pole_names = []\n",
    "            for index, row in self.polar_features[self.cols].iterrows():\n",
    "                pole_names.append(index)\n",
    "            result = self.mp_compute(processes,\n",
    "                                        self.polarDistance,\n",
    "                                        pole_names,\n",
    "                                        outfile)\n",
    "        else:\n",
    "            raise ValueError(\"load data first!\")\n",
    "        return result\n",
    "    \n",
    "    def polar_separation(self,\n",
    "                        nsteps=0):\n",
    "        \"\"\"calculates the distance between poles as a qdistance matrix\n",
    "\n",
    "        Args:\n",
    "          nsteps (int, optional): [description]. Defaults to 0.\n",
    "          \n",
    "        Returns:\n",
    "          self.polar_matrix: dictionary containing multiprocessing results\n",
    "        \"\"\"\n",
    "        # vectorize and qsample poles\n",
    "        polar_arraydata = self.polar_features[self.cols].values.astype(str)[:]\n",
    "        samples_ = []\n",
    "        for vector in polar_arraydata:\n",
    "            bp = self.getBaseFrequency(vector)\n",
    "            sample = qsample(vector, self.qnet, nsteps, baseline_prob=bp)\n",
    "            samples_.append(sample)\n",
    "        samples_ = np.array(samples_)\n",
    "        # calculate distance matrix for poles\n",
    "        self.polar_matrix = qdistance_matrix(samples_, samples_, self.qnet, self.qnet)\n",
    "        return self.polar_matrix\n",
    "        \n",
    "    def embed(self,\n",
    "            infile,\n",
    "            name_pref,\n",
    "            out_dir,\n",
    "            pca_model=False,\n",
    "            EMBED_BINARY=None):\n",
    "        '''\n",
    "        embed data\n",
    "\n",
    "        Args:\n",
    "          infile (str): input file to be embedded\n",
    "          name_pref (str): preferred name for output file\n",
    "          out_dir (str): output dir for results\n",
    "          pca_model (bool): whether or not to generate PCA model\n",
    "          EMBED_BINARY (os.path.abspath): path to embed binary\n",
    "        '''\n",
    "        # if all(x is not None for x in [self.year]):\n",
    "            # init file names \n",
    "        yr = ''\n",
    "        if self.year is not None:\n",
    "            yr = self.year\n",
    "        PREF = name_pref\n",
    "        FILE = infile\n",
    "        DATAFILE = out_dir + 'data_' +yr\n",
    "        EFILE = out_dir + PREF + '_E_' +yr\n",
    "        DFILE = out_dir + PREF + '_D_' +yr\n",
    "        \n",
    "        # set embed binary directory\n",
    "        if EMBED_BINARY is None:\n",
    "            EMBED = pkgutil.get_data(\"cognet.bin\", \"__embed__.so\") \n",
    "        else:\n",
    "            EMBED = EMBED_BINARY\n",
    "        \n",
    "        # embed data files\n",
    "        pd.read_csv(FILE, header=None).to_csv(DATAFILE,sep=' ',header=None,index=None)\n",
    "        STR=EMBED+' -f '+DATAFILE+' -E '+EFILE+' -D '+DFILE\n",
    "        subprocess.call(STR,shell=True)\n",
    "        if pca_model:\n",
    "            embed_to_pca(EFILE, EFILE+'_PCA')\n",
    "        # elif self.year is None:\n",
    "        #    raise ValueError(\"load_data first!\")\n",
    "    \n",
    "    def __calc_d0(self,\n",
    "                pole_1,\n",
    "                pole_2):\n",
    "        \"\"\"calculate distance between two poles\n",
    "\n",
    "        Args:\n",
    "          pole_1 (list[str]): a polar vector, must have same number of features as qnet\n",
    "          pole_2 (list[str]): a polar vector, must have same number of features as qnet\n",
    "        \"\"\"\n",
    "        self.pL = self.poles_dict[pole_1]\n",
    "        self.pR = self.poles_dict[pole_2]\n",
    "        self.d0 = qdistance(self.pL, self.pR, self.qnet, self.qnet)\n",
    "        \n",
    "    def ideology(self,\n",
    "                i,\n",
    "                return_dict=None,\n",
    "                pole_1=None,\n",
    "                pole_2=None):\n",
    "        \"\"\"return ideology index (left-leaning or right-leaning) for a singular sample\n",
    "\n",
    "        Args:\n",
    "          i (int): index of sample\n",
    "          pole_1 (int): index of Pole One to calc as base distance. Defaults to 0.\n",
    "          pole_2 (int): index of Pole Two to calc as base distance. Defaults to 1.\n",
    "          return_dict (dict, optional): dict containing results\n",
    "          \n",
    "        Returns:\n",
    "          [ideology_index, dR, dL, self.d0]: which way the sample leans,\n",
    "                                             distance from the right pole,\n",
    "                                             distance from the left pole,\n",
    "                                             and distance between poles, respectively\n",
    "        \"\"\"\n",
    "        # calculate base distance between two poles\n",
    "        if pole_1 is not None or pole_2 is not None:\n",
    "            self.__calc_d0(pole_1, pole_2)\n",
    "        \n",
    "        # calculate distances between sample and the two poles\n",
    "        p = self.samples_as_strings[i]\n",
    "        dR = qdistance(self.pR, p, self.qnet, self.qnet)\n",
    "        dL = qdistance(self.pL, p, self.qnet, self.qnet)\n",
    "        \n",
    "        ideology_index = (dR-dL)/self.d0\n",
    "        if return_dict is not None:\n",
    "            return_dict[i] = [ideology_index, dR, dL, self.d0]\n",
    "        return [ideology_index, dR, dL, self.d0]\n",
    "\n",
    "    def dispersion(self,\n",
    "                   i,\n",
    "                   return_dict=None):\n",
    "        \"\"\"qsamples a sample n times and takes distance matrix \n",
    "        to determine max and std of distances between qsamples\n",
    "\n",
    "        Args:\n",
    "          i (int): index of sample\n",
    "          return_dict (dict): dictionary containing multiprocessing results\n",
    "\n",
    "        Returns:\n",
    "          list[float]: std and max of the distances btwn qsamples\n",
    "        \"\"\"\n",
    "        # qsample sample num_qsample times\n",
    "        p = self.samples_as_strings[i]\n",
    "        Qset = [qsample(p, self.qnet, self.steps) for j in np.arange(self.num_qsamples)]\n",
    "        Qset = np.array(Qset)\n",
    "\n",
    "        # calculate qdistance matrix for qsampled samples\n",
    "        matrix = (qdistance_matrix(Qset, Qset, self.qnet, self.qnet))\n",
    "        Q = matrix.max()\n",
    "        Qsd = matrix.std()\n",
    "        \n",
    "        if return_dict is not None:\n",
    "            return_dict[i] = [Qsd, Q]\n",
    "        return [Qsd, Q]\n",
    "    \n",
    "    def compute_DLI_samples(self,\n",
    "                        type,\n",
    "                        outfile,\n",
    "                        num_qsamples=40,\n",
    "                        steps=120,\n",
    "                        n_jobs=28,\n",
    "                        pole_1=0,\n",
    "                        pole_2=1,\n",
    "                        processes=6):\n",
    "        \"\"\"compute and save ideology index or dispersion for all samples\n",
    "\n",
    "        Args:\n",
    "          num_qsamples (int): number of qsamples to compute\n",
    "          outfile (str): output file for results\n",
    "          type (str): whether to calc dispersion or ideology\n",
    "          steps (int): number of steps to qsample\n",
    "          n_jobs (int, optional): sets the number of jobs for parallelization. Defaults to 28.\n",
    "          pole_1 (int, optional): index of Pole One to calc as base distance. Defaults to 0.\n",
    "          pole_2 (int, optional): index of Pole Two to calc as base distance. Defaults to 1.\n",
    "\n",
    "        Raises:\n",
    "          ValueError: set poles if poles are not set\n",
    "          ValueError: load data if samples or features are not present\n",
    "            \n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing multiprocessing results\n",
    "        \"\"\"\n",
    "        if all(x is not None for x in [self.samples, self.features,\n",
    "                                    self.pL, self.pR]):\n",
    "            # init vars\n",
    "            self.num_qsamples = num_qsamples\n",
    "            self.steps = steps\n",
    "            if pole_1 != 0 or pole_2 != 1:\n",
    "                self.__calc_d0(pole_1, pole_2)\n",
    "            \n",
    "            if type == 'ideology':\n",
    "                func_ = self.ideology\n",
    "                cols=['ideology', 'dR', 'dL', 'd0']\n",
    "            elif type == 'dispersion':\n",
    "                func_ = self.dispersion\n",
    "                cols=['Qsd', 'Qmax']\n",
    "            else:\n",
    "                raise ValueError(\"Type must be either dispersion or ideology!\")\n",
    "            \n",
    "            result = self.mp_compute(processes,\n",
    "                                     func_,\n",
    "                                     cols,\n",
    "                                     outfile)\n",
    "        elif self.pL is None or self.pR is None:\n",
    "            raise ValueError(\"set_poles first!\")\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "        return result\n",
    "\n",
    "    def compute_polar_indices(self,\n",
    "                              num_samples=None,\n",
    "                              polar_comp=False,\n",
    "                              POLEFILE=None,\n",
    "                              steps=5):\n",
    "        '''set up polar indices for dissonance func\n",
    "\n",
    "        Args:\n",
    "          num_samples (int): subset of samples to take\n",
    "          polar_comp (bool): whether or not to set poles\n",
    "          POLEFILE (None): file containing pole samples and features\n",
    "          steps (int): number of steps to qsample\n",
    "        '''\n",
    "        if all(x is not None for x in [self.samples, self.features, self.poles]):\n",
    "            if num_samples is not None:\n",
    "                self.set_nsamples(num_samples)\n",
    "\n",
    "            if polar_comp:\n",
    "                self.set_poles(self.qnet, steps, POLEFILE)\n",
    "            \n",
    "            # calculate polar indices\n",
    "            polar_features = pd.concat([self.features, self.poles], axis=0)\n",
    "            self.polar_indices=np.where(polar_features[self.cols].fillna('XXXX').values[0]!='XXXX')[0]\n",
    "        \n",
    "        elif self.poles is None:\n",
    "            raise ValueError(\"set_poles first!\")\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "\n",
    "    def dissonance(self,\n",
    "                    sample_index=0,\n",
    "                    return_dict=None,\n",
    "                    MISSING_VAL=0.0,\n",
    "                    sample=None):\n",
    "        '''compute dissonance for a single sample, helper function for all_dissonance\n",
    "        \n",
    "        Args:\n",
    "          sample_index (int): index of the sample to compute dissonance. Defaults to 0.\n",
    "          return_dict (dict): dictionary containing multiprocessing results\n",
    "          MISSING_VAL (float): default dissonance value\n",
    "          sample (1D array): sample to compute dissonance of, instead of using sample index. Defaults to None.\n",
    "          \n",
    "        Returns: \n",
    "          diss[self.polar_indices]: ndarray containing dissonance for sample\n",
    "        '''\n",
    "        if all(x is not None for x in [self.samples, self.features]):\n",
    "            if sample is None:\n",
    "                s = self.samples_as_strings[sample_index]\n",
    "            else:\n",
    "                s = sample\n",
    "            if self.polar_indices is None:\n",
    "                self.polar_indices = range(len(s))\n",
    "\n",
    "            # init vars and calculate dissonance for sample\n",
    "            Ds=self.qnet.predict_distributions(s)\n",
    "            diss=np.ones(len(Ds))*MISSING_VAL\n",
    "            for i in self.polar_indices:\n",
    "                if s[i] != '':\n",
    "                    if s[i] in Ds[i].keys():\n",
    "                        diss[i]=1-Ds[i][s[i]]/np.max(\n",
    "                            list(Ds[i].values())) \n",
    "                    else:\n",
    "                        diss[i]=1.0\n",
    "            if return_dict is not None:\n",
    "                return_dict[sample_index] = diss[self.polar_indices]\n",
    "            return diss[self.polar_indices]\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "    \n",
    "    def dissonance_matrix(self,\n",
    "                        outfile='/example_results/DISSONANCE_matrix.csv',\n",
    "                        processes=6):\n",
    "        '''get the dissonance for all samples\n",
    "\n",
    "        Args:\n",
    "          output_file (str): directory and/or file for output\n",
    "          processes (int): max number of processes. Defaults to 6.\n",
    "\n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing dissonances for each sample\n",
    "        '''\n",
    "        # set columns\n",
    "        if self.polar_indices is not None:\n",
    "            polar_features = pd.concat([self.features, self.poles], axis=0)\n",
    "            cols = polar_features[self.cols].dropna(axis=1).columns\n",
    "        else:\n",
    "            cols = self.cols\n",
    "        \n",
    "        result = self.mp_compute(processes,\n",
    "                                    self.dissonance,\n",
    "                                    cols,\n",
    "                                    outfile)\n",
    "        return result\n",
    "    \n",
    "    def __choose_one(self,\n",
    "                X):\n",
    "        '''returns a random element of X\n",
    "\n",
    "        Args:\n",
    "          X (1D array-like): vector from which random element is to be chosen\n",
    "        \n",
    "        Returns:\n",
    "          X: random element of sample\n",
    "          None: if X has len 0\n",
    "        '''\n",
    "        X=list(X)\n",
    "        if len(X)>0:\n",
    "            return X[np.random.randint(len(X))]\n",
    "        return None\n",
    "\n",
    "    def getMaskedSample(self,\n",
    "                        s,\n",
    "                        mask_prob=0.5,\n",
    "                        allow_all_mutable=False):\n",
    "        '''inputs a sample and randomly mask elements of the sample\n",
    "\n",
    "        Args:\n",
    "          s (list[str]): vector of sample, must have the same num of features as the qnet.\n",
    "          mask_prob (float): float btwn 0 and 1, prob to mask element of sample. Defaults to 0.5\n",
    "          allow_all_mutable (bool): whether or not all variables are mutable. Defaults to False.\n",
    "          \n",
    "        Returns:\n",
    "          s1,\n",
    "          base_frequency,\n",
    "          MASKrand,\n",
    "          np.where(base_frequency)[0],\n",
    "          np.mean(rnd_match_prob),\n",
    "          np.mean(max_match_prob),\n",
    "          random_sample\n",
    "        '''\n",
    "        if self.samples is not None:\n",
    "            # init random mutable variable masking\n",
    "            s0=s.copy()\n",
    "            s0=np.array(s0)   \n",
    "            # double check, because code seems to imply that masking happens in order,\n",
    "            # i.e. limited to the first 100 features, if there are only 100 mutable features\n",
    "            MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()\n",
    "            WITHVAL=[x for x in self.cols[np.where(s0)[0]] if x in self.mutable_vars ]\n",
    "            MASKrand=[x for x in WITHVAL if random.random() < mask_prob ]\n",
    "            for m in MASKrand:\n",
    "                MUTABLE[m]=1.0\n",
    "            \n",
    "            mutable_x=MUTABLE.values[0]\n",
    "            base_frequency=mutable_x/mutable_x.sum()\n",
    "\n",
    "            # if np.isnan(base_frequency).any():\n",
    "            #     return np.nan,np.nan,np.nan\n",
    "            #     return self.getMaskedSample(s)\n",
    "\n",
    "            # mask sample according to masking (base_frequency)\n",
    "            s1=s.copy()\n",
    "            for i in range(len(base_frequency)):\n",
    "                if base_frequency[i]>0.0001:\n",
    "                    s1[i]=''\n",
    "                \n",
    "            # create a random sample to test reconstruction effectiveness\n",
    "            random_sample=np.copy(s)\n",
    "            rnd_match_prob=[]        \n",
    "            max_match_prob=[]        \n",
    "            D=self.qnet.predict_distributions(s)\n",
    "            for i in MASKrand:\n",
    "                random_sample[np.where(\n",
    "                    self.cols==i)[0][0]]=self.__choose_one(\n",
    "                        self.D_null[np.where(self.cols==i)[0][0]].keys())\n",
    "                    \n",
    "                rnd_match_prob=np.append(rnd_match_prob,1/len(\n",
    "                    self.D_null[np.where(self.cols==i)[0][0]].keys()))\n",
    "                \n",
    "                max_match_prob=np.append(\n",
    "                    max_match_prob,np.max(\n",
    "                        list(D[np.where(\n",
    "                            self.cols==i)[0][0]].values())))\n",
    "            \n",
    "            # calculate base_frequency if all variables are mutable\n",
    "            if allow_all_mutable:\n",
    "                WITHVAL=[x for x in self.cols[np.where(s0)[0]]]\n",
    "                MASKrand=[x for x in WITHVAL if random.random() < mask_prob ]\n",
    "                for m in MASKrand:\n",
    "                    MUTABLE[m]=1.0\n",
    "                mutable_x=MUTABLE.values[0]\n",
    "                base_frequency=mutable_x/mutable_x.sum()\n",
    "                s1=s.copy()\n",
    "                for i in range(len(base_frequency)):\n",
    "                    if base_frequency[i]>0.0001:\n",
    "                        s1[i]=''\n",
    "\n",
    "            return s1,base_frequency,MASKrand,np.where(\n",
    "                base_frequency)[0],np.mean(rnd_match_prob),np.mean(max_match_prob),random_sample\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "\n",
    "    def randomMaskReconstruction(self,\n",
    "                                index=None,\n",
    "                                return_dict=None,\n",
    "                                sample=None,\n",
    "                                index_colname=\"feature_names\",\n",
    "                                output_dir=\"recon_results/\",\n",
    "                                file_name=\"recon_tmp.csv\",\n",
    "                                mask_prob=0.5,\n",
    "                                allow_all_mutable=False,\n",
    "                                save_samples=False,\n",
    "                                save_output=True):\n",
    "        \"\"\"reconstruct the masked sample by qsampling and comparing to original\n",
    "        set self.mask_prob and self.steps if needed\n",
    "\n",
    "        Args:\n",
    "          index (int): index of sample to take.\n",
    "          return_dict (dict): dictionary containing multiprocessing results. Defaults to None.\n",
    "          sample (list[str], optional): sample vector, must have the same num of features as the qnet. Defaults to None.\n",
    "          index_colname (str): column name for index. Defaults to \"feature_names\"\n",
    "          output_dir (str): directory name for output files. Defaults to \"recon_results/\".\n",
    "          file_name (str): base file name for output files Defaults to \"recon_tmp.csv\".\n",
    "          mask_prob (float): float btwn 0 and 1, prob to mask element of sample. Defaults to 0.5\n",
    "          allow_all_mutable (bool): whether or not all variables are mutable. Defaults to False.\n",
    "          save_samples (bool): whether to include sample vectors in the savefile. Defaults to False.\n",
    "          save_output (bool): whether or not to save output df to file. Defaults to True.\n",
    "\n",
    "        Raises:\n",
    "          ValueError: Neither sample or index were given\n",
    "          ValueError: Both sample and index were given\n",
    "          \n",
    "        Returns:\n",
    "          return_values:(1 - (dqestim/dactual))*100,\n",
    "                            rmatch_u,\n",
    "                            rmatch,\n",
    "                            s,\n",
    "                            qs,\n",
    "                            random_sample,\n",
    "                            mask_\n",
    "        \"\"\"\n",
    "        if all(x is None for x in [sample, index]):\n",
    "            raise ValueError(\"Must input either sample or index!\")\n",
    "        elif all(x is not None for x in [sample, index]):\n",
    "            raise ValueError(\"Must input either sample or index not both!\")\n",
    "        elif sample is not None:\n",
    "            s=sample#np.array(pd.DataFrame(sample).fillna('').values.astype(str)[:])\n",
    "        elif index is not None:\n",
    "            s=self.samples_as_strings[index]\n",
    "        \n",
    "        # calculate masked sample and get variables\n",
    "        s1,bp,mask_,maskindex,rmatch_u,rmatch,random_sample=self.getMaskedSample(s, \n",
    "                                                                        mask_prob=mask_prob,\n",
    "                                                                        allow_all_mutable=allow_all_mutable)\n",
    "        # if base_frequency is nan, set return_dict to nans\n",
    "        if np.isnan(bp).any():\n",
    "            return_dict[index] = np.nan,np.nan,np.nan\n",
    "            return np.nan,np.nan,np.nan\n",
    "        \n",
    "        # make directories\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "\n",
    "        # qsample sample and calculate distances between original vs qsampled and masked\n",
    "        qs=qsample(s1,self.qnet,self.steps,bp)\n",
    "        dqestim=qdistance(s,qs,self.qnet,self.qnet)\n",
    "        dmask=qdistance(s,s1,self.qnet,self.qnet)\n",
    "        \n",
    "        # format and save sample, qsample statistics and values\n",
    "        cmpf=pd.DataFrame([s,qs,random_sample],\n",
    "                          columns=self.cols,\n",
    "                          index=['sample','qsampled','random_sample'])[mask_].transpose()\n",
    "        cmpf.index.name= index_colname\n",
    "        if save_output:\n",
    "            file_name = file_name.replace(\"tmp\", str(index))\n",
    "            cmpf.to_csv(output_dir+file_name)\n",
    "            \n",
    "        if save_samples:\n",
    "            return_values = (1 - (dqestim/dmask))*100,rmatch_u,rmatch,mask_,s,qs,random_sample\n",
    "        else:\n",
    "            return_values = (1 - (dqestim/dmask))*100,rmatch_u,rmatch,mask_\n",
    "        \n",
    "        if return_dict is not None:\n",
    "            return_dict[index] = return_values\n",
    "            return return_dict[index]\n",
    "        return return_values\n",
    "\n",
    "    def randomMaskReconstruction_multiple(self,\n",
    "                                          outfile,\n",
    "                                          steps=200,\n",
    "                                          processes=6,\n",
    "                                          index_colname=\"feature_names\",\n",
    "                                          output_dir=\"recon_results/\",\n",
    "                                          file_name=\"recon_tmp.csv\",\n",
    "                                          mask_prob=0.5,\n",
    "                                          allow_all_mutable=False,\n",
    "                                          save_samples=False,\n",
    "                                          save_output=True):\n",
    "        '''runs and saves the results of the predicted masked sample\n",
    "\n",
    "        Args:\n",
    "          output_file (str): directory and/or file for output.\n",
    "          processes (int): max number of processes. Defaults to 6.\n",
    "          index_colname=\"feature_names\",\n",
    "          output_dir=\"recon_results/\",\n",
    "          file_name=\"recon_tmp.csv\",\n",
    "          mask_prob (float): float btwn 0 and 1, prob to mask element of sample. Defaults to 0.5\n",
    "          allow_all_mutable (bool): whether or not all variables are mutable. Defaults to False.\n",
    "          save_samples (boolean): whether or not to save the generated qsamples, random samples, etc. Defaults to False.\n",
    "          save_output (bool): whether or not to save output df to file. Defaults to True.\n",
    "          \n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing masking and reconstruction results.\n",
    "        '''\n",
    "        # set columns for mp_compute\n",
    "        if save_samples:\n",
    "            cols = ['rederr','r_prob','rand_err','mask_','sample','qsampled','random_sample']\n",
    "        else:\n",
    "            cols = ['rederr','r_prob','rand_err','mask_']\n",
    "        \n",
    "        # update class steps\n",
    "        self.steps = steps\n",
    "        \n",
    "        # set args\n",
    "        args=[None, index_colname, output_dir,\n",
    "              file_name, mask_prob, allow_all_mutable, \n",
    "              save_samples, save_output]\n",
    "        \n",
    "        result = self.mp_compute(processes,\n",
    "                                    self.randomMaskReconstruction,\n",
    "                                    cols,\n",
    "                                    outfile,\n",
    "                                    args=args)\n",
    "        return result\n",
    "    \n",
    "    def dmat_filewriter(self,\n",
    "                        QNETPATH,\n",
    "                        mpi_path=\"mpi_tmp/\",\n",
    "                        pyfile=\"cognet_qdistmatrix.py\",\n",
    "                        MPI_SETUP_FILE=\"mpi_setup.sh\",\n",
    "                        MPI_RUN_FILE=\"mpi_run.sh\",\n",
    "                        MPI_LAUNCHER_FILE=\"../launcher.sh\",\n",
    "                        YEARS='2016',\n",
    "                        NODES=4,\n",
    "                        T=12,\n",
    "                        num_samples=None,\n",
    "                        OUTFILE='tmp_distmatrix.csv',\n",
    "                        tmp_samplesfile=\"tmp_samples_as_strings.csv\"):\n",
    "        \"\"\"generate files to compute qdistance matrix using mpi parallelization\n",
    "\n",
    "        Args:\n",
    "          QNETPATH (str): Qnet filepath\n",
    "          pyfile (str, optional): Name of generated python file. Defaults to \"cognet_qdistmatrix.py\".\n",
    "          MPI_SETUP_FILE (str, optional): Name of mpi setup script. Defaults to \"mpi_setup.sh\".\n",
    "          MPI_RUN_FILE (str, optional): Name of mpi run script. Defaults to \"mpi_run.sh\".\n",
    "          MPI_LAUNCHER_FILE (str, optional): Launcher script filepath. Defaults to \"launcher.sh\".\n",
    "          YEARS (str, optional): If looping by year, not currently implemented. Defaults to '2016'.\n",
    "          NODES (int, optional): Number of nodes to use. Defaults to 4.\n",
    "          T (int, optional): Number of hours to reserve nodes for. Defaults to 12.\n",
    "          num_samples ([type], optional): How many samples to take. Defaults to None.\n",
    "          OUTFILE (str, optional): CSV File to write computed qdist matrix. Defaults to 'tmp_distmatrix.csv'.\n",
    "          tmp_samplesfile (str, optional): CSV File to write samples as strings. Defaults to \"tmp_samples_as_strings.csv\".\n",
    "\n",
    "        Raises:\n",
    "            ValueError: load data if qnet, features, or samples are not present]\n",
    "        \"\"\"\n",
    "        if all(x is not None for x in [self.samples,self.features,\n",
    "                                       self.qnet, self.cols]):\n",
    "            if num_samples is not None:\n",
    "                self.set_nsamples(num_samples)\n",
    "            \n",
    "            # init and make tmp dir \n",
    "            tmp_path = mpi_path\n",
    "            if not os.path.exists(tmp_path):\n",
    "                os.makedirs(tmp_path)\n",
    "            \n",
    "            pd.DataFrame(self.samples_as_strings).to_csv(tmp_path+tmp_samplesfile, header=None, index=None)\n",
    "            \n",
    "            w = self.samples.index.size\n",
    "            \n",
    "            # writing python file\n",
    "            with open(tmp_path+pyfile, 'w+') as f:\n",
    "                f.writelines([\"from mpi4py.futures import MPIPoolExecutor\\n\",\n",
    "                              \"import numpy as np\\n\",\n",
    "                              \"import pandas as pd\\n\",\n",
    "                              \"from quasinet.qnet import Qnet, qdistance, load_qnet, qdistance_matrix\\n\",\n",
    "                              \"from quasinet.qsampling import qsample, targeted_qsample\\n\\n\",\n",
    "                              \"qnet=load_qnet(\\'{}\\')\\n\".format(QNETPATH)])\n",
    "\n",
    "                f.writelines([\"w = {}\\n\".format(w),\n",
    "                              \"h = w\\n\",\n",
    "                              \"p_all = pd.read_csv(\\\"{}\\\", header=None).values.astype(str)[:]\\n\\n\".format(tmp_samplesfile)])\n",
    "\n",
    "                f.writelines([\"def distfunc(x,y):\\n\",\n",
    "                              \"\\td=qdistance(x,y,qnet,qnet)\\n\",\n",
    "                              \"\\treturn d\\n\\n\"])\n",
    "\n",
    "                f.writelines([\"def dfunc_line(k):\\n\",\n",
    "                              \"\\tline = np.zeros(w)\\n\",\n",
    "                              \"\\ty = p_all[k]\\n\",\n",
    "                              \"\\tfor j in range(w):\\n\",\n",
    "                              \"\\t\\tif j > k:\\n\",\n",
    "                              \"\\t\\t\\tx = p_all[j]\\n\",\n",
    "                              \"\\t\\t\\tline[j] = distfunc(x, y)\\n\",\n",
    "                              \"\\treturn line\\n\\n\"])\n",
    "\n",
    "                f.writelines([\"if __name__ == '__main__':\\n\",\n",
    "                              \"\\twith MPIPoolExecutor() as executor:\\n\",\n",
    "                              \"\\t\\tresult = executor.map(dfunc_line, range(h))\\n\",\n",
    "                              \"\\tresult = pd.DataFrame(result)\\n\",\n",
    "\t                          \"\\tresult = result.to_numpy()\\n\",\n",
    "                              \"\\tresult = pd.DataFrame(np.maximum(result, result.transpose()))\\n\"\n",
    "                              \"\\tresult.to_csv(\\'{}\\',index=None,header=None)\".format(OUTFILE)])\n",
    "            \n",
    "            # writing MPI setup file\n",
    "            with open(tmp_path+MPI_SETUP_FILE, 'w+') as ms:\n",
    "                ms.writelines([\"#!/bin/bash\\n\",\n",
    "                               \"YEAR=$1\\n\\n\",\n",
    "                               \"if [ $# -gt 1 ] ; then\\n\",\n",
    "                               \"\\tNODES=$2\\n\",\n",
    "                               \"else\\n\",\n",
    "                               \"\\tNODES=3\\n\",\n",
    "                               \"fi\\n\",\n",
    "                               \"if [ $# -gt 2 ] ; then\\n\",\n",
    "                               \"\\tNUM=$3\\n\",\n",
    "                               \"else\\n\",\n",
    "                               \"\\tNUM='all'\\n\",\n",
    "                               \"fi\\n\",\n",
    "                               \"if [ $# -gt 3 ] ; then\\n\",\n",
    "                               \"\\tPROG=$4\\n\",\n",
    "                               \"else\\n\",\n",
    "                               \"\\tPROG=$(tty)\\n\",\n",
    "                               \"fi\\n\\n\",\n",
    "                               \"NUMPROC=`expr 28 \\* $NODES`\\n\",\n",
    "                               \"echo \\\"module load midway2\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module unload python\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module unload openmpi\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module load python/anaconda-2020.02\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module load mpi4py\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"date; mpiexec -n \\\"$NUMPROC\\\" python3 -m mpi4py.futures {}; date\\\"  >> $PROG\\n\".format(pyfile),\n",
    "                                ])\n",
    "\n",
    "            # writing MPI run file\n",
    "            with open(tmp_path+MPI_RUN_FILE, 'w+') as mr:\n",
    "                mr.writelines([\"#!/bin/bash\\n\",\n",
    "                               \"YEARS=\\'{}\\'\\n\".format(YEARS),\n",
    "                               \"# nodes requested\\n\",\n",
    "                               \"NODES={}\\n\".format(NODES),\n",
    "                               \"# time requested\\n\",\n",
    "                               \"T={}\\n\".format(T),\n",
    "                               \"NUM=\\'all\\'\\n\",\n",
    "                               \"LAUNCH=./\\'{}\\'\\n\\n\".format(MPI_LAUNCHER_FILE),\n",
    "                               \"for yr in `echo $YEARS`\\n\",\n",
    "                               \"do\\n\",\n",
    "                               \"\\techo $yr\\n\",\n",
    "                               \"\\t./{} $yr $NODES $NUM tmp_\\\"$yr\\\"\\n\".format(MPI_SETUP_FILE),\n",
    "                               \"\\t$LAUNCH -P tmp_\\\"$yr\\\" -F -T $T -N \\\"$NODES\\\" -C 28 -p broadwl -J MPI_TMP_\\\"$yr\\\" -M 56\\n\",\n",
    "                               \"done\\n\",\n",
    "                               \"rm tmp_\\\"$yr\\\"*\\n\"])\n",
    "            os.system(\"cp {} {}\".format(MPI_LAUNCHER_FILE,tmp_path+'mpi_launcher.sh'))\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"load data first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034\n"
     ]
    }
   ],
   "source": [
    "# testing cognet\n",
    "# set some paramaters in instantiating cognet class \n",
    "# if loading from model obj, no need to use load_data func, otherwise, load_data\n",
    "Cg = cognet()\n",
    "print(len(model_.features))\n",
    "Cg.load_from_model(model_, data, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class-computed distance: 0.1151825041669634\n",
      "actual:0.11418596000727715\n"
     ]
    }
   ],
   "source": [
    "# distance calculation for individual samples    \n",
    "# we have a nsteps parameter (for sample 1 and sample2)\n",
    "# which qsamples the sample1 and sample2 if set before\n",
    "# computing distance. Note qsampling must only \n",
    "# change mutable varaibles, so need to compute base-freq\n",
    "distance = Cg.distance(samples[1],samples[3],nsteps1=5, nsteps2=5)\n",
    "print(\"class-computed distance:\", distance)\n",
    "qdistance_ = qdistance(samples[1],samples[3],Cg.qnet,Cg.qnet)\n",
    "print(\"actual:{}\".format(qdistance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 pole features not found in sample features\n"
     ]
    }
   ],
   "source": [
    "# produce stats on how many column names actually match\n",
    "stats = Cg.set_poles(POLEFILE,\"R\",\"L\",steps=120, VERBOSE=True)\n",
    "\n",
    "# compute polar distance matrix\n",
    "dmatrix = Cg.polar_separation(nsteps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wrkstat</th>\n",
       "      <th>HRS1</th>\n",
       "      <th>HRS2</th>\n",
       "      <th>evwork</th>\n",
       "      <th>wrkslf</th>\n",
       "      <th>wrkgovt</th>\n",
       "      <th>OCC10</th>\n",
       "      <th>PRESTG10</th>\n",
       "      <th>PRESTG105PLUS</th>\n",
       "      <th>INDUS10</th>\n",
       "      <th>...</th>\n",
       "      <th>neisafe</th>\n",
       "      <th>rlooks</th>\n",
       "      <th>rgroomed</th>\n",
       "      <th>rweight</th>\n",
       "      <th>rhlthend</th>\n",
       "      <th>wtss</th>\n",
       "      <th>wtssnr</th>\n",
       "      <th>wtssall</th>\n",
       "      <th>vstrat</th>\n",
       "      <th>vpsu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>temp not working</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td></td>\n",
       "      <td>someone else</td>\n",
       "      <td>private</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>very safe</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>3301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>working fulltime</td>\n",
       "      <td>c</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>someone else</td>\n",
       "      <td>private</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>very safe</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>3301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>working fulltime</td>\n",
       "      <td>c</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>someone else</td>\n",
       "      <td>private</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>very safe</td>\n",
       "      <td>attractive</td>\n",
       "      <td>about average</td>\n",
       "      <td>about the right weight</td>\n",
       "      <td></td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>3301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>working fulltime</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>someone else</td>\n",
       "      <td>private</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>somewhat safe</td>\n",
       "      <td>about average</td>\n",
       "      <td>about average</td>\n",
       "      <td>slightly underweight</td>\n",
       "      <td>excellent</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>3301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>working fulltime</td>\n",
       "      <td>c</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>self-employed</td>\n",
       "      <td>private</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>very unsafe</td>\n",
       "      <td>very unattractive</td>\n",
       "      <td>very poorly groomed</td>\n",
       "      <td>very overweight</td>\n",
       "      <td>poor</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>3301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>retired</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>yes</td>\n",
       "      <td>someone else</td>\n",
       "      <td>private</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>very safe</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>3378</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>school</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>somewhat safe</td>\n",
       "      <td>about average</td>\n",
       "      <td>about average</td>\n",
       "      <td>slightly underweight</td>\n",
       "      <td>excellent</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>3378</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>working fulltime</td>\n",
       "      <td>c</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>someone else</td>\n",
       "      <td>government</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>very safe</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>3378</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>working parttime</td>\n",
       "      <td>c</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>someone else</td>\n",
       "      <td>private</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>very safe</td>\n",
       "      <td>about average</td>\n",
       "      <td>about average</td>\n",
       "      <td>slightly overweight</td>\n",
       "      <td>excellent</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>3378</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>retired</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>yes</td>\n",
       "      <td>someone else</td>\n",
       "      <td>private</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>very safe</td>\n",
       "      <td>attractive</td>\n",
       "      <td>well groomed</td>\n",
       "      <td>about the right weight</td>\n",
       "      <td></td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>3378</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1784 rows  1034 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               wrkstat HRS1 HRS2 evwork         wrkslf     wrkgovt OCC10  \\\n",
       "0     temp not working    e    c          someone else     private     b   \n",
       "1     working fulltime    c    e          someone else     private     b   \n",
       "2     working fulltime    c    e          someone else     private     c   \n",
       "3     working fulltime    e    e          someone else     private     c   \n",
       "4     working fulltime    c    e         self-employed     private     c   \n",
       "...                ...  ...  ...    ...            ...         ...   ...   \n",
       "1779           retired    e    e    yes   someone else     private     d   \n",
       "1780            school    e    e     no                                e   \n",
       "1781  working fulltime    c    e          someone else  government     c   \n",
       "1782  working parttime    c    e          someone else     private     c   \n",
       "1783           retired    e    e    yes   someone else     private     c   \n",
       "\n",
       "     PRESTG10 PRESTG105PLUS INDUS10  ...        neisafe             rlooks  \\\n",
       "0           c             c       c  ...      very safe                      \n",
       "1           d             d       c  ...      very safe                      \n",
       "2           d             d       c  ...      very safe         attractive   \n",
       "3           c             c       c  ...  somewhat safe      about average   \n",
       "4           c             c       c  ...    very unsafe  very unattractive   \n",
       "...       ...           ...     ...  ...            ...                ...   \n",
       "1779        c             c       c  ...      very safe                      \n",
       "1780        e             e       e  ...  somewhat safe      about average   \n",
       "1781        c             c       c  ...      very safe                      \n",
       "1782        b             b       c  ...      very safe      about average   \n",
       "1783        c             c       c  ...      very safe         attractive   \n",
       "\n",
       "                 rgroomed                 rweight   rhlthend wtss wtssnr  \\\n",
       "0                                                               e      e   \n",
       "1                                                               c      c   \n",
       "2           about average  about the right weight               c      c   \n",
       "3           about average    slightly underweight  excellent    c      c   \n",
       "4     very poorly groomed         very overweight       poor    c      c   \n",
       "...                   ...                     ...        ...  ...    ...   \n",
       "1779                                                            c      c   \n",
       "1780        about average    slightly underweight  excellent    d      d   \n",
       "1781                                                            c      c   \n",
       "1782        about average     slightly overweight  excellent    c      c   \n",
       "1783         well groomed  about the right weight               c      c   \n",
       "\n",
       "     wtssall vstrat vpsu  \n",
       "0          e   3301    1  \n",
       "1          c   3301    1  \n",
       "2          c   3301    1  \n",
       "3          c   3301    1  \n",
       "4          c   3301    1  \n",
       "...      ...    ...  ...  \n",
       "1779       c   3378    2  \n",
       "1780       d   3378    2  \n",
       "1781       c   3378    2  \n",
       "1782       c   3378    2  \n",
       "1783       c   3378    2  \n",
       "\n",
       "[1784 rows x 1034 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cg.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance calculations\n",
      "class-computed distance: 0.10533663368244225\n",
      "actual:0.10533663368244225\n"
     ]
    }
   ],
   "source": [
    "# distance calculation for individual samples after setting poles\n",
    "print(\"distance calculations\")\n",
    "distance = Cg.distance(Cg.samples.fillna('').values.astype(str)[3],Cg.samples.iloc[5].values.astype(str),nsteps1=0, nsteps2=0)\n",
    "print(\"class-computed distance:\", distance)\n",
    "qdistance_ = qdistance(samples[3],samples[5],Cg.qnet,Cg.qnet)\n",
    "print(\"actual:{}\".format(qdistance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dissonance: [0.        0.        0.        ... 0.        0.8772147 0.       ]\n",
      "ideology: [0.0448815784886624, 0.1584942468589248, 0.15274414779617124, 0.12811713082252893]\n",
      "Dispersion: [0.011071279678648623, 0.030232326026976016]\n",
      "distance from poles: [0.13113822150272192, 0.13817617891264256]\n",
      "reconstruction results: 19.583520747135776 0.296773610328649 0.6753800691667388\n"
     ]
    }
   ],
   "source": [
    "#------------------\n",
    "# the following are for single samples\n",
    "\n",
    "# dissonance\n",
    "dissonance_array = Cg.dissonance(1)\n",
    "print(\"dissonance:\", dissonance_array)\n",
    "\n",
    "#ideology\n",
    "Cg.num_qsamples = 5\n",
    "ideology_index = Cg.ideology(3,pole_1=\"R\",pole_2=\"L\")\n",
    "print(\"ideology:\", ideology_index)\n",
    "\n",
    "# disperion\n",
    "dispersion_ = Cg.dispersion(3)\n",
    "print(\"Dispersion:\", dispersion_)\n",
    "\n",
    "# compute distance from each pole\n",
    "array_distances = Cg.polarDistance(1)\n",
    "print(\"distance from poles:\", array_distances)\n",
    "\n",
    "# random mask and reconstruction\n",
    "returndict = {}\n",
    "rederr,r_prob,rand_err,s,qs,s_rand,mask_ = Cg.randomMaskReconstruction(index=1, \n",
    "                                                                       return_dict=returndict,\n",
    "                                                                       index_colname=\"feature_names\",\n",
    "                                                                       output_dir=\"GSS/results/recon_results/\",\n",
    "                                                                       file_name=\"recon_tmp.csv\",\n",
    "                                                                       save_samples=True)# sample=np.array(samples[1]))\n",
    "print(\"reconstruction results:\", rederr, r_prob, rand_err)\n",
    "#-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dissonance array:    spkcom  colcom  libcom  spkmil  colmil  libmil  libhomo  libmslm  gunlaw  \\\n",
      "0     0.0     0.0     0.0     0.0     0.0     0.0      0.0      0.0     0.0   \n",
      "1     0.0     0.0     0.0     0.0     0.0     0.0      0.0      0.0     0.0   \n",
      "\n",
      "   grass  ...  shotgun  rowngun  viruses  intmil   abpoorw  godchnge  \\\n",
      "0    0.0  ...      0.0      0.0      0.0     0.0  0.000000  0.853822   \n",
      "1    0.0  ...      0.0      0.0      0.0     0.0  0.769949  0.916401   \n",
      "\n",
      "   prayfreq  religcon  religint  comfort  \n",
      "0  0.000000  0.000000  0.827436      0.0  \n",
      "1  0.960481  0.323764  0.000000      0.0  \n",
      "\n",
      "[2 rows x 35 columns]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "reconstruction results       rederr    r_prob  rand_err  \\\n",
      "0  24.686852  0.301528  0.668370   \n",
      "1  29.059197  0.290665  0.667205   \n",
      "\n",
      "                                               mask_  \n",
      "0  [wrkstat, wrkslf, wrkgovt, PRESTG105PLUS, SPHR...  \n",
      "1  [OCC10, spwrksta, SPHRS1, spwrkslf, SPIND10, C...  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ideology indices    ideology        dR        dL        d0\n",
      "0  0.027638  0.149831  0.146705  0.113117\n",
      "1  0.049753  0.148349  0.142721  0.113117\n",
      "2  0.099777  0.165402  0.154116  0.113117\n",
      "3  0.002329  0.152225  0.151962  0.113117\n",
      "4  0.087333  0.145235  0.135356  0.113117\n",
      "5  0.066173  0.151587  0.144102  0.113117\n",
      "6  0.003744  0.148248  0.147824  0.113117\n",
      "7  0.078467  0.143704  0.134828  0.113117\n",
      "8 -0.014116  0.143703  0.145299  0.113117\n",
      "9  0.109856  0.153365  0.140938  0.113117\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "dispersion array         Qsd      Qmax\n",
      "0  0.004916  0.035621\n",
      "1  0.004846  0.032769\n",
      "2  0.005288  0.037120\n",
      "3  0.005391  0.038372\n",
      "4  0.005271  0.039663\n",
      "5  0.005109  0.037444\n",
      "6  0.005299  0.036169\n",
      "7  0.005842  0.042696\n",
      "8  0.004885  0.034288\n",
      "9  0.006319  0.045186\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "polar distances array           R         L\n",
      "0  0.133419  0.138813\n",
      "1  0.131138  0.138176\n",
      "2  0.147701  0.155682\n",
      "3  0.139177  0.142951\n",
      "4  0.125565  0.134898\n",
      "5  0.135593  0.143826\n",
      "6  0.136802  0.137866\n",
      "7  0.122264  0.130302\n",
      "8  0.134717  0.136087\n",
      "9  0.128460  0.138303\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the following are for arrays of samples\n",
    "# multiprocessing suffices\n",
    "\n",
    "# set sammple sizeN\n",
    "Cg.set_nsamples(10)\n",
    "    \n",
    "# computing polar_indices makes sure that dissonance matrix only takes in polar cols\n",
    "Cg.compute_polar_indices()\n",
    "dissonance_array = Cg.dissonance_matrix(outfile='GSS/results/DISSONANCE_matrix.csv')\n",
    "print(\"dissonance array:\", dissonance_array[:2])\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# random mask and reconstruction\n",
    "recon_df = Cg.randomMaskReconstruction_multiple('GSS/results/randomMaskRecon_test.csv')\n",
    "print(\"reconstruction results\", recon_df[:2])\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# ideology indices\n",
    "ideology_index = Cg.compute_DLI_samples('ideology','GSS/results/ideology.csv')\n",
    "print(\"ideology indices\", ideology_index)\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# dispersion\n",
    "local_dispersion = Cg.compute_DLI_samples('dispersion', 'GSS/results/dispersion_test.csv')\n",
    "print(\"dispersion array\", local_dispersion)\n",
    "print('----------------------------------------------------------------------\\n')\n",
    "\n",
    "# polar distances\n",
    "polar_array = Cg.polarDistance_multiple('GSS/results/polarDistance_multiple_test.csv')\n",
    "print(\"polar distances array\",polar_array)\n",
    "print('----------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute qdistance matrix for small set of samples\n",
    "# set nsamples first to set the number of samples to be included in matrix\n",
    "Cg.MAX_PROCESSES = 2\n",
    "Cg.set_nsamples(30)\n",
    "distance_matrix=Cg.distfunc_multiples(\"GSS/results/distfunc_multiples_testing.csv\")\n",
    "print(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091232</td>\n",
       "      <td>0.134658</td>\n",
       "      <td>0.113836</td>\n",
       "      <td>0.086175</td>\n",
       "      <td>0.120154</td>\n",
       "      <td>0.079885</td>\n",
       "      <td>0.079909</td>\n",
       "      <td>0.126323</td>\n",
       "      <td>0.096016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.091232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108381</td>\n",
       "      <td>0.114186</td>\n",
       "      <td>0.079264</td>\n",
       "      <td>0.085646</td>\n",
       "      <td>0.086029</td>\n",
       "      <td>0.102618</td>\n",
       "      <td>0.098386</td>\n",
       "      <td>0.092799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.134658</td>\n",
       "      <td>0.108381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129788</td>\n",
       "      <td>0.120588</td>\n",
       "      <td>0.076976</td>\n",
       "      <td>0.130525</td>\n",
       "      <td>0.145231</td>\n",
       "      <td>0.111161</td>\n",
       "      <td>0.139336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.113836</td>\n",
       "      <td>0.114186</td>\n",
       "      <td>0.129788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109474</td>\n",
       "      <td>0.105337</td>\n",
       "      <td>0.127201</td>\n",
       "      <td>0.117701</td>\n",
       "      <td>0.093618</td>\n",
       "      <td>0.130243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086175</td>\n",
       "      <td>0.079264</td>\n",
       "      <td>0.120588</td>\n",
       "      <td>0.109474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101664</td>\n",
       "      <td>0.093314</td>\n",
       "      <td>0.075187</td>\n",
       "      <td>0.124169</td>\n",
       "      <td>0.066111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.120154</td>\n",
       "      <td>0.085646</td>\n",
       "      <td>0.076976</td>\n",
       "      <td>0.105337</td>\n",
       "      <td>0.101664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115825</td>\n",
       "      <td>0.126603</td>\n",
       "      <td>0.094520</td>\n",
       "      <td>0.124740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.079885</td>\n",
       "      <td>0.086029</td>\n",
       "      <td>0.130525</td>\n",
       "      <td>0.127201</td>\n",
       "      <td>0.093314</td>\n",
       "      <td>0.115825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094005</td>\n",
       "      <td>0.115584</td>\n",
       "      <td>0.110569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.079909</td>\n",
       "      <td>0.102618</td>\n",
       "      <td>0.145231</td>\n",
       "      <td>0.117701</td>\n",
       "      <td>0.075187</td>\n",
       "      <td>0.126603</td>\n",
       "      <td>0.094005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134604</td>\n",
       "      <td>0.067742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.126323</td>\n",
       "      <td>0.098386</td>\n",
       "      <td>0.111161</td>\n",
       "      <td>0.093618</td>\n",
       "      <td>0.124169</td>\n",
       "      <td>0.094520</td>\n",
       "      <td>0.115584</td>\n",
       "      <td>0.134604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.096016</td>\n",
       "      <td>0.092799</td>\n",
       "      <td>0.139336</td>\n",
       "      <td>0.130243</td>\n",
       "      <td>0.066111</td>\n",
       "      <td>0.124740</td>\n",
       "      <td>0.110569</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>0.136706</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.091232  0.134658  0.113836  0.086175  0.120154  0.079885   \n",
       "1  0.091232  0.000000  0.108381  0.114186  0.079264  0.085646  0.086029   \n",
       "2  0.134658  0.108381  0.000000  0.129788  0.120588  0.076976  0.130525   \n",
       "3  0.113836  0.114186  0.129788  0.000000  0.109474  0.105337  0.127201   \n",
       "4  0.086175  0.079264  0.120588  0.109474  0.000000  0.101664  0.093314   \n",
       "5  0.120154  0.085646  0.076976  0.105337  0.101664  0.000000  0.115825   \n",
       "6  0.079885  0.086029  0.130525  0.127201  0.093314  0.115825  0.000000   \n",
       "7  0.079909  0.102618  0.145231  0.117701  0.075187  0.126603  0.094005   \n",
       "8  0.126323  0.098386  0.111161  0.093618  0.124169  0.094520  0.115584   \n",
       "9  0.096016  0.092799  0.139336  0.130243  0.066111  0.124740  0.110569   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.079909  0.126323  0.096016  \n",
       "1  0.102618  0.098386  0.092799  \n",
       "2  0.145231  0.111161  0.139336  \n",
       "3  0.117701  0.093618  0.130243  \n",
       "4  0.075187  0.124169  0.066111  \n",
       "5  0.126603  0.094520  0.124740  \n",
       "6  0.094005  0.115584  0.110569  \n",
       "7  0.000000  0.134604  0.067742  \n",
       "8  0.134604  0.000000  0.136706  \n",
       "9  0.067742  0.136706  0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute qdistance matrix for small set of samples different from qnet samples\n",
    "samples = Cg.samples.iloc[:10]\n",
    "Cg.distfunc_multiples(\"GSS/results/distfunc_multiples_samplestesting.csv\", samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute qdistance matrix for small set of samples\n",
    "# set nsamples first to set the number of samples to be included in matrix\n",
    "distance_matrix=Cg.distfunc_multiples(\"GSS/results/distfunc_multiples_testing.csv\")\n",
    "print(\"local distance matrix:\", distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write files to compute qdistance matrix for large set of samples\n",
    "# execute generated shell script to run mpi parallelization on midway\n",
    "Cg.dmat_filewriter(\"GSS/GSS_cognet.py\", \"GSS/data/gss_2018.joblib\",\n",
    "                   MPI_SETUP_FILE=\"GSS/GSS_mpi_setup.sh\",\n",
    "                   MPI_RUN_FILE=\"GSS/GSS_mpi_run.sh\",\n",
    "                   MPI_LAUNCHER_FILE=\"GSS/GSS_mpi_launcher.sh\",\n",
    "                   YEARS='2018',NODES=4,T=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## embedding\n",
    "## embed generated Qdist Matrix\n",
    "Cg.year = '2018'\n",
    "Cg.embed('examples_results/distfunc_multiples_testing.csv', 'embed', 'examples_results/',EMBED_BINARY='cognet/cognet/bin/__embed__.so')\n",
    "#pd.read_csv('examples_results/embed_E_2018.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
