{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0b54cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from quasinet.qnet import qdistance, save_qnet\n",
    "from cognet.cognet import cognet as cg\n",
    "from cognet.dataFormatter import dataFormatter\n",
    "from cognet.model import model \n",
    "#import cognet.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d585f7be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## read in data, configure to Qnet specifications and fit Qnet model\n",
    "data_obj=dataFormatter(samples=\"data/PTSD_cognet_test_processed.csv\")\n",
    "features,samples = data_obj.Qnet_formatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a7a27b-194e-44fd-bc6d-30eda87ec0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = False\n",
    "model_obj = model()\n",
    "if fit:\n",
    "    model_obj.fit(data_obj=data_obj, njobs=2)\n",
    "    # model_obj.save(\"examples_results/PTSD_cognet_test.joblib\")\n",
    "    save_qnet(model_obj.myQnet, \"results/PTSD_cognet_test.joblib\", low_mem=False)\n",
    "else:\n",
    "    model_obj.load(\"results/PTSD_cognet_test.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9bd7198f-7e1b-4319-9f92-5718c5ebdd8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from quasinet.qnet import Qnet, qdistance, load_qnet, qdistance_matrix\n",
    "from quasinet.qsampling import qsample, targeted_qsample\n",
    "#from mpi4py.futures import MPIPoolExecutor\n",
    "import sys\n",
    "import subprocess\n",
    "from scipy.stats import entropy\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from cognet.util import embed_to_pca\n",
    "import pkgutil\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pqdm.threads import pqdm  \n",
    "\n",
    "class cognet:\n",
    "    \"\"\"Aggregate related Qnet functions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Init\n",
    "        \"\"\"\n",
    "        self.year = None\n",
    "        self.n_jobs = 28\n",
    "        self.qnet = None\n",
    "        self.steps = 120\n",
    "        self.num_qsamples = None\n",
    "        self.all_samples = None\n",
    "        self.samples = None\n",
    "        self.samples_as_strings = None\n",
    "        self.features = None\n",
    "        self.cols = None\n",
    "        self.immutable_vars = None\n",
    "        self.mutable_vars = None\n",
    "        self.poles = None\n",
    "        self.polar_features = None\n",
    "        self.polar_indices = None\n",
    "        self.poles_dict = {}\n",
    "        self.d0 = None\n",
    "        self.s_null = None\n",
    "        self.D_null = None\n",
    "        self.mask_prob = 0.5\n",
    "        self.variation_weight = None\n",
    "        self.polar_matrix = None\n",
    "        self.nsamples = None\n",
    "        self.restricted = False\n",
    "        self.MAX_PROCESSES = 0\n",
    "    \n",
    "    def load_from_model(self,\n",
    "                        model,\n",
    "                        data_obj,\n",
    "                        key,\n",
    "                        im_vars=None,\n",
    "                        m_vars=None):\n",
    "        \"\"\"load parameters from model object\n",
    "\n",
    "        Args:\n",
    "          model (Class): model obj for loading parameters\n",
    "          data_obj (class): instance of dataformatter class\n",
    "          key (str): 'all', 'train', or 'test', corresponding to sample type\n",
    "          im_vars (list[str], optional): Not implemented yet. Defaults to None.\n",
    "          m_vars (list[str], optional): Not implemented yet. Defaults to None.\n",
    "        \"\"\"\n",
    "        if model is not None:\n",
    "            # inherit atrributes from model object\n",
    "            self.qnet = model.myQnet\n",
    "            featurenames, samples = data_obj.format_samples(key)\n",
    "            samples = pd.DataFrame(samples)\n",
    "            self.cols = np.array(featurenames)\n",
    "            self.features = pd.DataFrame(columns=np.array(featurenames))\n",
    "            \n",
    "            # inherit mutable and immutable variables from model obj\n",
    "            if any(x is not None for x in [model.immutable_vars, model.mutable_vars]):\n",
    "                if model.immutable_vars is not None:\n",
    "                    self.immutable_vars = model.immutable_vars\n",
    "                    self.mutable_vars = [x for x in self.features if x not in self.immutable_vars]\n",
    "                elif model.mutable_vars is not None:\n",
    "                    self.mutable_vars = model.mutable_vars\n",
    "                    self.immutable_vars = [x for x in self.features if x not in self.mutable_vars]\n",
    "            else:\n",
    "                self.mutable_vars = self.features\n",
    "            \n",
    "            # inherit and set class attributes.\n",
    "            self.samples = pd.DataFrame(samples).replace(\"nan\",\"\").fillna(\"\")\n",
    "            self.samples.columns = np.array(featurenames)\n",
    "            self.all_samples = self.samples\n",
    "            self.samples_as_strings = self.samples.fillna('').values.astype(str)[:]\n",
    "            self.s_null=['']*len(self.samples_as_strings[0])\n",
    "            self.D_null=self.qnet.predict_distributions(self.s_null)\n",
    "            variation_weight = []\n",
    "            for d in self.D_null:\n",
    "                v=[]\n",
    "                for val in d.values():\n",
    "                    v=np.append(v,val)\n",
    "                variation_weight.append(entropy(v,base=len(v)))\n",
    "            variation_weight = np.nan_to_num(variation_weight) # remove nans\n",
    "            self.variation_weight = variation_weight\n",
    "    \n",
    "    def load_from_dataformatter(self, \n",
    "                                data_obj,\n",
    "                                key):\n",
    "        \"\"\"read in either train or test data, specified by key, from data obj,\n",
    "        and inherit other attributes.\n",
    "\n",
    "        Args:\n",
    "          data_obj (class): instance of dataformatter class\n",
    "          key (str): 'all', 'train', or 'test', corresponding to sample type\n",
    "          \n",
    "        Returns:\n",
    "          featurenames, samples: formatted arrays\n",
    "        \"\"\"\n",
    "        # inherit attributes from dataformatter object\n",
    "        featurenames, samples = data_obj.format_samples(key)\n",
    "        if any(x is not None for x in [self.features, self.samples]):\n",
    "            print(\"replacing original features/samples with dataformatter data\")\n",
    "        self.cols = featurenames\n",
    "        self.features = pd.DataFrame(columns=self.cols)\n",
    "        self.samples = pd.DataFrame(samples,columns=self.features)\n",
    "        self.all_samples = self.samples\n",
    "        self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "        self.s_null=['']*len(self.samples_as_strings[0])\n",
    "        return featurenames, samples\n",
    "\n",
    "    def load_data(self,\n",
    "                  year,\n",
    "                  features_by_year,\n",
    "                  samples,\n",
    "                  Qnet):\n",
    "        '''load cols, features, samples, and qnet.\n",
    "\n",
    "        Args:\n",
    "          year (str): to identify cols/features.\n",
    "          features_by_year (str): file containing all features by year of the dataset.\n",
    "          samples (str): file of samples for that year.\n",
    "          Qnet (str): Qnet file location.\n",
    "        '''\n",
    "        # set attributes from given files and data\n",
    "        self.qnet = load_qnet(qnet)\n",
    "        self.year = year\n",
    "        self.cols = np.array((pd.read_csv(features_by_year,\n",
    "                            keep_default_na=True, \n",
    "                            index_col=0).set_index(\n",
    "                                'year')).loc[int(year)].apply(\n",
    "                                    eval).values[0])\n",
    "        self.features = pd.DataFrame(columns=self.cols)\n",
    "        self.mutable_vars = [x for x in self.cols]\n",
    "        #[self.cols].fillna('').values.astype(str)[:]\n",
    "\n",
    "        # read in samples and initialize related attributes\n",
    "        self.samples=pd.read_csv(samples)\n",
    "        self.samples = pd.concat([self.samples,self.features], axis=0)\n",
    "        self.all_samples = self.samples\n",
    "        self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "        self.s_null=['']*len(self.samples_as_strings[0])\n",
    "        self.D_null=self.qnet.predict_distributions(self.s_null)\n",
    "        variation_weight = []\n",
    "        for d in self.D_null:\n",
    "            v=[]\n",
    "            for val in d.values():\n",
    "                v=np.append(v,val)\n",
    "            variation_weight.append(entropy(v,base=len(v)))\n",
    "        self.variation_weight = variation_weight\n",
    "\n",
    "    def set_immutable_vars(self,\n",
    "                        IMMUTABLE_FILE):\n",
    "        '''set vars to immutable and mutable, \n",
    "        can prob combine this with the load_data func: only set the immutable vars if necessary\n",
    "\n",
    "        Args:\n",
    "          IMMUTABLE_FILE (str): file containing the immutable features/vars\n",
    "        '''\n",
    "        # set mutable and immutable variable attributes \n",
    "        if self.cols is None:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "        self.immutable_vars = pd.read_csv(IMMUTABLE_FILE,index_col=0).transpose()\n",
    "        self.mutable_vars = None\n",
    "        self.mutable_vars = [x for x in self.cols\n",
    "                            if x.upper() not in self.immutable_vars.columns]\n",
    "    \n",
    "    def set_nsamples(self,\n",
    "                    num_samples,\n",
    "                    random=False):\n",
    "        '''select a subset of the samples\n",
    "\n",
    "        Args:\n",
    "          num_samples (int): Set num of samples to subset, default to None, resets to all samples\n",
    "          random (bool): take random sample if true, ordered sample if false\n",
    "        '''\n",
    "        # each time function is called, reset samples to use_all_samples\n",
    "        # this allows us to call nsamples numerous times \n",
    "        self.samples = self.all_samples\n",
    "        if self.samples is not None:\n",
    "            # if a greater number of sample is selected than available, raise error\n",
    "            if all(x is not None for x in [num_samples, self.samples]):\n",
    "                if num_samples > len(self.samples.index):\n",
    "                    string = 'The number of selected samples ({}) ' + \\\n",
    "                        'is greater than the number of samples ({})!'\n",
    "                    string = string.format(num_samples, len(self.samples.index))\n",
    "                    raise ValueError(string)\n",
    "\n",
    "                # if the same number of samples is selected as available, print warning\n",
    "                if num_samples == len(self.samples.index):\n",
    "                    string = 'The number of selected samples ({}) ' + \\\n",
    "                        'is equal to the number of samples ({})!'\n",
    "                    string = string.format(num_samples, len(self.samples.index))\n",
    "                    print(string)\n",
    "                    \n",
    "                # if random is true, return random sample, otherwise return an ordered slice\n",
    "                if random:\n",
    "                    self.samples = self.samples.sample(num_samples)\n",
    "                else:\n",
    "                    self.samples = self.samples.iloc[:num_samples]\n",
    "                self.nsamples = num_samples\n",
    "                self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "                \n",
    "            elif self.samples is None:\n",
    "                raise ValueError(\"load_data first!\")\n",
    "\n",
    "    def __variation_weight(self,\n",
    "                        index):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        d_=self.D_null[index]\n",
    "        v=[]\n",
    "        for val in d_.values():\n",
    "            v=np.append(v,val)\n",
    "        return entropy(v,base=len(v))\n",
    "    \n",
    "    def getBaseFrequency(self, \n",
    "                        sample):\n",
    "        '''get frequency of the variables\n",
    "        helper func for qsampling\n",
    "\n",
    "        Args:\n",
    "          sample (list[str]): vector of sample, must have the same num of features as the qnet\n",
    "        '''\n",
    "        # if variable is not mutable, set its base frequency to zero \n",
    "        MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()\n",
    "             \n",
    "        for m in self.mutable_vars:\n",
    "            MUTABLE[m]=1.0\n",
    "        mutable_x=MUTABLE.values[0]\n",
    "        base_frequency=mutable_x/mutable_x.sum()\n",
    "        \n",
    "        # otherwise, set base frequency weighted by variation weight\n",
    "        for i in range(len(base_frequency)):\n",
    "            if base_frequency[i]>0.0:\n",
    "                base_frequency[i]= self.variation_weight[i]*base_frequency[i]\n",
    "\n",
    "        return base_frequency/base_frequency.sum()\n",
    "    \n",
    "    def qsampling(self,\n",
    "                sample,\n",
    "                steps,\n",
    "                immutable=False):\n",
    "        '''perturb the sample based on the qnet distributions and number of steps\n",
    "\n",
    "        Args:\n",
    "          sample (1d array-like): sample vector, must have the same num of features as the qnet\n",
    "          steps (int): number of steps to qsample\n",
    "          immutable (bool): are there variables that are immutable?\n",
    "        '''\n",
    "        # immutable, check that mutable variables have been initialized\n",
    "        if immutable == True:\n",
    "            if all(x is not None for x in [self.mutable_vars, sample]):\n",
    "                return qsample(sample,self.qnet,steps,self.getBaseFrequency(self.samples))\n",
    "            elif self.mutable_vars is None:\n",
    "                raise ValueError(\"set mutable and immutable variables first!\")\n",
    "        else:\n",
    "            return qsample(sample,self.qnet,steps)\n",
    "\n",
    "    def random_sample(self,\n",
    "                      type=\"prob\",\n",
    "                      df=None,\n",
    "                      n=1,\n",
    "                      steps=200,\n",
    "                      n_jobs=3):\n",
    "        '''compute a random sample from the underlying distributions of the dataset, by column.\n",
    "        \n",
    "        \n",
    "        Args:\n",
    "          type (str): How to randomly draw samples. Can take on \"null\", \"uniform\", or \"prob\". Deafults to \"prob\".\n",
    "          df (pandas.DataFrame): Desired data to take random sample of. Defaults to None, in which case qnet samples are used.\n",
    "          n (int): number of random samples to take. Defaults to 1.\n",
    "          steps (int): number of steps to qsample. Defaults to 1000\n",
    "          \n",
    "        Returns:\n",
    "          return_df (pd.DataFrame): Drawn random sample.\n",
    "        '''\n",
    "        # check if a new dataset was given\n",
    "        if df is None:\n",
    "            samples_ = self.samples\n",
    "        else:\n",
    "            samples_ = df\n",
    "\n",
    "        return_df = pd.DataFrame()\n",
    "        # take random sample from each of the columns based on their probability distribution\n",
    "        if type == \"prob\":\n",
    "            for col in samples_.columns:\n",
    "                return_df[col] = samples_[col].sample(n=n, replace=True).values\n",
    "                \n",
    "        # random sampling using Qnet qsampling\n",
    "        elif type == \"null\":\n",
    "            null_array = np.zeros((len(samples_.columns),), dtype=str)\n",
    "            args = [[null_array, steps] for i in range(n)]\n",
    "            qsamples = pqdm(args, self.qsampling, n_jobs=n_jobs, argument_type='args') \n",
    "            \n",
    "            # for i in range(n):\n",
    "            #     qsamples.append(self.qsampling(null_array, steps))\n",
    "            return_df = pd.DataFrame(qsamples, columns=samples_.columns)\n",
    "            \n",
    "        # random sampling using uniform distribution of values by Columns\n",
    "        elif type == \"uniform\":\n",
    "            for col in samples_.columns:\n",
    "                # get unqiue values for each column and draw n values randomly\n",
    "                values = samples_[col].unique().astype(str)\n",
    "                return_df[col]=np.random.choice(values, size=n, replace=True)\n",
    "        else:\n",
    "            raise ValueError(\"Type is not supported!\")\n",
    "        return return_df\n",
    "    \n",
    "    def set_poles(self,\n",
    "                  POLEFILE,\n",
    "                  pole_1,\n",
    "                  pole_2,\n",
    "                  steps=0,\n",
    "                  mutable=False,\n",
    "                  VERBOSE=False,\n",
    "                  restrict=False,\n",
    "                  nsamples = None,\n",
    "                  random=False):\n",
    "        '''set the poles and samples such that the samples contain features in poles\n",
    "\n",
    "        Args:\n",
    "          steps (int): number of steps to qsample\n",
    "          POLEFILE (str): file containing poles samples and features\n",
    "          pole_1 (str): column name for first pole\n",
    "          pole_2 (str): column name for second pole\n",
    "          mutable (bool): Whether or not to set poles as the only mutable_vars\n",
    "          VERBOSE (bool): boolean flag prints number of pole features not found in sample features if True\n",
    "          restrict (bool): boolean flag restricts the sample features to polar features if True. Defaults to False.\n",
    "          random (bool): boolean flag takes random sample of all_samples\n",
    "        '''\n",
    "        invalid_count = 0\n",
    "        if all(x is not None for x in [self.samples, self.qnet]):\n",
    "            # read and set poles\n",
    "            poles = pd.read_csv(POLEFILE, index_col=0)\n",
    "            self.poles=poles.transpose()\n",
    "            self.polar_features = pd.concat([self.features, self.poles], axis=0).fillna('')\n",
    "            poles_dict = {}\n",
    "            for column in poles:\n",
    "                p_ = self.polar_features.loc[column][self.cols].fillna('').values.astype(str)[:]\n",
    "                # qsample poles to qnet\n",
    "                poles_dict[column] = self.qsampling(p_,steps)\n",
    "            self.poles_dict = poles_dict\n",
    "            self.pL = self.poles_dict[pole_1]\n",
    "            self.pR = self.poles_dict[pole_2]\n",
    "            self.d0 = qdistance(self.pL, self.pR, self.qnet, self.qnet)\n",
    "            \n",
    "            # restrict sample columns to polar columns\n",
    "            if restrict:\n",
    "                cols = [x for x in self.poles.columns if x in self.samples.columns]\n",
    "                self.samples=self.samples[cols]\n",
    "                self.restricted = True\n",
    "                self.samples = pd.concat([self.features,self.samples], axis=0).replace(\"nan\",\"\").fillna('')\n",
    "                self.samples_as_strings = self.samples[self.cols].fillna('').values.astype(str)[:]\n",
    "                \n",
    "            # if restrict==False, unrestrict it and set original\n",
    "            else:\n",
    "                self.restricted = False\n",
    "                self.samples = self.all_samples\n",
    "                if self.nsamples is not None:\n",
    "                    self.set_nsamples(nsamples, random)\n",
    "            \n",
    "            # identify pole features that were excluded due to sample features restriction\n",
    "            if VERBOSE:\n",
    "                for x in self.poles.columns:\n",
    "                    if x not in self.samples.columns:\n",
    "                        invalid_count += 1\n",
    "                        #self.samples[x]=''\n",
    "            \n",
    "            if mutable:\n",
    "                self.mutable_vars=[x for x in self.cols if x in self.poles.columns]\n",
    "        elif self.samples is None:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "\n",
    "        if VERBOSE:\n",
    "            print(\"{} pole features not found in sample features\".format(invalid_count))\n",
    "\n",
    "    def mp_compute(self, \n",
    "                   processes,\n",
    "                   func, \n",
    "                   cols,\n",
    "                   outfile, \n",
    "                   args=[]):\n",
    "        \"\"\"\n",
    "        Compute desired function through multiprocessing and save result to csv.\n",
    "\n",
    "        Args:\n",
    "          processes (int): number of processes to use.\n",
    "          func (func): function to compute using multiprocessing\n",
    "          cols (list): column names of resulting csv\n",
    "          outfile (str)): filepath + filename for resulting csv\n",
    "          args (list): list containing arguments for desired function. Defaults to empty list.\n",
    "        \"\"\"\n",
    "\n",
    "        # init mp.Manager and result dict\n",
    "        manager = mp.Manager()\n",
    "        return_dict = manager.dict()\n",
    "\n",
    "        # set processes as given, unless class parameter is set\n",
    "        max_processes = processes\n",
    "        if self.MAX_PROCESSES != 0:\n",
    "            max_processes = self.MAX_PROCESSES\n",
    "            print(\"Number of Processes {} has been set using class parameter\".format(self.MAX_PROCESSES))\n",
    "        num_processes = 0\n",
    "        process_list = []\n",
    "        \n",
    "        # init mp.Processes for each individual sample\n",
    "        # run once collected processes hit max\n",
    "        for i in range(len(self.samples)):\n",
    "            params = tuple([i, return_dict] + args)\n",
    "            num_processes += 1\n",
    "            p = mp.Process(target=func,\n",
    "                        args=params)\n",
    "            process_list.append(p)\n",
    "            if num_processes == max_processes:\n",
    "                [x.start() for x in process_list]\n",
    "                [x.join() for x in process_list]\n",
    "                process_list = []\n",
    "                num_processes = 0\n",
    "                \n",
    "        # compute remaining processes\n",
    "        if num_processes != 0:\n",
    "            [x.start() for x in process_list]\n",
    "            [x.join() for x in process_list]\n",
    "            process_list = []\n",
    "            num_processes = 0\n",
    "        \n",
    "        # format and save resulting dict\n",
    "        result = pd.DataFrame(return_dict.values(), columns=cols, index=return_dict.keys()).sort_index()\n",
    "        result.to_csv(outfile, index=None)\n",
    "        return result\n",
    "    \n",
    "    def distance(self,\n",
    "                sample1,\n",
    "                sample2,\n",
    "                nsteps1=0,\n",
    "                nsteps2=0):\n",
    "        \"\"\"qsamples each sample set num of steps, then takes qdistance\n",
    "\n",
    "        Args:\n",
    "          sample1 (list[str]): sample vector 1, must have the same num of features as the qnet\n",
    "          sample2 (list[str]): sample vector 2, must have the same num of features as the qnet\n",
    "          nsteps1 (int, optional): number of steps to qsample for sample1\n",
    "          nsteps2 (int, optional): number of steps to qsample for sample2\n",
    "\n",
    "        Returns:\n",
    "          qdistance: float, distance between two samples\n",
    "        \"\"\"\n",
    "        if self.qnet is None:\n",
    "            raise ValueError(\"load qnet first!\")\n",
    "        #bp1 = self.getBaseFrequency(sample1)\n",
    "        #bp2 = self.getBaseFrequency(sample2)\n",
    "        # qsample samples\n",
    "        sample1 = qsample(sample1, self.qnet, nsteps1)#, baseline_prob=bp1)\n",
    "        sample2 = qsample(sample2, self.qnet, nsteps2)#, baseline_prob=bp2)\n",
    "        return qdistance(sample1, sample2, self.qnet, self.qnet)\n",
    "    \n",
    "    def __distfunc(self, \n",
    "                   x, \n",
    "                   y):\n",
    "        '''Compute distance between two samples\n",
    "\n",
    "        Args:\n",
    "          x (list[str]): first sample\n",
    "          y (list[str]): second sample\n",
    "          \n",
    "        Returns:\n",
    "         d: qdistance\n",
    "        '''\n",
    "        d=qdistance(x,y,self.qnet,self.qnet)\n",
    "        return d\n",
    "    \n",
    "    def distfunc_line(self,\n",
    "                    i,\n",
    "                    return_dict=None):\n",
    "        '''compute the distance for a single sample against all other samples\n",
    "\n",
    "        Args:\n",
    "          i (int): row\n",
    "          return_dict (dict): dictionary containing multiprocessing results\n",
    "        \n",
    "        Return:\n",
    "          line: float, numpy.ndarray\n",
    "        '''\n",
    "        if all(x is not None for x in [self.samples, self.features]):\n",
    "            w = self.samples.index.size\n",
    "            line = np.zeros(w)\n",
    "            y = self.samples_as_strings[i]\n",
    "            for j in range(w):\n",
    "                # only compute half of the distance matrix\n",
    "                if j > i:\n",
    "                    x = self.samples_as_strings[j]\n",
    "                    line[j] = self.__distfunc(x, y)\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "        if return_dict is not None:\n",
    "            return_dict[i] = line\n",
    "        return line\n",
    "    \n",
    "    def distfunc_multiples(self,\n",
    "                           outfile,\n",
    "                           processes=6,\n",
    "                           samples=None):\n",
    "        \"\"\"compute distance matrix for all samples in the dataset\n",
    "\n",
    "        Args:\n",
    "          outfile (str): desired output filename and path\n",
    "          processes (int): Number of processes to run in parallel. Defaults to 6.\n",
    "          samples (2D array): Dataset from which to calculate qdist matrix. Defaults to None.\n",
    "          \n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing distance matrix\n",
    "        \"\"\"\n",
    "        if all(x is not None for x in [self.samples, self.features]):\n",
    "            # if exterior dataset is given, temporarily replace class attributes\n",
    "            if samples is not None:\n",
    "                original_samples = self.samples\n",
    "                original_samples_as_strings = self.samples_as_strings\n",
    "                self.samples = samples\n",
    "                samples = samples.fillna(\"\").values.astype(str)\n",
    "                self.samples_as_strings = samples\n",
    "            cols = [i for i in range(len(self.samples))]\n",
    "            result = self.mp_compute(processes,\n",
    "                                        self.distfunc_line,\n",
    "                                        cols,\n",
    "                                        outfile)\n",
    "            \n",
    "            # format and save resulting dict, and tranpose symmetrical distance matrix\n",
    "            result = result.to_numpy()\n",
    "            result = pd.DataFrame(np.maximum(result, result.transpose()))\n",
    "            result.to_csv(outfile, index=None, header=None)\n",
    "            \n",
    "            # replace class attributes with originals\n",
    "            if samples is not None:\n",
    "                self.samples = original_samples\n",
    "                self.samples_as_strings = original_samples_as_strings\n",
    "        else:\n",
    "            raise ValueError(\"load data first!\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def polarDistance(self,\n",
    "                    i,\n",
    "                    return_dict=None):\n",
    "        \"\"\"return the distances from a single sample to the poles\n",
    "\n",
    "        Args:\n",
    "          i (int): index of sample to take\n",
    "          return_dict (dict): dictionary containing multiprocessing results\n",
    "\n",
    "        Returns:\n",
    "          distances: float, distance from sample to each pole\n",
    "        \"\"\"\n",
    "        p = self.samples_as_strings[i]\n",
    "        distances = []\n",
    "        # calculate from each pole to the sample, and append to array\n",
    "        for index, row in self.polar_features[self.cols].iterrows():\n",
    "            row = row.fillna('').values.astype(str)[:]\n",
    "            distances.append(self.distance(p, np.array(row)))\n",
    "        if return_dict is not None:\n",
    "            return_dict[i] = distances\n",
    "        return distances\n",
    "            \n",
    "    def polarDistance_multiple(self,\n",
    "                               outfile,\n",
    "                               processes=6):\n",
    "        \"\"\"return the distance from all samples to the poles\n",
    "\n",
    "        Args:\n",
    "          outfile (str): desired output filename and path\n",
    "          \n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing polar distance results\n",
    "        \"\"\"\n",
    "        if all(x is not None for x in [self.samples, self.cols,\n",
    "                                    self.polar_features]):\n",
    "            # get the column names\n",
    "            pole_names = []\n",
    "            for index, row in self.polar_features[self.cols].iterrows():\n",
    "                pole_names.append(index)\n",
    "            result = self.mp_compute(processes,\n",
    "                                        self.polarDistance,\n",
    "                                        pole_names,\n",
    "                                        outfile)\n",
    "        else:\n",
    "            raise ValueError(\"load data first!\")\n",
    "        return result\n",
    "    \n",
    "    def polar_separation(self,\n",
    "                        nsteps=0):\n",
    "        \"\"\"calculates the distance between poles as a qdistance matrix\n",
    "\n",
    "        Args:\n",
    "          nsteps (int, optional): [description]. Defaults to 0.\n",
    "          \n",
    "        Returns:\n",
    "          self.polar_matrix: dictionary containing multiprocessing results\n",
    "        \"\"\"\n",
    "        # vectorize and qsample poles\n",
    "        polar_arraydata = self.polar_features[self.cols].values.astype(str)[:]\n",
    "        samples_ = []\n",
    "        for vector in polar_arraydata:\n",
    "            bp = self.getBaseFrequency(vector)\n",
    "            sample = qsample(vector, self.qnet, nsteps, baseline_prob=bp)\n",
    "            samples_.append(sample)\n",
    "        samples_ = np.array(samples_)\n",
    "        # calculate distance matrix for poles\n",
    "        self.polar_matrix = qdistance_matrix(samples_, samples_, self.qnet, self.qnet)\n",
    "        return self.polar_matrix\n",
    "        \n",
    "    def embed(self,\n",
    "            infile,\n",
    "            name_pref,\n",
    "            out_dir,\n",
    "            pca_model=False,\n",
    "            EMBED_BINARY=None):\n",
    "        '''\n",
    "        embed data\n",
    "\n",
    "        Args:\n",
    "          infile (str): input file to be embedded\n",
    "          name_pref (str): preferred name for output file\n",
    "          out_dir (str): output dir for results\n",
    "          pca_model (bool): whether or not to generate PCA model\n",
    "          EMBED_BINARY (os.path.abspath): path to embed binary\n",
    "        '''\n",
    "        # if all(x is not None for x in [self.year]):\n",
    "            # init file names \n",
    "        yr = ''\n",
    "        if self.year is not None:\n",
    "            yr = self.year\n",
    "        PREF = name_pref\n",
    "        FILE = infile\n",
    "        DATAFILE = out_dir + 'data_' +yr\n",
    "        EFILE = out_dir + PREF + '_E_' +yr\n",
    "        DFILE = out_dir + PREF + '_D_' +yr\n",
    "        \n",
    "        # set embed binary directory\n",
    "        if EMBED_BINARY is None:\n",
    "            EMBED = pkgutil.get_data(\"cognet.bin\", \"__embed__.so\") \n",
    "        else:\n",
    "            EMBED = EMBED_BINARY\n",
    "        \n",
    "        # embed data files\n",
    "        pd.read_csv(FILE, header=None).to_csv(DATAFILE,sep=' ',header=None,index=None)\n",
    "        STR=EMBED+' -f '+DATAFILE+' -E '+EFILE+' -D '+DFILE\n",
    "        subprocess.call(STR,shell=True)\n",
    "        if pca_model:\n",
    "            embed_to_pca(EFILE, EFILE+'_PCA')\n",
    "        # elif self.year is None:\n",
    "        #    raise ValueError(\"load_data first!\")\n",
    "    \n",
    "    def __calc_d0(self,\n",
    "                pole_1,\n",
    "                pole_2):\n",
    "        \"\"\"calculate distance between two poles\n",
    "\n",
    "        Args:\n",
    "          pole_1 (list[str]): a polar vector, must have same number of features as qnet\n",
    "          pole_2 (list[str]): a polar vector, must have same number of features as qnet\n",
    "        \"\"\"\n",
    "        self.pL = self.poles_dict[pole_1]\n",
    "        self.pR = self.poles_dict[pole_2]\n",
    "        self.d0 = qdistance(self.pL, self.pR, self.qnet, self.qnet)\n",
    "        \n",
    "    def ideology(self,\n",
    "                i,\n",
    "                return_dict=None,\n",
    "                pole_1=None,\n",
    "                pole_2=None):\n",
    "        \"\"\"return ideology index (left-leaning or right-leaning) for a singular sample\n",
    "\n",
    "        Args:\n",
    "          i (int): index of sample\n",
    "          pole_1 (int): index of Pole One to calc as base distance. Defaults to 0.\n",
    "          pole_2 (int): index of Pole Two to calc as base distance. Defaults to 1.\n",
    "          return_dict (dict, optional): dict containing results\n",
    "          \n",
    "        Returns:\n",
    "          [ideology_index, dR, dL, self.d0]: which way the sample leans,\n",
    "                                             distance from the right pole,\n",
    "                                             distance from the left pole,\n",
    "                                             and distance between poles, respectively\n",
    "        \"\"\"\n",
    "        # calculate base distance between two poles\n",
    "        if pole_1 is not None or pole_2 is not None:\n",
    "            self.__calc_d0(pole_1, pole_2)\n",
    "        \n",
    "        # calculate distances between sample and the two poles\n",
    "        p = self.samples_as_strings[i]\n",
    "        dR = qdistance(self.pR, p, self.qnet, self.qnet)\n",
    "        dL = qdistance(self.pL, p, self.qnet, self.qnet)\n",
    "        \n",
    "        ideology_index = (dR-dL)/self.d0\n",
    "        if return_dict is not None:\n",
    "            return_dict[i] = [ideology_index, dR, dL, self.d0]\n",
    "        return [ideology_index, dR, dL, self.d0]\n",
    "\n",
    "    def dispersion(self,\n",
    "                   i,\n",
    "                   return_dict=None):\n",
    "        \"\"\"qsamples a sample n times and takes distance matrix \n",
    "        to determine max and std of distances between qsamples\n",
    "\n",
    "        Args:\n",
    "          i (int): index of sample\n",
    "          return_dict (dict): dictionary containing multiprocessing results\n",
    "\n",
    "        Returns:\n",
    "          list[float]: std and max of the distances btwn qsamples\n",
    "        \"\"\"\n",
    "        # qsample sample num_qsample times\n",
    "        p = self.samples_as_strings[i]\n",
    "        Qset = [qsample(p, self.qnet, self.steps) for j in np.arange(self.num_qsamples)]\n",
    "        Qset = np.array(Qset)\n",
    "\n",
    "        # calculate qdistance matrix for qsampled samples\n",
    "        matrix = (qdistance_matrix(Qset, Qset, self.qnet, self.qnet))\n",
    "        Q = matrix.max()\n",
    "        Qsd = matrix.std()\n",
    "        \n",
    "        if return_dict is not None:\n",
    "            return_dict[i] = [Qsd, Q]\n",
    "        return [Qsd, Q]\n",
    "    \n",
    "    def compute_DLI_samples(self,\n",
    "                        type,\n",
    "                        outfile,\n",
    "                        num_qsamples=40,\n",
    "                        steps=120,\n",
    "                        n_jobs=28,\n",
    "                        pole_1=0,\n",
    "                        pole_2=1,\n",
    "                        processes=6):\n",
    "        \"\"\"compute and save ideology index or dispersion for all samples\n",
    "\n",
    "        Args:\n",
    "          num_qsamples (int): number of qsamples to compute\n",
    "          outfile (str): output file for results\n",
    "          type (str): whether to calc dispersion or ideology\n",
    "          steps (int): number of steps to qsample\n",
    "          n_jobs (int, optional): sets the number of jobs for parallelization. Defaults to 28.\n",
    "          pole_1 (int, optional): index of Pole One to calc as base distance. Defaults to 0.\n",
    "          pole_2 (int, optional): index of Pole Two to calc as base distance. Defaults to 1.\n",
    "\n",
    "        Raises:\n",
    "          ValueError: set poles if poles are not set\n",
    "          ValueError: load data if samples or features are not present\n",
    "            \n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing multiprocessing results\n",
    "        \"\"\"\n",
    "        if all(x is not None for x in [self.samples, self.features,\n",
    "                                    self.pL, self.pR]):\n",
    "            # init vars\n",
    "            self.num_qsamples = num_qsamples\n",
    "            self.steps = steps\n",
    "            if pole_1 != 0 or pole_2 != 1:\n",
    "                self.__calc_d0(pole_1, pole_2)\n",
    "            \n",
    "            if type == 'ideology':\n",
    "                func_ = self.ideology\n",
    "                cols=['ideology', 'dR', 'dL', 'd0']\n",
    "            elif type == 'dispersion':\n",
    "                func_ = self.dispersion\n",
    "                cols=['Qsd', 'Qmax']\n",
    "            else:\n",
    "                raise ValueError(\"Type must be either dispersion or ideology!\")\n",
    "            \n",
    "            result = self.mp_compute(processes,\n",
    "                                     func_,\n",
    "                                     cols,\n",
    "                                     outfile)\n",
    "        elif self.pL is None or self.pR is None:\n",
    "            raise ValueError(\"set_poles first!\")\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "        return result\n",
    "\n",
    "    def compute_polar_indices(self,\n",
    "                              num_samples=None,\n",
    "                              polar_comp=False,\n",
    "                              POLEFILE=None,\n",
    "                              steps=5):\n",
    "        '''set up polar indices for dissonance func\n",
    "\n",
    "        Args:\n",
    "          num_samples (int): subset of samples to take\n",
    "          polar_comp (bool): whether or not to set poles\n",
    "          POLEFILE (None): file containing pole samples and features\n",
    "          steps (int): number of steps to qsample\n",
    "        '''\n",
    "        if all(x is not None for x in [self.samples, self.features, self.poles]):\n",
    "            if num_samples is not None:\n",
    "                self.set_nsamples(num_samples)\n",
    "\n",
    "            if polar_comp:\n",
    "                self.set_poles(self.qnet, steps, POLEFILE)\n",
    "            \n",
    "            # calculate polar indices\n",
    "            polar_features = pd.concat([self.features, self.poles], axis=0)\n",
    "            self.polar_indices=np.where(polar_features[self.cols].fillna('XXXX').values[0]!='XXXX')[0]\n",
    "        \n",
    "        elif self.poles is None:\n",
    "            raise ValueError(\"set_poles first!\")\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "\n",
    "    def dissonance(self,\n",
    "                    sample_index=0,\n",
    "                    return_dict=None,\n",
    "                    MISSING_VAL=0.0,\n",
    "                    sample=None):\n",
    "        '''compute dissonance for a single sample, helper function for all_dissonance\n",
    "        \n",
    "        Args:\n",
    "          sample_index (int): index of the sample to compute dissonance. Defaults to 0.\n",
    "          return_dict (dict): dictionary containing multiprocessing results\n",
    "          MISSING_VAL (float): default dissonance value\n",
    "          sample (1D array): sample to compute dissonance of, instead of using sample index. Defaults to None.\n",
    "          \n",
    "        Returns: \n",
    "          diss[self.polar_indices]: ndarray containing dissonance for sample\n",
    "        '''\n",
    "        if all(x is not None for x in [self.samples, self.features]):\n",
    "            if sample is None:\n",
    "                s = self.samples_as_strings[sample_index]\n",
    "            else:\n",
    "                s = sample\n",
    "            if self.polar_indices is None:\n",
    "                self.polar_indices = range(len(s))\n",
    "\n",
    "            # init vars and calculate dissonance for sample\n",
    "            Ds=self.qnet.predict_distributions(s)\n",
    "            diss=np.ones(len(Ds))*MISSING_VAL\n",
    "            for i in self.polar_indices:\n",
    "                if s[i] != '':\n",
    "                    if s[i] in Ds[i].keys():\n",
    "                        diss[i]=1-Ds[i][s[i]]/np.max(\n",
    "                            list(Ds[i].values())) \n",
    "                    else:\n",
    "                        diss[i]=1.0\n",
    "            if return_dict is not None:\n",
    "                return_dict[sample_index] = diss[self.polar_indices]\n",
    "            return diss[self.polar_indices]\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "    \n",
    "    def dissonance_matrix(self,\n",
    "                        outfile='/example_results/DISSONANCE_matrix.csv',\n",
    "                        processes=6):\n",
    "        '''get the dissonance for all samples\n",
    "\n",
    "        Args:\n",
    "          output_file (str): directory and/or file for output\n",
    "          processes (int): max number of processes. Defaults to 6.\n",
    "\n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing dissonances for each sample\n",
    "        '''\n",
    "        # set columns\n",
    "        if self.polar_indices is not None:\n",
    "            polar_features = pd.concat([self.features, self.poles], axis=0)\n",
    "            cols = polar_features[self.cols].dropna(axis=1).columns\n",
    "        else:\n",
    "            cols = self.cols\n",
    "        \n",
    "        result = self.mp_compute(processes,\n",
    "                                    self.dissonance,\n",
    "                                    cols,\n",
    "                                    outfile)\n",
    "        return result\n",
    "    \n",
    "    def __choose_one(self,\n",
    "                X):\n",
    "        '''returns a random element of X\n",
    "\n",
    "        Args:\n",
    "          X (1D array-like): vector from which random element is to be chosen\n",
    "        \n",
    "        Returns:\n",
    "          X: random element of sample\n",
    "          None: if X has len 0\n",
    "        '''\n",
    "        X=list(X)\n",
    "        if len(X)>0:\n",
    "            return X[np.random.randint(len(X))]\n",
    "        return None\n",
    "\n",
    "    def getMaskedSample(self,\n",
    "                        s,\n",
    "                        mask_prob=0.5,\n",
    "                        allow_all_mutable=False):\n",
    "        '''inputs a sample and randomly mask elements of the sample\n",
    "\n",
    "        Args:\n",
    "          s (list[str]): vector of sample, must have the same num of features as the qnet.\n",
    "          mask_prob (float): float btwn 0 and 1, prob to mask element of sample. Defaults to 0.5\n",
    "          allow_all_mutable (bool): whether or not all variables are mutable. Defaults to False.\n",
    "          \n",
    "        Returns:\n",
    "          s1,\n",
    "          base_frequency,\n",
    "          MASKrand,\n",
    "          np.where(base_frequency)[0],\n",
    "          np.mean(rnd_match_prob),\n",
    "          np.mean(max_match_prob),\n",
    "          random_sample\n",
    "        '''\n",
    "        if self.samples is not None:\n",
    "            # init random mutable variable masking\n",
    "            s0=s.copy()\n",
    "            s0=np.array(s0)   \n",
    "            # double check, because code seems to imply that masking happens in order,\n",
    "            # i.e. limited to the first 100 features, if there are only 100 mutable features\n",
    "            MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()\n",
    "            WITHVAL=[x for x in self.cols[np.where(s0)[0]] if x in self.mutable_vars ]\n",
    "            MASKrand=[x for x in WITHVAL if random.random() < mask_prob ]\n",
    "            for m in MASKrand:\n",
    "                MUTABLE[m]=1.0\n",
    "            \n",
    "            mutable_x=MUTABLE.values[0]\n",
    "            base_frequency=mutable_x/mutable_x.sum()\n",
    "\n",
    "            # if np.isnan(base_frequency).any():\n",
    "            #     return np.nan,np.nan,np.nan\n",
    "            #     return self.getMaskedSample(s)\n",
    "\n",
    "            # mask sample according to masking (base_frequency)\n",
    "            s1=s.copy()\n",
    "            for i in range(len(base_frequency)):\n",
    "                if base_frequency[i]>0.0001:\n",
    "                    s1[i]=''\n",
    "                \n",
    "            # create a random sample to test reconstruction effectiveness\n",
    "            random_sample=np.copy(s)\n",
    "            rnd_match_prob=[]        \n",
    "            max_match_prob=[]        \n",
    "            D=self.qnet.predict_distributions(s)\n",
    "            for i in MASKrand:\n",
    "                random_sample[np.where(\n",
    "                    self.cols==i)[0][0]]=self.__choose_one(\n",
    "                        self.D_null[np.where(self.cols==i)[0][0]].keys())\n",
    "                    \n",
    "                rnd_match_prob=np.append(rnd_match_prob,1/len(\n",
    "                    self.D_null[np.where(self.cols==i)[0][0]].keys()))\n",
    "                \n",
    "                max_match_prob=np.append(\n",
    "                    max_match_prob,np.max(\n",
    "                        list(D[np.where(\n",
    "                            self.cols==i)[0][0]].values())))\n",
    "            \n",
    "            # calculate base_frequency if all variables are mutable\n",
    "            if allow_all_mutable:\n",
    "                WITHVAL=[x for x in self.cols[np.where(s0)[0]]]\n",
    "                MASKrand=[x for x in WITHVAL if random.random() < mask_prob ]\n",
    "                for m in MASKrand:\n",
    "                    MUTABLE[m]=1.0\n",
    "                mutable_x=MUTABLE.values[0]\n",
    "                base_frequency=mutable_x/mutable_x.sum()\n",
    "                s1=s.copy()\n",
    "                for i in range(len(base_frequency)):\n",
    "                    if base_frequency[i]>0.0001:\n",
    "                        s1[i]=''\n",
    "\n",
    "            return s1,base_frequency,MASKrand,np.where(\n",
    "                base_frequency)[0],np.mean(rnd_match_prob),np.mean(max_match_prob),random_sample\n",
    "        else:\n",
    "            raise ValueError(\"load_data first!\")\n",
    "\n",
    "    def randomMaskReconstruction(self,\n",
    "                                index=None,\n",
    "                                return_dict=None,\n",
    "                                sample=None,\n",
    "                                index_colname=\"feature_names\",\n",
    "                                output_dir=\"recon_results/\",\n",
    "                                file_name=\"recon_tmp.csv\",\n",
    "                                mask_prob=0.5,\n",
    "                                allow_all_mutable=False,\n",
    "                                save_samples=False,\n",
    "                                save_output=True):\n",
    "        \"\"\"reconstruct the masked sample by qsampling and comparing to original\n",
    "        set self.mask_prob and self.steps if needed\n",
    "\n",
    "        Args:\n",
    "          index (int): index of sample to take.\n",
    "          return_dict (dict): dictionary containing multiprocessing results. Defaults to None.\n",
    "          sample (list[str], optional): sample vector, must have the same num of features as the qnet. Defaults to None.\n",
    "          index_colname (str): column name for index. Defaults to \"feature_names\"\n",
    "          output_dir (str): directory name for output files. Defaults to \"recon_results/\".\n",
    "          file_name (str): base file name for output files Defaults to \"recon_tmp.csv\".\n",
    "          mask_prob (float): float btwn 0 and 1, prob to mask element of sample. Defaults to 0.5\n",
    "          allow_all_mutable (bool): whether or not all variables are mutable. Defaults to False.\n",
    "          save_samples (bool): whether to include sample vectors in the savefile. Defaults to False.\n",
    "          save_output (bool): whether or not to save output df to file. Defaults to True.\n",
    "\n",
    "        Raises:\n",
    "          ValueError: Neither sample or index were given\n",
    "          ValueError: Both sample and index were given\n",
    "          \n",
    "        Returns:\n",
    "          return_values:(1 - (dqestim/dactual))*100,\n",
    "                            rmatch_u,\n",
    "                            rmatch,\n",
    "                            s,\n",
    "                            qs,\n",
    "                            random_sample,\n",
    "                            mask_\n",
    "        \"\"\"\n",
    "        if all(x is None for x in [sample, index]):\n",
    "            raise ValueError(\"Must input either sample or index!\")\n",
    "        elif all(x is not None for x in [sample, index]):\n",
    "            raise ValueError(\"Must input either sample or index not both!\")\n",
    "        elif sample is not None:\n",
    "            s=sample#np.array(pd.DataFrame(sample).fillna('').values.astype(str)[:])\n",
    "        elif index is not None:\n",
    "            s=self.samples_as_strings[index]\n",
    "        \n",
    "        # calculate masked sample and get variables\n",
    "        s1,bp,mask_,maskindex,rmatch_u,rmatch,random_sample=self.getMaskedSample(s, \n",
    "                                                                        mask_prob=mask_prob,\n",
    "                                                                        allow_all_mutable=allow_all_mutable)\n",
    "        # if base_frequency is nan, set return_dict to nans\n",
    "        if np.isnan(bp).any():\n",
    "            return_dict[index] = np.nan,np.nan,np.nan\n",
    "            return np.nan,np.nan,np.nan\n",
    "        \n",
    "        # make directories\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "\n",
    "        # qsample sample and calculate distances between original vs qsampled and masked\n",
    "        qs=qsample(s1,self.qnet,self.steps,bp)\n",
    "        dqestim=qdistance(s,qs,self.qnet,self.qnet)\n",
    "        dmask=qdistance(s,s1,self.qnet,self.qnet)\n",
    "        \n",
    "        # format and save sample, qsample statistics and values\n",
    "        cmpf=pd.DataFrame([s,qs,random_sample],\n",
    "                          columns=self.cols,\n",
    "                          index=['sample','qsampled','random_sample'])[mask_].transpose()\n",
    "        cmpf.index.name= index_colname\n",
    "        if save_output:\n",
    "            file_name = file_name.replace(\"tmp\", str(index))\n",
    "            cmpf.to_csv(output_dir+file_name)\n",
    "            \n",
    "        if save_samples:\n",
    "            return_values = (1 - (dqestim/dmask))*100,rmatch_u,rmatch,mask_,s,qs,random_sample\n",
    "        else:\n",
    "            return_values = (1 - (dqestim/dmask))*100,rmatch_u,rmatch,mask_\n",
    "        \n",
    "        if return_dict is not None:\n",
    "            return_dict[index] = return_values\n",
    "            return return_dict[index]\n",
    "        return return_values\n",
    "\n",
    "    def randomMaskReconstruction_multiple(self,\n",
    "                                          outfile,\n",
    "                                          steps=200,\n",
    "                                          processes=6,\n",
    "                                          index_colname=\"feature_names\",\n",
    "                                          output_dir=\"recon_results/\",\n",
    "                                          file_name=\"recon_tmp.csv\",\n",
    "                                          mask_prob=0.5,\n",
    "                                          allow_all_mutable=False,\n",
    "                                          save_samples=False,\n",
    "                                          save_output=True):\n",
    "        '''runs and saves the results of the predicted masked sample\n",
    "\n",
    "        Args:\n",
    "          output_file (str): directory and/or file for output.\n",
    "          processes (int): max number of processes. Defaults to 6.\n",
    "          index_colname=\"feature_names\",\n",
    "          output_dir=\"recon_results/\",\n",
    "          file_name=\"recon_tmp.csv\",\n",
    "          mask_prob (float): float btwn 0 and 1, prob to mask element of sample. Defaults to 0.5\n",
    "          allow_all_mutable (bool): whether or not all variables are mutable. Defaults to False.\n",
    "          save_samples (boolean): whether or not to save the generated qsamples, random samples, etc. Defaults to False.\n",
    "          save_output (bool): whether or not to save output df to file. Defaults to True.\n",
    "          \n",
    "        Returns:\n",
    "          result: pandas.DataFrame containing masking and reconstruction results.\n",
    "        '''\n",
    "        # set columns for mp_compute\n",
    "        if save_samples:\n",
    "            cols = ['rederr','r_prob','rand_err','mask_','sample','qsampled','random_sample']\n",
    "        else:\n",
    "            cols = ['rederr','r_prob','rand_err','mask_']\n",
    "        \n",
    "        # update class steps\n",
    "        self.steps = steps\n",
    "        \n",
    "        # set args\n",
    "        args=[None, index_colname, output_dir,\n",
    "              file_name, mask_prob, allow_all_mutable, \n",
    "              save_samples, save_output]\n",
    "        \n",
    "        result = self.mp_compute(processes,\n",
    "                                    self.randomMaskReconstruction,\n",
    "                                    cols,\n",
    "                                    outfile,\n",
    "                                    args=args)\n",
    "        return result\n",
    "    \n",
    "    def dmat_filewriter(self,\n",
    "                        QNETPATH,\n",
    "                        mpi_path=\"mpi_tmp/\",\n",
    "                        pyfile=\"cognet_qdistmatrix.py\",\n",
    "                        MPI_SETUP_FILE=\"mpi_setup.sh\",\n",
    "                        MPI_RUN_FILE=\"mpi_run.sh\",\n",
    "                        MPI_LAUNCHER_FILE=\"../launcher.sh\",\n",
    "                        YEARS='2016',\n",
    "                        NODES=4,\n",
    "                        T=12,\n",
    "                        num_samples=None,\n",
    "                        OUTFILE='tmp_distmatrix.csv',\n",
    "                        tmp_samplesfile=\"tmp_samples_as_strings.csv\"):\n",
    "        \"\"\"generate files to compute qdistance matrix using mpi parallelization\n",
    "\n",
    "        Args:\n",
    "          QNETPATH (str): Qnet filepath\n",
    "          pyfile (str, optional): Name of generated python file. Defaults to \"cognet_qdistmatrix.py\".\n",
    "          MPI_SETUP_FILE (str, optional): Name of mpi setup script. Defaults to \"mpi_setup.sh\".\n",
    "          MPI_RUN_FILE (str, optional): Name of mpi run script. Defaults to \"mpi_run.sh\".\n",
    "          MPI_LAUNCHER_FILE (str, optional): Launcher script filepath. Defaults to \"launcher.sh\".\n",
    "          YEARS (str, optional): If looping by year, not currently implemented. Defaults to '2016'.\n",
    "          NODES (int, optional): Number of nodes to use. Defaults to 4.\n",
    "          T (int, optional): Number of hours to reserve nodes for. Defaults to 12.\n",
    "          num_samples ([type], optional): How many samples to take. Defaults to None.\n",
    "          OUTFILE (str, optional): CSV File to write computed qdist matrix. Defaults to 'tmp_distmatrix.csv'.\n",
    "          tmp_samplesfile (str, optional): CSV File to write samples as strings. Defaults to \"tmp_samples_as_strings.csv\".\n",
    "\n",
    "        Raises:\n",
    "            ValueError: load data if qnet, features, or samples are not present]\n",
    "        \"\"\"\n",
    "        if all(x is not None for x in [self.samples,self.features,\n",
    "                                       self.qnet, self.cols]):\n",
    "            if num_samples is not None:\n",
    "                self.set_nsamples(num_samples)\n",
    "            \n",
    "            # init and make tmp dir \n",
    "            tmp_path = mpi_path\n",
    "            if not os.path.exists(tmp_path):\n",
    "                os.makedirs(tmp_path)\n",
    "            \n",
    "            pd.DataFrame(self.samples_as_strings).to_csv(tmp_path+tmp_samplesfile, header=None, index=None)\n",
    "            \n",
    "            w = self.samples.index.size\n",
    "            \n",
    "            # writing python file\n",
    "            with open(tmp_path+pyfile, 'w+') as f:\n",
    "                f.writelines([\"from mpi4py.futures import MPIPoolExecutor\\n\",\n",
    "                              \"import numpy as np\\n\",\n",
    "                              \"import pandas as pd\\n\",\n",
    "                              \"from quasinet.qnet import Qnet, qdistance, load_qnet, qdistance_matrix\\n\",\n",
    "                              \"from quasinet.qsampling import qsample, targeted_qsample\\n\\n\",\n",
    "                              \"qnet=load_qnet(\\'{}\\')\\n\".format(QNETPATH)])\n",
    "\n",
    "                f.writelines([\"w = {}\\n\".format(w),\n",
    "                              \"h = w\\n\",\n",
    "                              \"p_all = pd.read_csv(\\\"{}\\\", header=None).values.astype(str)[:]\\n\\n\".format(tmp_samplesfile)])\n",
    "\n",
    "                f.writelines([\"def distfunc(x,y):\\n\",\n",
    "                              \"\\td=qdistance(x,y,qnet,qnet)\\n\",\n",
    "                              \"\\treturn d\\n\\n\"])\n",
    "\n",
    "                f.writelines([\"def dfunc_line(k):\\n\",\n",
    "                              \"\\tline = np.zeros(w)\\n\",\n",
    "                              \"\\ty = p_all[k]\\n\",\n",
    "                              \"\\tfor j in range(w):\\n\",\n",
    "                              \"\\t\\tif j > k:\\n\",\n",
    "                              \"\\t\\t\\tx = p_all[j]\\n\",\n",
    "                              \"\\t\\t\\tline[j] = distfunc(x, y)\\n\",\n",
    "                              \"\\treturn line\\n\\n\"])\n",
    "\n",
    "                f.writelines([\"if __name__ == '__main__':\\n\",\n",
    "                              \"\\twith MPIPoolExecutor() as executor:\\n\",\n",
    "                              \"\\t\\tresult = executor.map(dfunc_line, range(h))\\n\",\n",
    "                              \"\\tresult = pd.DataFrame(result)\\n\",\n",
    "\t                          \"\\tresult = result.to_numpy()\\n\",\n",
    "                              \"\\tresult = pd.DataFrame(np.maximum(result, result.transpose()))\\n\"\n",
    "                              \"\\tresult.to_csv(\\'{}\\',index=None,header=None)\".format(OUTFILE)])\n",
    "            \n",
    "            # writing MPI setup file\n",
    "            with open(tmp_path+MPI_SETUP_FILE, 'w+') as ms:\n",
    "                ms.writelines([\"#!/bin/bash\\n\",\n",
    "                               \"YEAR=$1\\n\\n\",\n",
    "                               \"if [ $# -gt 1 ] ; then\\n\",\n",
    "                               \"\\tNODES=$2\\n\",\n",
    "                               \"else\\n\",\n",
    "                               \"\\tNODES=3\\n\",\n",
    "                               \"fi\\n\",\n",
    "                               \"if [ $# -gt 2 ] ; then\\n\",\n",
    "                               \"\\tNUM=$3\\n\",\n",
    "                               \"else\\n\",\n",
    "                               \"\\tNUM='all'\\n\",\n",
    "                               \"fi\\n\",\n",
    "                               \"if [ $# -gt 3 ] ; then\\n\",\n",
    "                               \"\\tPROG=$4\\n\",\n",
    "                               \"else\\n\",\n",
    "                               \"\\tPROG=$(tty)\\n\",\n",
    "                               \"fi\\n\\n\",\n",
    "                               \"NUMPROC=`expr 28 \\* $NODES`\\n\",\n",
    "                               \"echo \\\"module load midway2\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module unload python\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module unload openmpi\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module load python/anaconda-2020.02\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"module load mpi4py\\\" >> $PROG\\n\",\n",
    "                               \"echo \\\"date; mpiexec -n \\\"$NUMPROC\\\" python3 -m mpi4py.futures {}; date\\\"  >> $PROG\\n\".format(pyfile),\n",
    "                                ])\n",
    "\n",
    "            # writing MPI run file\n",
    "            with open(tmp_path+MPI_RUN_FILE, 'w+') as mr:\n",
    "                mr.writelines([\"#!/bin/bash\\n\",\n",
    "                               \"YEARS=\\'{}\\'\\n\".format(YEARS),\n",
    "                               \"# nodes requested\\n\",\n",
    "                               \"NODES={}\\n\".format(NODES),\n",
    "                               \"# time requested\\n\",\n",
    "                               \"T={}\\n\".format(T),\n",
    "                               \"NUM=\\'all\\'\\n\",\n",
    "                               \"LAUNCH=./\\'{}\\'\\n\\n\".format(MPI_LAUNCHER_FILE),\n",
    "                               \"for yr in `echo $YEARS`\\n\",\n",
    "                               \"do\\n\",\n",
    "                               \"\\techo $yr\\n\",\n",
    "                               \"\\t./{} $yr $NODES $NUM tmp_\\\"$yr\\\"\\n\".format(MPI_SETUP_FILE),\n",
    "                               \"\\t$LAUNCH -P tmp_\\\"$yr\\\" -F -T $T -N \\\"$NODES\\\" -C 28 -p broadwl -J MPI_TMP_\\\"$yr\\\" -M 56\\n\",\n",
    "                               \"done\\n\",\n",
    "                               \"rm tmp_\\\"$yr\\\"*\\n\"])\n",
    "            os.system(\"cp {} {}\".format(MPI_LAUNCHER_FILE,tmp_path+'mpi_launcher.sh'))\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"load data first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "09ab5308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptsd1</th>\n",
       "      <th>ptsd2</th>\n",
       "      <th>ptsd3</th>\n",
       "      <th>ptsd4</th>\n",
       "      <th>ptsd5</th>\n",
       "      <th>ptsd6</th>\n",
       "      <th>ptsd7</th>\n",
       "      <th>ptsd8</th>\n",
       "      <th>ptsd9</th>\n",
       "      <th>ptsd10</th>\n",
       "      <th>...</th>\n",
       "      <th>ptsd202</th>\n",
       "      <th>ptsd203</th>\n",
       "      <th>ptsd204</th>\n",
       "      <th>ptsd205</th>\n",
       "      <th>ptsd206</th>\n",
       "      <th>ptsd207</th>\n",
       "      <th>ptsd208</th>\n",
       "      <th>ptsd209</th>\n",
       "      <th>ptsd210</th>\n",
       "      <th>ptsd211</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows  211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ptsd1 ptsd2 ptsd3 ptsd4 ptsd5 ptsd6 ptsd7 ptsd8 ptsd9 ptsd10  ... ptsd202  \\\n",
       "0       4     2     5     4     2     3     2     3     3      2  ...       2   \n",
       "1       3     2     3     3     1     3     2     2     2      1  ...       3   \n",
       "2       2     2     2     4     1     3     3     2     2      4  ...       4   \n",
       "3       2     2     5     1     3     2     1     2     2      1  ...       1   \n",
       "4       4     1     1     1     2     2     1     1     1      2  ...       2   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...     ...   \n",
       "299     4     2     3     4     1     1     1     1     3      2  ...       2   \n",
       "300     5     2     2     4     4     3     2     5     4      4  ...       5   \n",
       "301     5     1     2     1     1     3     5     5     3      4  ...       4   \n",
       "302     2     1     3     3     1     2     2     2     1      1  ...       1   \n",
       "303     5     2     1     1     1     1     1     1     1      1  ...       2   \n",
       "\n",
       "    ptsd203 ptsd204 ptsd205 ptsd206 ptsd207 ptsd208 ptsd209 ptsd210 ptsd211  \n",
       "0         4       4       3       2       3       2       2       4       2  \n",
       "1         4       4       3       3       3       4       3       4       5  \n",
       "2         2       2       4       4       2       3       2       2       5  \n",
       "3         2       3       3       3       2       1       1       2       2  \n",
       "4         2       2       2       1       1       2       2       2       3  \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "299       2       2       2       2       2       2       2       2       3  \n",
       "300       5       5       5       4       5       5       4       4       5  \n",
       "301       3       3       2       3       1       3       2       5       5  \n",
       "302       1       1       1       1       2       2       2       2       2  \n",
       "303       2       1       2       1       1       2       2       1       4  \n",
       "\n",
       "[304 rows x 211 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load Qnet, write mpi files for distance matrix\n",
    "# run qdistance matrix with \"./mpi_run.sh\" command\n",
    "cognet_obj = cognet()\n",
    "cognet_obj.load_from_model(model_obj, data_obj, 'all')\n",
    "cognet_obj.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f566fea-8a02-48ac-8864-e6d0a7f61b78",
   "metadata": {},
   "source": [
    "# Compute dissonance and random mask reconstruction for Qnet samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e04b2205",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of selected samples (304) is equal to the number of samples (304)!\n",
      "___________________________________________________\n",
      "The number of selected samples (304) is equal to the number of samples (304)!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rederr</th>\n",
       "      <th>r_prob</th>\n",
       "      <th>rand_err</th>\n",
       "      <th>mask_</th>\n",
       "      <th>sample</th>\n",
       "      <th>qsampled</th>\n",
       "      <th>random_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.889835</td>\n",
       "      <td>0.216514</td>\n",
       "      <td>0.377956</td>\n",
       "      <td>[ptsd3, ptsd4, ptsd5, ptsd6, ptsd7, ptsd8, pts...</td>\n",
       "      <td>[4, 2, 5, 4, 2, 3, 2, 3, 3, 2, 3, 2, 4, 3, 3, ...</td>\n",
       "      <td>[4, 2, 4, 4, , 2, 2, 5, 3, 3, 3, 2, 1, 3, 3, 2...</td>\n",
       "      <td>[4, 2, 2, 3, 2, 4, 1, 3, 3, 4, 3, 2, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.882595</td>\n",
       "      <td>0.218269</td>\n",
       "      <td>0.410304</td>\n",
       "      <td>[ptsd1, ptsd6, ptsd7, ptsd8, ptsd10, ptsd11, p...</td>\n",
       "      <td>[3, 2, 3, 3, 1, 3, 2, 2, 2, 1, 3, 1, 2, 2, 2, ...</td>\n",
       "      <td>[4, 2, 3, 3, 1, 2, , 5, 2, 3, 2, 3, 2, 2, 2, 3...</td>\n",
       "      <td>[4, 2, 3, 3, 1, 4, 4, 4, 2, 3, 2, 4, 2, 2, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.501801</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.388399</td>\n",
       "      <td>[ptsd1, ptsd2, ptsd4, ptsd6, ptsd9, ptsd11, pt...</td>\n",
       "      <td>[2, 2, 2, 4, 1, 3, 3, 2, 2, 4, 4, 3, 3, 3, 3, ...</td>\n",
       "      <td>[5, 1, 2, 1, 1, , 3, 2, 3, 4, 1, 3, 3, 3, 1, 2...</td>\n",
       "      <td>[4, 1, 2, 1, 1, 4, 3, 2, 1, 4, 2, 3, 3, 3, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.002608</td>\n",
       "      <td>0.221028</td>\n",
       "      <td>0.445630</td>\n",
       "      <td>[ptsd1, ptsd4, ptsd6, ptsd7, ptsd9, ptsd12, pt...</td>\n",
       "      <td>[2, 2, 5, 1, 3, 2, 1, 2, 2, 1, 2, 3, 3, 3, 3, ...</td>\n",
       "      <td>[5, 2, 5, 3, 3, 4, 3, 2, 3, 1, 2, 1, 1, 3, 2, ...</td>\n",
       "      <td>[4, 2, 5, 3, 3, 2, 2, 2, 1, 1, 2, 3, 5, 3, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.904224</td>\n",
       "      <td>0.217708</td>\n",
       "      <td>0.449331</td>\n",
       "      <td>[ptsd1, ptsd2, ptsd3, ptsd5, ptsd6, ptsd8, pts...</td>\n",
       "      <td>[4, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 3, 3, 1, ...</td>\n",
       "      <td>[5, 1, 1, 1, 1, , 1, 1, 1, 2, 1, 1, 2, 3, 3, 1...</td>\n",
       "      <td>[4, 1, 2, 1, 1, 1, 1, 3, 1, 2, 4, 1, 4, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>56.671276</td>\n",
       "      <td>0.221698</td>\n",
       "      <td>0.408178</td>\n",
       "      <td>[ptsd1, ptsd5, ptsd7, ptsd10, ptsd11, ptsd14, ...</td>\n",
       "      <td>[4, 2, 3, 4, 1, 1, 1, 1, 3, 2, 1, 1, 2, 2, 2, ...</td>\n",
       "      <td>[4, 2, 3, 4, 2, 1, , 1, 3, 4, 3, 1, 2, 1, 3, 2...</td>\n",
       "      <td>[4, 2, 3, 4, 1, 1, 4, 1, 3, 1, 2, 1, 2, 3, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>46.516036</td>\n",
       "      <td>0.218860</td>\n",
       "      <td>0.403780</td>\n",
       "      <td>[ptsd1, ptsd4, ptsd7, ptsd8, ptsd9, ptsd10, pt...</td>\n",
       "      <td>[5, 2, 2, 4, 4, 3, 2, 5, 4, 4, 4, 3, 4, 5, 5, ...</td>\n",
       "      <td>[4, 2, 2, 4, 4, 3, , 5, 4, 4, 3, 3, 4, 2, 5, 2...</td>\n",
       "      <td>[4, 2, 2, 3, 4, 3, 4, 4, 1, 3, 4, 3, 4, 2, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>39.886438</td>\n",
       "      <td>0.218056</td>\n",
       "      <td>0.429076</td>\n",
       "      <td>[ptsd3, ptsd5, ptsd6, ptsd9, ptsd11, ptsd12, p...</td>\n",
       "      <td>[5, 1, 2, 1, 1, 3, 5, 5, 3, 4, 2, 2, 3, 3, 4, ...</td>\n",
       "      <td>[5, 1, 2, 1, 1, 2, 5, 5, 2, 4, 4, 1, 3, 3, 2, ...</td>\n",
       "      <td>[5, 1, 2, 1, 1, 2, 5, 5, 2, 4, 2, 3, 3, 3, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>37.231134</td>\n",
       "      <td>0.216827</td>\n",
       "      <td>0.422792</td>\n",
       "      <td>[ptsd1, ptsd4, ptsd5, ptsd7, ptsd8, ptsd9, pts...</td>\n",
       "      <td>[2, 1, 3, 3, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[5, 1, 3, 3, 1, 2, 3, 3, 2, 1, 2, 4, 2, 2, 2, ...</td>\n",
       "      <td>[4, 1, 3, 3, 2, 2, 2, 1, 3, 1, 2, 4, 4, 3, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>34.808996</td>\n",
       "      <td>0.219196</td>\n",
       "      <td>0.468654</td>\n",
       "      <td>[ptsd5, ptsd7, ptsd8, ptsd10, ptsd11, ptsd15, ...</td>\n",
       "      <td>[5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, ...</td>\n",
       "      <td>[5, 2, 1, 1, 1, 1, 2, 2, 1, 1, 4, 2, 1, 1, 5, ...</td>\n",
       "      <td>[5, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 3, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rederr    r_prob  rand_err  \\\n",
       "0    51.889835  0.216514  0.377956   \n",
       "1    45.882595  0.218269  0.410304   \n",
       "2    39.501801  0.216500  0.388399   \n",
       "3    45.002608  0.221028  0.445630   \n",
       "4    48.904224  0.217708  0.449331   \n",
       "..         ...       ...       ...   \n",
       "299  56.671276  0.221698  0.408178   \n",
       "300  46.516036  0.218860  0.403780   \n",
       "301  39.886438  0.218056  0.429076   \n",
       "302  37.231134  0.216827  0.422792   \n",
       "303  34.808996  0.219196  0.468654   \n",
       "\n",
       "                                                 mask_  \\\n",
       "0    [ptsd3, ptsd4, ptsd5, ptsd6, ptsd7, ptsd8, pts...   \n",
       "1    [ptsd1, ptsd6, ptsd7, ptsd8, ptsd10, ptsd11, p...   \n",
       "2    [ptsd1, ptsd2, ptsd4, ptsd6, ptsd9, ptsd11, pt...   \n",
       "3    [ptsd1, ptsd4, ptsd6, ptsd7, ptsd9, ptsd12, pt...   \n",
       "4    [ptsd1, ptsd2, ptsd3, ptsd5, ptsd6, ptsd8, pts...   \n",
       "..                                                 ...   \n",
       "299  [ptsd1, ptsd5, ptsd7, ptsd10, ptsd11, ptsd14, ...   \n",
       "300  [ptsd1, ptsd4, ptsd7, ptsd8, ptsd9, ptsd10, pt...   \n",
       "301  [ptsd3, ptsd5, ptsd6, ptsd9, ptsd11, ptsd12, p...   \n",
       "302  [ptsd1, ptsd4, ptsd5, ptsd7, ptsd8, ptsd9, pts...   \n",
       "303  [ptsd5, ptsd7, ptsd8, ptsd10, ptsd11, ptsd15, ...   \n",
       "\n",
       "                                                sample  \\\n",
       "0    [4, 2, 5, 4, 2, 3, 2, 3, 3, 2, 3, 2, 4, 3, 3, ...   \n",
       "1    [3, 2, 3, 3, 1, 3, 2, 2, 2, 1, 3, 1, 2, 2, 2, ...   \n",
       "2    [2, 2, 2, 4, 1, 3, 3, 2, 2, 4, 4, 3, 3, 3, 3, ...   \n",
       "3    [2, 2, 5, 1, 3, 2, 1, 2, 2, 1, 2, 3, 3, 3, 3, ...   \n",
       "4    [4, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 3, 3, 1, ...   \n",
       "..                                                 ...   \n",
       "299  [4, 2, 3, 4, 1, 1, 1, 1, 3, 2, 1, 1, 2, 2, 2, ...   \n",
       "300  [5, 2, 2, 4, 4, 3, 2, 5, 4, 4, 4, 3, 4, 5, 5, ...   \n",
       "301  [5, 1, 2, 1, 1, 3, 5, 5, 3, 4, 2, 2, 3, 3, 4, ...   \n",
       "302  [2, 1, 3, 3, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, ...   \n",
       "303  [5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, ...   \n",
       "\n",
       "                                              qsampled  \\\n",
       "0    [4, 2, 4, 4, , 2, 2, 5, 3, 3, 3, 2, 1, 3, 3, 2...   \n",
       "1    [4, 2, 3, 3, 1, 2, , 5, 2, 3, 2, 3, 2, 2, 2, 3...   \n",
       "2    [5, 1, 2, 1, 1, , 3, 2, 3, 4, 1, 3, 3, 3, 1, 2...   \n",
       "3    [5, 2, 5, 3, 3, 4, 3, 2, 3, 1, 2, 1, 1, 3, 2, ...   \n",
       "4    [5, 1, 1, 1, 1, , 1, 1, 1, 2, 1, 1, 2, 3, 3, 1...   \n",
       "..                                                 ...   \n",
       "299  [4, 2, 3, 4, 2, 1, , 1, 3, 4, 3, 1, 2, 1, 3, 2...   \n",
       "300  [4, 2, 2, 4, 4, 3, , 5, 4, 4, 3, 3, 4, 2, 5, 2...   \n",
       "301  [5, 1, 2, 1, 1, 2, 5, 5, 2, 4, 4, 1, 3, 3, 2, ...   \n",
       "302  [5, 1, 3, 3, 1, 2, 3, 3, 2, 1, 2, 4, 2, 2, 2, ...   \n",
       "303  [5, 2, 1, 1, 1, 1, 2, 2, 1, 1, 4, 2, 1, 1, 5, ...   \n",
       "\n",
       "                                         random_sample  \n",
       "0    [4, 2, 2, 3, 2, 4, 1, 3, 3, 4, 3, 2, 3, 3, 3, ...  \n",
       "1    [4, 2, 3, 3, 1, 4, 4, 4, 2, 3, 2, 4, 2, 2, 4, ...  \n",
       "2    [4, 1, 2, 1, 1, 4, 3, 2, 1, 4, 2, 3, 3, 3, 5, ...  \n",
       "3    [4, 2, 5, 3, 3, 2, 2, 2, 1, 1, 2, 3, 5, 3, 4, ...  \n",
       "4    [4, 1, 2, 1, 1, 1, 1, 3, 1, 2, 4, 1, 4, 3, 3, ...  \n",
       "..                                                 ...  \n",
       "299  [4, 2, 3, 4, 1, 1, 4, 1, 3, 1, 2, 1, 2, 3, 5, ...  \n",
       "300  [4, 2, 2, 3, 4, 3, 4, 4, 1, 3, 4, 3, 4, 2, 5, ...  \n",
       "301  [5, 1, 2, 1, 1, 2, 5, 5, 2, 4, 2, 3, 3, 3, 5, ...  \n",
       "302  [4, 1, 3, 3, 2, 2, 2, 1, 3, 1, 2, 4, 4, 3, 2, ...  \n",
       "303  [5, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 3, ...  \n",
       "\n",
       "[304 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute dissonance matrix of qnet samples\n",
    "cognet_obj.set_nsamples(304)\n",
    "return_dict = cognet_obj.dissonance_matrix(outfile=\"mpi_tmp/PTSD_dissonance_matrix.csv\", processes=2)\n",
    "return_dict\n",
    "qnet_dissonance_df=pd.DataFrame(return_dict.copy())\n",
    "\n",
    "# computing random mask reconstruction of qnet samples\n",
    "print(\"___________________________________________________\")\n",
    "cognet_obj.set_nsamples(304)\n",
    "qnet_randommask_df = cognet_obj.randomMaskReconstruction_multiple('results/PTSD_randomMaskRecon_test.csv',  save_samples=True)\n",
    "qnet_randommask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a2d152-efdf-4729-b431-ff3adf379467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________\n",
      "The number of selected samples (304) is equal to the number of samples (304)!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rederr</th>\n",
       "      <th>r_prob</th>\n",
       "      <th>rand_err</th>\n",
       "      <th>mask_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.494799</td>\n",
       "      <td>0.217593</td>\n",
       "      <td>0.384213</td>\n",
       "      <td>[ptsd3, ptsd5, ptsd7, ptsd9, ptsd10, ptsd12, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.086574</td>\n",
       "      <td>0.219919</td>\n",
       "      <td>0.427794</td>\n",
       "      <td>[ptsd1, ptsd2, ptsd3, ptsd5, ptsd6, ptsd8, pts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.950114</td>\n",
       "      <td>0.217826</td>\n",
       "      <td>0.401986</td>\n",
       "      <td>[ptsd5, ptsd6, ptsd11, ptsd12, ptsd13, ptsd17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.819036</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.456392</td>\n",
       "      <td>[ptsd2, ptsd3, ptsd4, ptsd12, ptsd13, ptsd15, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.858806</td>\n",
       "      <td>0.217021</td>\n",
       "      <td>0.465767</td>\n",
       "      <td>[ptsd1, ptsd2, ptsd5, ptsd6, ptsd11, ptsd14, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>35.815801</td>\n",
       "      <td>0.218367</td>\n",
       "      <td>0.394428</td>\n",
       "      <td>[ptsd2, ptsd5, ptsd8, ptsd12, ptsd13, ptsd14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>25.029084</td>\n",
       "      <td>0.218627</td>\n",
       "      <td>0.401497</td>\n",
       "      <td>[ptsd2, ptsd4, ptsd6, ptsd7, ptsd8, ptsd10, pt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>50.955039</td>\n",
       "      <td>0.218932</td>\n",
       "      <td>0.408963</td>\n",
       "      <td>[ptsd1, ptsd2, ptsd4, ptsd9, ptsd12, ptsd13, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>52.630869</td>\n",
       "      <td>0.216981</td>\n",
       "      <td>0.417414</td>\n",
       "      <td>[ptsd5, ptsd7, ptsd8, ptsd9, ptsd10, ptsd11, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>41.709253</td>\n",
       "      <td>0.218878</td>\n",
       "      <td>0.468554</td>\n",
       "      <td>[ptsd1, ptsd3, ptsd4, ptsd5, ptsd6, ptsd8, pts...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rederr    r_prob  rand_err  \\\n",
       "0    52.494799  0.217593  0.384213   \n",
       "1    50.086574  0.219919  0.427794   \n",
       "2    41.950114  0.217826  0.401986   \n",
       "3    41.819036  0.218750  0.456392   \n",
       "4    36.858806  0.217021  0.465767   \n",
       "..         ...       ...       ...   \n",
       "299  35.815801  0.218367  0.394428   \n",
       "300  25.029084  0.218627  0.401497   \n",
       "301  50.955039  0.218932  0.408963   \n",
       "302  52.630869  0.216981  0.417414   \n",
       "303  41.709253  0.218878  0.468554   \n",
       "\n",
       "                                                 mask_  \n",
       "0    [ptsd3, ptsd5, ptsd7, ptsd9, ptsd10, ptsd12, p...  \n",
       "1    [ptsd1, ptsd2, ptsd3, ptsd5, ptsd6, ptsd8, pts...  \n",
       "2    [ptsd5, ptsd6, ptsd11, ptsd12, ptsd13, ptsd17,...  \n",
       "3    [ptsd2, ptsd3, ptsd4, ptsd12, ptsd13, ptsd15, ...  \n",
       "4    [ptsd1, ptsd2, ptsd5, ptsd6, ptsd11, ptsd14, p...  \n",
       "..                                                 ...  \n",
       "299  [ptsd2, ptsd5, ptsd8, ptsd12, ptsd13, ptsd14, ...  \n",
       "300  [ptsd2, ptsd4, ptsd6, ptsd7, ptsd8, ptsd10, pt...  \n",
       "301  [ptsd1, ptsd2, ptsd4, ptsd9, ptsd12, ptsd13, p...  \n",
       "302  [ptsd5, ptsd7, ptsd8, ptsd9, ptsd10, ptsd11, p...  \n",
       "303  [ptsd1, ptsd3, ptsd4, ptsd5, ptsd6, ptsd8, pts...  \n",
       "\n",
       "[304 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cognet_obj.steps = 200\n",
    "# computing random mask reconstruction of qnet samples\n",
    "print(\"___________________________________________________\")\n",
    "cognet_obj.set_nsamples(304)\n",
    "qnet_randommask_df_200step = cognet_obj.randomMaskReconstruction_multiple('results/PTSD_randomMaskRecon_test.csv',  save_samples=False)\n",
    "qnet_randommask_df_200step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07a067e-86ef-4393-a382-612c14157d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine the reconstruction error for PTSD\n",
    "samples=[]\n",
    "for s in qnet_randommask_df['sample']:\n",
    "    samples.append(list(s))\n",
    "qnet_randommask_samples=pd.DataFrame(data=samples, columns=features, dtype='int').astype(int)\n",
    "qnet_randommask_samples\n",
    "\n",
    "qsamples=[]\n",
    "for s in qnet_randommask_df['qsampled']:\n",
    "    qsamples.append(list(s))\n",
    "qnet_randommask_qsamples=pd.DataFrame(data=qsamples, columns=features, dtype='int').replace('',0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d70a3c-0849-4c45-a42e-fc566c9ee5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = qnet_randommask_samples - qnet_randommask_qsamples\n",
    "diff_df[\"diff sum\"] = diff_df.sum(axis=1)\n",
    "num_masked = pd.DataFrame([len(list(s)) for s in qnet_randommask_df['mask_']], columns=[\"num masked\"])\n",
    "diff_df[\"num masked\"] = num_masked\n",
    "diff_df[\"recon_results\"] = diff_df[\"diff sum\"] / diff_df[\"num masked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70956bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnet_dissonance_df.mean(axis=1).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d891d18-8b88-4342-a513-a70e9b05d9e5",
   "metadata": {},
   "source": [
    "# Compute dissonance and random mask reconstruction for random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97accab-b6b9-4132-953e-1b615a5d1859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# computing dissonance of random samples\n",
    "print(\"___________________________________________________\")\n",
    "n=304\n",
    "random_samples = cognet_obj.random_sample(n=n)\n",
    "print(\"{} random samples computed\".format(n))\n",
    "random_samples_strings = random_samples.values.astype(str)\n",
    "results = []\n",
    "for s in random_samples_strings:\n",
    "    results.append(cognet_obj.dissonance(0, sample=s))\n",
    "random_dissonance_df = pd.DataFrame(results)\n",
    "random_dissonance_df.mean(axis=1).hist()\n",
    "\n",
    "# computing random mask reconstruction of random samples\n",
    "print(\"___________________________________________________\")\n",
    "random_samples_strings = random_samples.values.astype(str)\n",
    "results = []\n",
    "for s in random_samples_strings:\n",
    "    results.append(cognet_obj.randomMaskReconstruction(sample=s, save_output=False))\n",
    "random_randommask_df = pd.DataFrame(results)\n",
    "random_randommask_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2e246-9650-4c30-8a60-fb4661a9b47c",
   "metadata": {},
   "source": [
    "# Comparing the dissonance distributions of Qnet vs Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca0544-af94-4774-9e19-0ee5c0742e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing random and qnet sample dissonance distributions\n",
    "plt.figure()\n",
    "dissonance_df = pd.DataFrame(data=qnet_dissonance_df.mean(axis=1), columns=[\"Qnet\"])\n",
    "dissonance_df[\"random\"] = random_dissonance_df.mean(axis=1)\n",
    "plt.hist(dissonance_df[\"Qnet\"], alpha=0.5, label=\"Qnet samples\")\n",
    "plt.hist(dissonance_df[\"random\"], alpha=0.5, label=\"random samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47742a52-4100-4407-a04b-854910995295",
   "metadata": {},
   "source": [
    "# Comparing Positive vs Negative PTSD dissonance and reconstruction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7d066-a082-4538-a9f3-8be48f4622f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting positive and negative PTSD samples and merging with dissonance and reconstruction results\n",
    "PTSD_DATA = pd.read_csv(\"data/PTSD_cognet_test.csv\")[[\"PTSDDx\"]]\n",
    "\n",
    "PTSD_DATA[\"Mean Reconstruction\"] = diff_df[\"recon_results\"] # qnet_randommask_df[\"rederr\"]\n",
    "PTSD_DATA[\"Mean Dissonance\"] = qnet_dissonance_df.mean(axis=1)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "PTSD_DATA.plot.scatter(\"Mean Dissonance\", \"Mean Reconstruction\", c=\"PTSDDx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e96fec-2150-4871-a053-ef63f5a821df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find confidence interval for negative PTSD samples\n",
    "neg_mean = PTSD_DATA[PTSD_DATA[\"PTSDDx\"] == 0][\"Mean Dissonance\"].mean()\n",
    "neg_std = PTSD_DATA[PTSD_DATA[\"PTSDDx\"] == 0][\"Mean Dissonance\"].std(ddof=1)\n",
    "alpha_p1 = 0.1\n",
    "alpha_p05 = 0.05\n",
    "n_sided = 1 # 1-sided test\n",
    "z_crit = stats.norm.ppf(1-alpha_p1/n_sided)\n",
    "neg_threshold_p1=((-z_crit*neg_std)+neg_mean, (+z_crit*neg_std)+neg_mean)\n",
    "\n",
    "z_crit = stats.norm.ppf(1-alpha_p05/n_sided)\n",
    "neg_threshold_p05=((-z_crit*neg_std)+neg_mean, (+z_crit*neg_std)+neg_mean)\n",
    "\n",
    "print('PTSD Negative Threshold (90%): ',neg_threshold_p1)\n",
    "print('PTSD Negative (95%): ',neg_threshold_p05)\n",
    "\n",
    "# find confidence interval for positive PTSD samples\n",
    "pos_mean = PTSD_DATA[PTSD_DATA[\"PTSDDx\"] == 1][\"Mean Dissonance\"].mean()\n",
    "pos_std = PTSD_DATA[PTSD_DATA[\"PTSDDx\"] == 1][\"Mean Dissonance\"].std(ddof=1)\n",
    "alpha_p1 = 0.1\n",
    "alpha_p05 = 0.05\n",
    "n_sided = 1 # 1-sided test\n",
    "z_crit = stats.norm.ppf(1-alpha_p1/n_sided)\n",
    "pos_threshold_p1=((-z_crit*pos_std)+neg_mean, (+z_crit*pos_std)+pos_mean)\n",
    "\n",
    "z_crit = stats.norm.ppf(1-alpha_p05/n_sided)\n",
    "pos_threshold_p05=((-z_crit*pos_std)+pos_mean, (+z_crit*pos_std)+pos_mean)\n",
    "\n",
    "# find confidence interval for positive PTSD samples\n",
    "print('PTSD Positive Threshold (90%): ',pos_threshold_p1)\n",
    "print('PTSD Positive (95%): ',pos_threshold_p05)\n",
    "\n",
    "\n",
    "# confidence interval for all PTSD samples\n",
    "all_mean = PTSD_DATA[\"Mean Dissonance\"].mean()\n",
    "all_std = PTSD_DATA[\"Mean Dissonance\"].std(ddof=1)\n",
    "alpha_p1 = 0.1\n",
    "alpha_p05 = 0.05\n",
    "n_sided = 1 # 1-sided test\n",
    "z_crit = stats.norm.ppf(1-alpha_p1/n_sided)\n",
    "all_threshold_p1=((-z_crit*all_std)+all_mean, (+z_crit*all_std)+all_mean)\n",
    "\n",
    "z_crit = stats.norm.ppf(1-alpha_p05/n_sided)\n",
    "all_threshold_p05=((-z_crit*all_std)+all_mean, (+z_crit*all_std)+all_mean)\n",
    "\n",
    "print('All PTSD Threshold (90%): ',all_threshold_p1)\n",
    "print('All PTSD (95%): ',all_threshold_p05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6162c381-2eec-4b10-b617-33ce00a27098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting negative vs postive PTSD samples\n",
    "#random_mask_dissonance_df.plot.scatter(\"Mean Dissonance\", \"Mean Reconstruction\", c=\"actual\")\n",
    "print(pos_threshold_p05[1])\n",
    "plt.axvline(pos_threshold_p05[1], color=\"red\", linestyle=\"--\", alpha=.5)\n",
    "#plt.axvline(pos_threshold_p1[1], color=\"red\", linestyle=\"--\", alpha=.5)\n",
    "plt.axvline(neg_threshold_p05[1], color=\"blue\", linestyle=\"--\", alpha=.5)\n",
    "#plt.axvline(neg_threshold_p1[1], color=\"blue\", linestyle=\"--\", alpha=.5)\n",
    "plt.axvline(all_threshold_p05[1], color=\"black\", linestyle=\"--\", alpha=.5)\n",
    "sns.scatterplot(PTSD_DATA[\"Mean Dissonance\"],\n",
    "                PTSD_DATA[\"Mean Reconstruction\"],\n",
    "                hue=PTSD_DATA[\"PTSDDx\"]).set(ylim=(-3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "189d87c6-5413-483a-81ab-c68c9025d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative PTSD results that are 'suspect' at alpha level of .05: 14\n",
      "Number of positive PTSD results that are 'suspect' at alpha level of .05: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of negative PTSD results that are 'suspect' at alpha level of .05:\", len(PTSD_DATA[(PTSD_DATA[\"Mean Dissonance\"] >= neg_threshold_p05[1]) & (PTSD_DATA[\"PTSDDx\"] == 0)][\"Mean Dissonance\"]))\n",
    "print(\"Number of positive PTSD results that are 'suspect' at alpha level of .05:\", len(PTSD_DATA[(PTSD_DATA[\"Mean Dissonance\"] >= pos_threshold_p05[1]) & (PTSD_DATA[\"PTSDDx\"] == 1)][\"Mean Dissonance\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a0cc776f-b5b1-4e84-abe4-66baae1cc9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTSDDx</th>\n",
       "      <th>Mean Reconstruction</th>\n",
       "      <th>Mean Dissonance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>39.452127</td>\n",
       "      <td>0.369462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>48.545839</td>\n",
       "      <td>0.316486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>31.909471</td>\n",
       "      <td>0.323956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>35.589638</td>\n",
       "      <td>0.291811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>37.279897</td>\n",
       "      <td>0.281550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>38.571410</td>\n",
       "      <td>0.301607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>34.640084</td>\n",
       "      <td>0.343368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>34.811713</td>\n",
       "      <td>0.316036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>38.013921</td>\n",
       "      <td>0.308456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>43.013907</td>\n",
       "      <td>0.419398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>29.915861</td>\n",
       "      <td>0.390101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>23.040904</td>\n",
       "      <td>0.369530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>42.818289</td>\n",
       "      <td>0.325193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>33.724088</td>\n",
       "      <td>0.402023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>29.061513</td>\n",
       "      <td>0.335103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>44.419026</td>\n",
       "      <td>0.282672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>33.452264</td>\n",
       "      <td>0.315828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1</td>\n",
       "      <td>33.128175</td>\n",
       "      <td>0.336550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>24.517871</td>\n",
       "      <td>0.294877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1</td>\n",
       "      <td>37.622267</td>\n",
       "      <td>0.373479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1</td>\n",
       "      <td>45.634698</td>\n",
       "      <td>0.279548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1</td>\n",
       "      <td>40.355069</td>\n",
       "      <td>0.382831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "      <td>34.548599</td>\n",
       "      <td>0.282772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "      <td>29.510644</td>\n",
       "      <td>0.410215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0</td>\n",
       "      <td>43.546484</td>\n",
       "      <td>0.318208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1</td>\n",
       "      <td>34.525326</td>\n",
       "      <td>0.343890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1</td>\n",
       "      <td>39.738602</td>\n",
       "      <td>0.307246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>27.017382</td>\n",
       "      <td>0.386804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>32.297571</td>\n",
       "      <td>0.371270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1</td>\n",
       "      <td>36.547336</td>\n",
       "      <td>0.353974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1</td>\n",
       "      <td>34.971282</td>\n",
       "      <td>0.283469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1</td>\n",
       "      <td>40.725680</td>\n",
       "      <td>0.332060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1</td>\n",
       "      <td>40.233175</td>\n",
       "      <td>0.286344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>29.929963</td>\n",
       "      <td>0.295539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>27.083384</td>\n",
       "      <td>0.352989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>42.022193</td>\n",
       "      <td>0.307087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>32.769730</td>\n",
       "      <td>0.382645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>33.239286</td>\n",
       "      <td>0.457220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>1</td>\n",
       "      <td>38.619077</td>\n",
       "      <td>0.322980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0</td>\n",
       "      <td>22.292087</td>\n",
       "      <td>0.344116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1</td>\n",
       "      <td>43.164422</td>\n",
       "      <td>0.293715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1</td>\n",
       "      <td>33.953013</td>\n",
       "      <td>0.316663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0</td>\n",
       "      <td>24.893099</td>\n",
       "      <td>0.338198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0</td>\n",
       "      <td>35.982828</td>\n",
       "      <td>0.297504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>25.962316</td>\n",
       "      <td>0.462012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1</td>\n",
       "      <td>38.405300</td>\n",
       "      <td>0.359545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1</td>\n",
       "      <td>27.958768</td>\n",
       "      <td>0.335505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0</td>\n",
       "      <td>39.422515</td>\n",
       "      <td>0.332518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1</td>\n",
       "      <td>32.510264</td>\n",
       "      <td>0.285215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1</td>\n",
       "      <td>36.593131</td>\n",
       "      <td>0.307663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PTSDDx  Mean Reconstruction  Mean Dissonance\n",
       "9         1            39.452127         0.369462\n",
       "18        1            48.545839         0.316486\n",
       "20        1            31.909471         0.323956\n",
       "21        0            35.589638         0.291811\n",
       "22        0            37.279897         0.281550\n",
       "32        1            38.571410         0.301607\n",
       "46        1            34.640084         0.343368\n",
       "52        0            34.811713         0.316036\n",
       "57        1            38.013921         0.308456\n",
       "60        1            43.013907         0.419398\n",
       "63        1            29.915861         0.390101\n",
       "86        1            23.040904         0.369530\n",
       "90        1            42.818289         0.325193\n",
       "98        1            33.724088         0.402023\n",
       "101       0            29.061513         0.335103\n",
       "106       1            44.419026         0.282672\n",
       "118       0            33.452264         0.315828\n",
       "129       1            33.128175         0.336550\n",
       "152       1            24.517871         0.294877\n",
       "159       1            37.622267         0.373479\n",
       "185       1            45.634698         0.279548\n",
       "188       1            40.355069         0.382831\n",
       "200       1            34.548599         0.282772\n",
       "210       0            29.510644         0.410215\n",
       "212       0            43.546484         0.318208\n",
       "213       1            34.525326         0.343890\n",
       "216       1            39.738602         0.307246\n",
       "221       1            27.017382         0.386804\n",
       "222       0            32.297571         0.371270\n",
       "225       1            36.547336         0.353974\n",
       "230       1            34.971282         0.283469\n",
       "231       1            40.725680         0.332060\n",
       "234       1            40.233175         0.286344\n",
       "235       0            29.929963         0.295539\n",
       "238       1            27.083384         0.352989\n",
       "246       1            42.022193         0.307087\n",
       "252       1            32.769730         0.382645\n",
       "261       1            33.239286         0.457220\n",
       "262       1            38.619077         0.322980\n",
       "263       0            22.292087         0.344116\n",
       "264       1            43.164422         0.293715\n",
       "265       1            33.953013         0.316663\n",
       "272       0            24.893099         0.338198\n",
       "281       0            35.982828         0.297504\n",
       "282       0            25.962316         0.462012\n",
       "291       1            38.405300         0.359545\n",
       "293       1            27.958768         0.335505\n",
       "294       0            39.422515         0.332518\n",
       "296       1            32.510264         0.285215\n",
       "300       1            36.593131         0.307663"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PTSD_DATA[(PTSD_DATA[\"Mean Dissonance\"] >= neg_threshold_p05[1])]#[PTSD_DATA[\"PTSDDx\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e2362a-277c-4bca-8b57-b25e8e670918",
   "metadata": {},
   "source": [
    "# Using Qsamples to generate random samples (Null Qsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "45ca8cf0-71ac-4d2b-8338-9d0b4b8ac313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "304 random samples computed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4ef448eeb247dbb76f3ef7db92e479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='SUBMITTING | ', style=ProgressStyle(description_width='in"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0df6a6c9994d2b8de5ad7e9c51594a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='PROCESSING | ', style=ProgressStyle(description_width='in"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79abeb9e544475c88d12b9fc3386c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='COLLECTING | ', style=ProgressStyle(description_width='in"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886866</td>\n",
       "      <td>0.676939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313882</td>\n",
       "      <td>0.079643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181010</td>\n",
       "      <td>0.283358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449221</td>\n",
       "      <td>0.384563</td>\n",
       "      <td>0.367011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225533</td>\n",
       "      <td>0.772641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.136645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836214</td>\n",
       "      <td>0.110001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.299732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.723079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.468785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871282</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.304015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292486</td>\n",
       "      <td>0.153982</td>\n",
       "      <td>0.467295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923166</td>\n",
       "      <td>0.620710</td>\n",
       "      <td>0.240547</td>\n",
       "      <td>0.806746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453020</td>\n",
       "      <td>0.176010</td>\n",
       "      <td>0.525570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.554817</td>\n",
       "      <td>0.580849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810208</td>\n",
       "      <td>0.903436</td>\n",
       "      <td>0.445556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262499</td>\n",
       "      <td>0.062481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388530</td>\n",
       "      <td>0.847911</td>\n",
       "      <td>0.033468</td>\n",
       "      <td>0.628408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165343</td>\n",
       "      <td>0.198383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253147</td>\n",
       "      <td>0.274906</td>\n",
       "      <td>0.367799</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.750976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310746</td>\n",
       "      <td>0.100115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.307925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832321</td>\n",
       "      <td>0.262232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.762910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.264153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095590</td>\n",
       "      <td>0.226669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068013</td>\n",
       "      <td>0.148524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434413</td>\n",
       "      <td>0.185812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228428</td>\n",
       "      <td>0.032433</td>\n",
       "      <td>0.242658</td>\n",
       "      <td>0.195439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.518493  0.000000   \n",
       "1   0.000000  0.000000  0.181010  0.283358  0.000000  0.000000  0.000000   \n",
       "2   0.136645  0.000000  0.214282  0.000000  0.836214  0.110001  0.000000   \n",
       "3   0.304015  0.000000  0.303352  0.000000  0.000000  0.000000  0.324366   \n",
       "4   0.000000  0.923166  0.620710  0.240547  0.806746  0.000000  0.453020   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.000000  0.554817  0.580849  0.000000  0.810208  0.903436  0.445556   \n",
       "96  0.000000  0.576185  0.000000  0.388530  0.847911  0.033468  0.628408   \n",
       "97  0.307925  0.000000  0.000000  0.260082  0.000000  0.000000  0.832321   \n",
       "98  0.264153  0.000000  0.287848  0.000000  0.000000  0.000000  0.587616   \n",
       "99  0.000000  0.068013  0.148524  0.000000  0.000000  0.064472  0.000000   \n",
       "\n",
       "         7         8         9    ...       201       202       203       204  \\\n",
       "0   0.000000  0.886866  0.676939  ...  0.549934  0.000000  0.227090  0.000000   \n",
       "1   0.449221  0.384563  0.367011  ...  0.000000  0.000000  0.000000  0.225533   \n",
       "2   0.299732  0.000000  0.723079  ...  0.000000  0.000000  0.468785  0.000000   \n",
       "3   0.000000  0.478082  0.000000  ...  0.000000  0.000000  0.000000  0.231752   \n",
       "4   0.176010  0.525570  0.000000  ...  0.000000  0.241601  0.000000  0.000000   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95  0.000000  0.689994  0.000000  ...  0.000000  0.433986  0.000000  0.000000   \n",
       "96  0.000000  0.165343  0.198383  ...  0.000000  0.253147  0.274906  0.367799   \n",
       "97  0.262232  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "98  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.681299  0.000000   \n",
       "99  0.000000  0.434413  0.185812  ...  0.707560  0.000000  0.000000  0.000000   \n",
       "\n",
       "         205       206       207       208       209       210  \n",
       "0   0.000000  0.209624  0.000000  0.000000  0.313882  0.079643  \n",
       "1   0.772641  0.000000  0.000000  0.000000  0.000000  0.632690  \n",
       "2   0.000000  0.400971  0.000000  0.000000  0.871282  0.000000  \n",
       "3   0.000000  0.000000  0.000000  0.292486  0.153982  0.467295  \n",
       "4   0.000000  0.232433  0.000000  0.000000  0.000000  0.043897  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "95  0.348351  0.000000  0.409083  0.000000  0.262499  0.062481  \n",
       "96  0.400000  0.750976  0.000000  0.000000  0.310746  0.100115  \n",
       "97  0.000000  0.000000  0.000000  0.762910  0.000000  0.000000  \n",
       "98  0.000000  0.095590  0.226669  0.000000  0.000000  0.407222  \n",
       "99  0.142439  0.000000  0.228428  0.032433  0.242658  0.195439  \n",
       "\n",
       "[100 rows x 211 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"__________________________________________________\")\n",
    "# null_array = np.zeros((len(features),), dtype=str)\n",
    "# nsamples = 304\n",
    "# print(\"{} random samples computed\".format(nsamples))\n",
    "# qsamples = []\n",
    "# for n in range(nsamples):\n",
    "#     qsamples.append(cognet_obj.qsampling(null_array, 300))\n",
    "# qsamples\n",
    "\n",
    "print(\"{} random samples computed\".format(304))\n",
    "qsamples = cognet_obj.random_sample(type=\"null\",n=304, steps=300, n_jobs=3)\n",
    "results = []\n",
    "for s in range(len(qsamples)):\n",
    "    results.append(cognet_obj.dissonance(0, sample=qsamples.iloc[s]))\n",
    "qrandom_dissonance_df = pd.DataFrame(results)\n",
    "qrandom_dissonance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eecb462a-15a0-4b53-91f3-070342f2323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "304 random samples computed\n"
     ]
    }
   ],
   "source": [
    "print(\"__________________________________________________\")\n",
    "null_array = np.zeros((len(features),), dtype=str)\n",
    "nsamples = 304\n",
    "print(\"{} random samples computed\".format(nsamples))\n",
    "qsamples = []\n",
    "for n in range(nsamples):\n",
    "    qsamples.append(cognet_obj.qsampling(null_array, 500))\n",
    "qsamples\n",
    "\n",
    "results = []\n",
    "for s in qsamples:\n",
    "    results.append(cognet_obj.dissonance(0, sample=s))\n",
    "qrandom_dissonance_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "62978e71-64e2-4395-b847-96dec498240b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comparing qsampled random and qnet sample dissonance distributions\n",
    "plt.figure()\n",
    "qdissonance_df = pd.DataFrame(data=qnet_dissonance_df.mean(axis=1), columns=[\"Qnet\"])\n",
    "qdissonance_df[\"random\"] = qrandom_dissonance_df.mean(axis=1)\n",
    "plt.hist(qdissonance_df[\"Qnet\"], alpha=0.5, label=\"Qnet samples\")\n",
    "plt.hist(qdissonance_df[\"random\"], alpha=0.5, label=\"random samples\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25c2c529-152a-49e1-8a80-de0ea0511506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.02638788602222"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnet_randommask_df[\"rederr\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6f3c4f1-bf98-4fe2-b956-db9a8179699d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.1130648637064"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_randommask_df[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75e526c3-6452-482c-b7c2-46a6d55af309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sample Thershold (90%):  0.323930021895188\n",
      "Random Sample Thershold (95%):  0.33153236597733904\n",
      "Qnet Thershold (90%):  0.29858583623412405\n",
      "Qnet Thershold (95%):  0.32759370082729655\n"
     ]
    }
   ],
   "source": [
    "# find confidence interval for random samples\n",
    "from scipy import stats\n",
    "random_mean = random_dissonance_df.mean(axis=1).mean()\n",
    "random_std = random_dissonance_df.mean(axis=1).std(ddof=1)\n",
    "alpha_p1 = 0.1\n",
    "alpha_p05 = 0.05\n",
    "n_sided = 1 # 1-sided test\n",
    "z_crit = stats.norm.ppf(1-alpha_p1/n_sided)\n",
    "threshold_p1=(z_crit*random_std)+random_mean\n",
    "\n",
    "z_crit = stats.norm.ppf(1-alpha_p05/n_sided)\n",
    "threshold_p05=(z_crit*random_std)+random_mean\n",
    "\n",
    "print('Random Sample Thershold (90%): ',threshold_p1)\n",
    "print('Random Sample Thershold (95%): ',threshold_p05)\n",
    "\n",
    "# find confidence interval for qnet samples\n",
    "qnet_mean = qnet_dissonance_df.mean(axis=1).mean()\n",
    "qnet_std = qnet_dissonance_df.mean(axis=1).std(ddof=1)\n",
    "alpha_p1 = 0.1\n",
    "alpha_p05 = 0.05\n",
    "n_sided = 1 # 1-sided test\n",
    "z_crit = stats.norm.ppf(1-alpha_p1/n_sided)\n",
    "threshold_p1=(z_crit*qnet_std)+qnet_mean\n",
    "\n",
    "z_crit = stats.norm.ppf(1-alpha_p05/n_sided)\n",
    "threshold_p05=(z_crit*qnet_std)+qnet_mean\n",
    "\n",
    "print('Qnet Thershold (90%): ',threshold_p1)\n",
    "print('Qnet Thershold (95%): ',threshold_p05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31c4f5b5-2cbf-4715-ad0e-2db03b59a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the random mask reconstruction dfs\n",
    "qnet_randommask_df1 = qnet_randommask_df[[\"rederr\"]]\n",
    "random_randommask_df1 = random_randommask_df[[0]]\n",
    "random_randommask_df1.columns=[\"rederr\"]\n",
    "qnet_randommask_df1[\"actual\"] = 1\n",
    "random_randommask_df1[\"actual\"] = 0\n",
    "random_mask_df = pd.concat([qnet_randommask_df1, random_randommask_df1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6470671f-7e43-4413-b267-b77db88a51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the dissonance dfs\n",
    "dissonance_df = pd.DataFrame(data=qnet_dissonance_df.mean(axis=1), columns=[\"Mean Dissonance\"])\n",
    "dissonance_df[\"actual\"] = 1\n",
    "dissonance_df1 = pd.DataFrame(data=random_dissonance_df.mean(axis=1), columns=[\"Mean Dissonance\"])\n",
    "dissonance_df1[\"actual\"] = 0\n",
    "dissonance_df = pd.concat([dissonance_df, dissonance_df1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1f042b4-f2ab-446c-b0c3-bea7e0fc17a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Dissonance</th>\n",
       "      <th>actual</th>\n",
       "      <th>Mean Reconstruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185657</td>\n",
       "      <td>1</td>\n",
       "      <td>33.270891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.153450</td>\n",
       "      <td>1</td>\n",
       "      <td>37.695298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222102</td>\n",
       "      <td>1</td>\n",
       "      <td>38.887323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.138878</td>\n",
       "      <td>1</td>\n",
       "      <td>41.820925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.146156</td>\n",
       "      <td>1</td>\n",
       "      <td>38.100904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0.326093</td>\n",
       "      <td>0</td>\n",
       "      <td>41.100344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0.288748</td>\n",
       "      <td>0</td>\n",
       "      <td>37.927735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0.304060</td>\n",
       "      <td>0</td>\n",
       "      <td>38.349455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.276205</td>\n",
       "      <td>0</td>\n",
       "      <td>27.842122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0.329974</td>\n",
       "      <td>0</td>\n",
       "      <td>46.035389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean Dissonance  actual  Mean Reconstruction\n",
       "0           0.185657       1            33.270891\n",
       "1           0.153450       1            37.695298\n",
       "2           0.222102       1            38.887323\n",
       "3           0.138878       1            41.820925\n",
       "4           0.146156       1            38.100904\n",
       "..               ...     ...                  ...\n",
       "603         0.326093       0            41.100344\n",
       "604         0.288748       0            37.927735\n",
       "605         0.304060       0            38.349455\n",
       "606         0.276205       0            27.842122\n",
       "607         0.329974       0            46.035389\n",
       "\n",
       "[608 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine dissonance and recon dfs\n",
    "random_mask_dissonance_df = dissonance_df\n",
    "random_mask_dissonance_df[\"Mean Reconstruction\"] = random_mask_df[\"rederr\"]\n",
    "random_mask_dissonance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c4f2248-7dac-46f4-900d-d09e0ff9c0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f90ed83a908>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot dissonance vs recon colored by qsampled vs actual data\n",
    "import seaborn as sns\n",
    "plt.gca().axes.get_xaxis().set_visible(True)\n",
    "#random_mask_dissonance_df.plot.scatter(\"Mean Dissonance\", \"Mean Reconstruction\", c=\"actual\")\n",
    "sns.scatterplot(random_mask_dissonance_df[\"Mean Dissonance\"],\n",
    "                random_mask_dissonance_df[\"Mean Reconstruction\"],\n",
    "                hue=random_mask_dissonance_df[\"actual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06175c03-8bd9-4e6e-8d2c-808252ac9aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptsd1</th>\n",
       "      <th>ptsd2</th>\n",
       "      <th>ptsd3</th>\n",
       "      <th>ptsd4</th>\n",
       "      <th>ptsd5</th>\n",
       "      <th>ptsd6</th>\n",
       "      <th>ptsd7</th>\n",
       "      <th>ptsd8</th>\n",
       "      <th>ptsd9</th>\n",
       "      <th>ptsd10</th>\n",
       "      <th>...</th>\n",
       "      <th>ptsd202</th>\n",
       "      <th>ptsd203</th>\n",
       "      <th>ptsd204</th>\n",
       "      <th>ptsd205</th>\n",
       "      <th>ptsd206</th>\n",
       "      <th>ptsd207</th>\n",
       "      <th>ptsd208</th>\n",
       "      <th>ptsd209</th>\n",
       "      <th>ptsd210</th>\n",
       "      <th>ptsd211</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ptsd1 ptsd2 ptsd3 ptsd4 ptsd5 ptsd6 ptsd7 ptsd8 ptsd9 ptsd10  ... ptsd202  \\\n",
       "0     2     1     1     1     4     3     1     3     1      1  ...       3   \n",
       "\n",
       "  ptsd203 ptsd204 ptsd205 ptsd206 ptsd207 ptsd208 ptsd209 ptsd210 ptsd211  \n",
       "0       2       1       2       4       1       3       1       2       5  \n",
       "\n",
       "[1 rows x 211 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_df = pd.DataFrame()\n",
    "for col in cognet_obj.samples.columns:\n",
    "    return_df[col] = cognet_obj.samples[col].sample(n=1, replace=True).values\n",
    "return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7ee9840-f803-4ece-a6bf-9fe12800b839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptsd1</th>\n",
       "      <th>ptsd2</th>\n",
       "      <th>ptsd3</th>\n",
       "      <th>ptsd4</th>\n",
       "      <th>ptsd5</th>\n",
       "      <th>ptsd6</th>\n",
       "      <th>ptsd7</th>\n",
       "      <th>ptsd8</th>\n",
       "      <th>ptsd9</th>\n",
       "      <th>ptsd10</th>\n",
       "      <th>...</th>\n",
       "      <th>ptsd202</th>\n",
       "      <th>ptsd203</th>\n",
       "      <th>ptsd204</th>\n",
       "      <th>ptsd205</th>\n",
       "      <th>ptsd206</th>\n",
       "      <th>ptsd207</th>\n",
       "      <th>ptsd208</th>\n",
       "      <th>ptsd209</th>\n",
       "      <th>ptsd210</th>\n",
       "      <th>ptsd211</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ptsd1, ptsd2, ptsd3, ptsd4, ptsd5, ptsd6, ptsd7, ptsd8, ptsd9, ptsd10, ptsd11, ptsd12, ptsd13, ptsd14, ptsd15, ptsd16, ptsd17, ptsd18, ptsd19, ptsd20, ptsd21, ptsd22, ptsd23, ptsd24, ptsd25, ptsd26, ptsd27, ptsd28, ptsd29, ptsd30, ptsd31, ptsd32, ptsd33, ptsd34, ptsd35, ptsd36, ptsd37, ptsd38, ptsd39, ptsd40, ptsd41, ptsd42, ptsd43, ptsd44, ptsd45, ptsd46, ptsd47, ptsd48, ptsd49, ptsd50, ptsd51, ptsd52, ptsd53, ptsd54, ptsd55, ptsd56, ptsd57, ptsd58, ptsd59, ptsd60, ptsd61, ptsd62, ptsd63, ptsd64, ptsd65, ptsd66, ptsd67, ptsd68, ptsd69, ptsd70, ptsd71, ptsd72, ptsd73, ptsd74, ptsd75, ptsd76, ptsd77, ptsd78, ptsd79, ptsd80, ptsd81, ptsd82, ptsd83, ptsd84, ptsd85, ptsd86, ptsd87, ptsd88, ptsd89, ptsd90, ptsd91, ptsd92, ptsd93, ptsd94, ptsd95, ptsd96, ptsd97, ptsd98, ptsd99, ptsd100, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 211 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cognet_obj.samples[cognet_obj.samples.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbb72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = pd.read_csv(\"PTSD_cognet_test.csv\")\n",
    "# samples = samples.drop(['record_id', 'PTSDDx'], axis=1)\n",
    "# samples.to_csv(\"PTSD_cognet_test_processed.csv\", index=False)\n",
    "# samples = pd.read_csv(\"PTSD_cognet_test_processed.csv\")\n",
    "# samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a0b4a-4a5b-497c-974d-2b53ef245a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
