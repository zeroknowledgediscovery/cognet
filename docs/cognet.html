<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>cognet.cognet API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#666666;background-color:black;//mix-blend-mode:difference;color:#bbbbbb;z-index:3}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#66bb66;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#66FF66}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:transparent;padding:1px 4px;color:#FFA500;overflow-wrap:break-word}h1 code{background:transparent}pre{overflow-wrap:break-word;background:#111111;word-wrap:break-word;border:0;border-top:1px solid #666;border-bottom:1px solid #666;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#333333;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#aaeeaa;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;color:#bbbbbb;background-color:black;overflow-wrap:break-word}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cognet.cognet</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import pandas as pd
import random
from quasinet.qnet import Qnet, qdistance, load_qnet, qdistance_matrix
from quasinet.qsampling import qsample, targeted_qsample
import os
os.system(&#34;module unload openmpi&#34;)
#from mpi4py.futures import MPIPoolExecutor
import sys
import subprocess
from pqdm.processes import pqdm
from scipy.stats import entropy

import multiprocessing as mp
import time

class cognet:
    &#34;&#34;&#34;Aggregate related Qnet functions
    &#34;&#34;&#34;

    def __init__(self):
        &#34;&#34;&#34;Init
        &#34;&#34;&#34;
        self.year = None
        self.n_jobs = 28
        self.qnet = None
        self.steps = 120
        self.num_qsamples = None
        self.samples = None
        self.samples_as_strings = None
        self.features = None
        self.cols = None
        self.immutable_vars = None
        self.mutable_vars = None
        self.poles = None
        self.polar_features = None
        self.polar_indices = None
        self.pL = None
        self.pR = None
        self.d0 = None
        self.qdistance_matrix_file = None
        self.dissonance_file = None
        self.s_null = None
        self.D_null = None
        self.mask_prob = 0.5
        self.variation_weight = None
        self.polar_matrix = None
    
    def load_from_model(self,
                        model,
                        im_vars=None,
                        m_vars=None):
        &#34;&#34;&#34;[summary]

        Args:
            model ([type]): [description]
            im_vars ([type], optional): [description]. Defaults to None.
            m_vars ([type], optional): [description]. Defaults to None.
        &#34;&#34;&#34;
        if model is not None:
            self.qnet = model.myQnet
            self.cols = model.features
            self.features = pd.DataFrame(columns=self.cols)
            self.immutable_vars = model.immutable_vars
            self.mutable_vars = model.mutable_vars
            
            samples = pd.DataFrame(model.samples)
            self.samples = pd.concat([samples,self.features], axis=0)
            self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]
            self.s_null=[&#39;&#39;]*len(self.samples_as_strings[0])
            self.D_null=self.qnet.predict_distributions(self.s_null)
            variation_weight = []
            for d in self.D_null:
                v=[]
                for val in d.values():
                    v=np.append(v,val)
                variation_weight.append(entropy(v,base=len(v)))
            self.variation_weight = variation_weight
            
    def load_data(self,
                  year,
                  features_by_year,
                  samples,
                  qnet):
        &#39;&#39;&#39;load cols, features, samples, and qnet.

        Args:
          year (str): to identify cols/features.
          features_by_year (str): file containing all features by year of the dataset.
          samples (str): file of samples for that year.
          Qnet (str): Qnet file location.
        &#39;&#39;&#39;
        self.qnet = load_qnet(qnet)
        self.year = year
        self.cols = np.array((pd.read_csv(features_by_year,
                               keep_default_na=True, 
                               index_col=0).set_index(
                                   &#39;year&#39;)).loc[int(year)].apply(
                                       eval).values[0])
        self.features = pd.DataFrame(columns=self.cols)
        self.mutable_vars = [x for x in self.cols]
        #[self.cols].fillna(&#39;&#39;).values.astype(str)[:]

        self.samples=pd.read_csv(samples)
        self.samples = pd.concat([self.samples,self.features], axis=0)
        self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]
        self.s_null=[&#39;&#39;]*len(self.samples_as_strings[0])
        self.D_null=self.qnet.predict_distributions(self.s_null)
        variation_weight = []
        for d in self.D_null:
            v=[]
            for val in d.values():
                v=np.append(v,val)
            variation_weight.append(entropy(v,base=len(v)))
        self.variation_weight = variation_weight

    def set_immutable_vars(self,
                           IMMUTABLE_FILE):
        &#39;&#39;&#39;
        set vars to immutable and mutable, 
        can prob combine this with the load_data func: only set the immutable vars if necessary

        Args:
          IMMUTABLE_FILE (str): file containing the immutable features/vars
        &#39;&#39;&#39;
        if self.cols is None:
            raise ValueError(&#34;load_data first!&#34;)
        self.immutable_vars = pd.read_csv(IMMUTABLE_FILE,index_col=0).transpose()
        self.mutable_vars = None
        self.mutable_vars = [x for x in self.cols
                             if x.upper() not in self.immutable_vars.columns]
    
    def set_nsamples(self,
                     num_samples):
        &#39;&#39;&#39;
        select a subset of the samples

        Args:
          num_samples (int): Set num of samples to subset
        &#39;&#39;&#39;
        
        if all(x is not None for x in [num_samples, self.samples]):
            if num_samples &gt; len(self.samples.index):
                string = &#39;The number of selected samples ({}) &#39; + \
                     &#39;is greater than the number of samples ({})!&#39;
                string = string.format(num_samples, len(self.samples.index))
                raise ValueError(string)

            if num_samples == len(self.samples.index):
                string = &#39;The number of selected samples ({}) &#39; + \
                     &#39;is equal the number of samples ({})!&#39;
                string = string.format(num_samples, len(self.samples.index))
                print(string)
            #self.samples = self.samples.sample(num_samples)
            self.samples = self.samples[:10]
            self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]

        elif self.samples is None:
            raise ValueError(&#34;load_data first!&#34;)

    def __variation_weight(self,
                           index):
        &#34;&#34;&#34;[summary]

        Args:
            index ([type]): [description]

        Returns:
            [type]: [description]
        &#34;&#34;&#34;
        d_=self.D_null[index]
        v=[]
        for val in d_.values():
            v=np.append(v,val)
        return entropy(v,base=len(v))
    
    def getBaseFrequency(self, 
                         sample):
        &#39;&#39;&#39;
        get frequency of the variables
        helper func for qsampling

        Args:
          sample (list[str]): vector of sample, must have the same dimensions as the qnet
        &#39;&#39;&#39;
        MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()
                
        for m in self.mutable_vars:
            MUTABLE[m]=1.0
        mutable_x=MUTABLE.values[0]
        base_frequency=mutable_x/mutable_x.sum()

        # commented out for now for testing using smaller qnet
        # for i in range(len(base_frequency)):
        #     if base_frequency[i]&gt;0.0:
        #         base_frequency[i]= self.__variation_weight(i)*base_frequency[i]

        return base_frequency/base_frequency.sum()

    def __getBaseFrequency_test(self, 
                         sample):
        &#39;&#39;&#39;
        get frequency of the variables
        helper func for qsampling

        Args:
          sample (list[str]): vector of sample, must have the same dimensions as the qnet
        &#39;&#39;&#39;
        MUTABLE=pd.DataFrame(np.zeros(len(sample)),index=sample).transpose()
                
        for m in sample:
            MUTABLE[m]=1.0
        mutable_x=MUTABLE.values[0]
        base_frequency=mutable_x/mutable_x.sum()

        # commented out for now for testing using smaller qnet
        for i in range(len(base_frequency)):
            if base_frequency[i]&gt;0.0:
                base_frequency[i]= self.variation_weight[i]*base_frequency[i]

        return base_frequency/base_frequency.sum()
    
    def qsampling(self,
                  sample,
                  steps,
                  immutable=False):
        &#39;&#39;&#39;
        perturb the sample based on thet qnet distributions and number of steps

        Args:
          sample (1d array-like): vector of sample, must have the same dimensions as the qnet
          steps (int): number of steps to qsample
          immutable (bool): are there variables that are immutable?
        &#39;&#39;&#39;
        if all(x is not None for x in [self.mutable_vars, self.immutable_vars, sample]):
            if immutable == True:
                return qsample(sample,self.qnet,steps,self.getBaseFrequency(self.samples))
            else:
                return qsample(sample,self.qnet,steps)
        elif self.mutable_vars is None:
            raise ValueError(&#34;load_data first!&#34;)
        elif self.immutable_vars is None:
            raise ValueError(&#34;load immutable variables first!&#34;)

    def set_poles(self,
                  POLEFILE,
                  steps=0,
                  mutable=False):
        &#39;&#39;&#39;
        set the poles and samples such that the samples contain features in poles


        Args:
          steps (int): number of steps to qsample
          POLEFILE (str): file containing poles samples and features
          mutable (boolean): Whether or not to set poles as the only mutable_vars
        &#39;&#39;&#39;
        invalid_count = 0
        if all(x is not None for x in [self.samples]):
            poles = pd.read_csv(POLEFILE, index_col=0)
            L=poles.L.to_dict()
            R=poles.R.to_dict()
            self.poles=poles.transpose()

            cols = [x for x in self.poles.columns if x in self.samples.columns]
            self.samples=self.samples[cols]
        
            for x in self.poles.columns:
                if x not in self.samples.columns:
                    invalid_count += 1
                    self.samples[x]=np.nan

            self.samples = pd.concat([self.samples,self.features], axis=0)
            self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]

            self.polar_features = pd.concat([self.poles, self.features], axis=0)
            pL= self.polar_features.loc[&#39;L&#39;][self.cols].fillna(&#39;&#39;).values.astype(str)[:]
            pR= self.polar_features.loc[&#39;R&#39;][self.cols].fillna(&#39;&#39;).values.astype(str)[:]

            self.pL=self.qsampling(pL,steps)
            self.pR=self.qsampling(pR,steps)
            if mutable:
                self.mutable_vars=[x for x in self.cols if x in self.poles.columns]
        elif self.samples is None:
            raise ValueError(&#34;load_data first!&#34;)
        
        print(&#34;{} pole features not found in sample features&#34;.format(invalid_count))

    def distance(self,
                 sample1,
                 sample2,
                 nsteps1=0,
                 nsteps2=0):
        &#34;&#34;&#34;[summary]

        Args:
            sample1 ([type]): [description]
            sample2 ([type]): [description]
            nsteps1 (int, optional): [description]. Defaults to 0.
            nsteps2 (int, optional): [description]. Defaults to 0.

        Raises:
            ValueError: [description]

        Returns:
            [type]: [description]
        &#34;&#34;&#34;
        if self.qnet is None:
            raise ValueError(&#34;load qnet first!&#34;)
        sample1 = pd.DataFrame(sample1).fillna(&#39;&#39;).values.astype(str)[:]
        sample2 = pd.DataFrame(sample1).fillna(&#39;&#39;).values.astype(str)[:]
        bp1 = self.__getBaseFrequency_test(sample1)
        bp2 = self.__getBaseFrequency_test(sample2)
        print(sample1)
        print(sample1.shape)
        print(bp1.shape)
        sample1 = qsample(sample1, self.qnet, nsteps1, baseline_prob=bp1)
        sample2 = qsample(sample2, self.qnet, nsteps2, baseline_prob=bp2)
        return qdistance(sample1, sample2)
    
    def __distfunc(self, 
                 x, 
                 y):
        &#39;&#39;&#39;
        Compute distance between two samples

        Args:
          x : first sample
          y : second sample
        &#39;&#39;&#39;
        d=qdistance(x,y,self.qnet,self.qnet)
        return d
    
    def polarDistance(self,
                      sample):
        &#34;&#34;&#34;[summary]

        Args:
            sample ([type]): [description]

        Returns:
            [type]: [description]
        &#34;&#34;&#34;
        distances = {}
        for index, row in self.poles.iterrows():
            distances[index] = distance(sample, row)
        return distances
            
    
    def distfunc_line(self,
                   row):
        &#39;&#39;&#39;
        compute the dist for a row, or vector of samples

        Args:
          k (int): row
        return:
          numpy.ndarray(float)
        &#39;&#39;&#39;
        if all(x is not None for x in [self.samples, self.features]):
            w = self.samples.index.size
            p_all = pd.concat([self.samples, self.features], axis=0)[cols].fillna(&#39;&#39;).values.astype(str)[:]
            line = np.zeros(w)
            y = p_all[row]
            for j in range(w):
                # only compute half of the distance matrix
                if j &gt; row:
                    x = p_all[j]
                    line[j] = self.__distfunc(x, y)
        else:
            raise ValueError(&#34;load_data first!&#34;)
        return line
    
    def polar_separation(self,
                         nsteps=0):
        &#34;&#34;&#34;[summary]

        Args:
            nsteps (int, optional): [description]. Defaults to 0.

        Returns:
            [type]: [description]
        &#34;&#34;&#34;
        polar_arraydata = self.polar_features[self.cols].fillna(&#39;&#39;).values.astype(str)[:]
        print(&#34;testing polar_separation&#34;)
        print(polar_arraydata)
        samples_ = []
        for vector in polar_arraydata:
            bp = self.getBaseFrequency(vector)
            sample = qsample(vector, self.qnet, nsteps, baseline_prob=bp)
            samples_.append(sample)
        self.polar_matrix = qdistance_matrix(samples_, samples_, self.qnet, self.qnet)
        return self.polar_matrix
        
    def embed(self,
              infile,
              name_pref,
              out_dir):
        &#39;&#39;&#39;
        embed data

        Args:
          infile (str): input file to be embedded
          name_pref (str): preferred name for output file
          out_dir (str): output dir for results
        &#39;&#39;&#39;
        if all(x is not None for x in [self.year]):
            yr = self.year
            PREF = name_pref
            FILE = infile

            EMBED = &#39;../GSS/bin/embed&#39;
            DATAFILE = &#39;data_&#39; +yr
            EFILE = out_dir + PREF + &#39;_E_&#39; +yr
            DFILE = out_dir + PREF + &#39;_D_&#39; +yr

            pd.read_csv(infile,header=None).to_csv(out_dir + DATAFILE,sep=&#39; &#39;,header=None,index=None)
            STR=EMBED+&#39; -f &#39;+DATAFILE+&#39; -E &#39;+EFILE+&#39; -D &#39;+DFILE
            subprocess.call(STR,shell=True)
        elif self.year is None:
            raise ValueError(&#34;load_data first!&#34;)
    
    def compute_DLI_sample(self,
                           i,):
        &#39;&#39;&#39;
        return ideology index, dL, dR, Qsd (std), Q (max) for one sample

        Args:
          i (int): index of sample
        &#39;&#39;&#39;
        p = self.samples_as_strings[i]
        dR = qdistance(self.pR, p, self.qnet, self.qnet)
        dL = qdistance(self.pL, p, self.qnet, self.qnet)
        ideology_index = (dR-dL)/self.d0
        
        Qset = [qsample(p, self.qnet, self.steps) for j in np.arange(self.num_qsamples)]
        Qset = np.array(Qset)

        matrix = (qdistance_matrix(Qset, Qset, self.qnet, self.qnet))
        Q = matrix.max()
        Qsd = matrix.std()

        return [ideology_index, dL, dR, Qsd, Q]
       
    def compute_DLI_samples(self,
                    num_qsamples,
                    outfile,
                    steps=5,
                    n_jobs=28):
        &#39;&#39;&#39;
        compute and save ideology index, dL, dR, Qsd (std), Q (max) for all samples

        Args:
          num_qsamples (int): number of qsamples to compute
          steps (int): number of steps to qsample
          outfile (str): output file for results
        &#39;&#39;&#39;
        if all(x is not None for x in [self.samples, self.features,
                                    self.pL, self.pR]):
            self.num_qsamples = num_qsamples
            self.steps = steps
            self.d0 = qdistance(self.pL, self.pR, self.qnet, self.qnet)

            result=pqdm(range(len(self.samples)), self.compute_DLI, n_jobs)
            pd.DataFrame(result,
                        columns=[&#39;ido&#39;, &#39;dL&#39;, &#39;dR&#39;, &#39;Qsd&#39;, &#39;Q&#39;]).to_csv(outfile)

        elif self.pL is None or self.pR is None:
            raise ValueError(&#34;set_poles first!&#34;)
        else:
            raise ValueError(&#34;load_data first!&#34;)
    
    def compute_polar_indices(self,
                              num_samples = None,
                              polar_comp = False,
                              POLEFILE = None,
                              steps = 5):
        &#39;&#39;&#39;
        set up polar indices for dissonance func

        Args:
          num_samples (int): subset of samples to take
          polar_comp (bool): whether or not to set poles
          POLEFILE (None): file containing pole samples and features
          steps (int): number of steps to qsample
        &#39;&#39;&#39;
        if all(x is not None for x in [self.samples, self.features, self.poles]):
            if num_samples is not None:
                self.set_nsamples(num_samples)

            # read sample data
            if polar_comp:
                self.set_poles(self.qnet, steps, POLEFILE)
            
            polar_features = pd.concat([self.poles, self.features], axis=0)
            self.polar_indices=np.where(polar_features[self.cols].fillna(&#39;XXXX&#39;).values[0]!=&#39;XXXX&#39;)[0]
        
        elif self.poles is None:
            raise ValueError(&#34;set_poles first!&#34;)
        else:
            raise ValueError(&#34;load_data first!&#34;)

    def dissonance(self,
                sample_index,
                MISSING_VAL=0.0):
        &#39;&#39;&#39;
        compute dissonance for each sample_index, helper function for all_dissonance
        
        Args:
          sample_index (int): index of the sample to compute dissonance
          MISSING_VAL (float): 
        &#39;&#39;&#39;
        if all(x is not None for x in [self.samples, self.features, 
                                       self.poles]):
            s = self.samples_as_strings[sample_index]
            if self.polar_indices is None:
                self.polar_indices = range(len(s))

            Ds=self.qnet.predict_distributions(s)
            
            diss=np.ones(len(Ds))*MISSING_VAL
            for i in self.polar_indices:
                if s[i] != &#39;&#39;:
                    if s[i] in Ds[i].keys():
                        diss[i]=1-Ds[i][s[i]]/np.max(
                            list(Ds[i].values())) 
                    else:
                        diss[i]=1.0
            return diss[self.polar_indices]

        elif self.poles is None:
            raise ValueError(&#34;set_poles first!&#34;)
        else:
            raise ValueError(&#34;load_data first!&#34;)
    
    def dissonance_matrix(self,
                          output_file=None,
                          n_jobs=28):
        &#39;&#39;&#39;
        get the dissonance for all samples

        Args:
          output_file (str): directory and/or file for output
          n_jobs (int): number of jobs for pdqm
        &#39;&#39;&#39;
        if output_file is None:
            output_file = &#39;DISSONANCE_&#39;+self.year+&#39;.csv&#39;
        result=pqdm(range(len(self.samples)), self.dissonance, n_jobs)
        out_file = output_file

        pd.DataFrame(result,
                    columns=self.polar_features[self.cols].dropna(
                    axis=1).columns).to_csv(out_file)
        self.dissonance_file = out_file
    
    def __choose_one(self,
                   X):
        &#39;&#39;&#39;
        returns a random element of X

        Args:
          X (1D array-like): vector from which random element is to be chosen
        &#39;&#39;&#39;
        X=list(X)
        if len(X)&gt;0:
            return X[np.random.randint(len(X))]
        return None

    def getMaskedSample(self,
                        s,
                        mask_prob=0.5,
                        allow_all_mutable=False):
        &#39;&#39;&#39;
        inputs a sample and randomly mask elements of the sample

        Args:
          s (list[str]): vector of sample, must have the same dimensions as the qnet
          mask_prob (float): float btwn 0 and 1, prob to mask element of sample
          allow_all_mutable (bool): whether or not all variables are mutable
        &#39;&#39;&#39;
        if self.samples is not None:   
            MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()
            WITHVAL=[x for x in self.cols[np.where(s)[0]] if x in self.mutable_vars ]
            MASKrand=[x for x in WITHVAL if random.random() &lt; mask_prob ]
            for m in MASKrand:
                MUTABLE[m]=1.0
            
            mutable_x=MUTABLE.values[0]
            base_frequency=mutable_x/mutable_x.sum()

            # if np.isnan(base_frequency).any():
            #     return np.nan,np.nan,np.nan
            #     return self.getMaskedSample(s)

            s1=s.copy()
            for i in range(len(base_frequency)):
                if base_frequency[i]&gt;0.0001:
                    s1[i]=&#39;&#39;
                    
            s_rand=np.copy(s)
            rnd_match_prob=[]        
            max_match_prob=[]        
            D=self.qnet.predict_distributions(s)
            for i in MASKrand:
                s_rand[np.where(
                    self.cols==i)[0][0]]=self.__choose_one(
                        self.D_null[np.where(self.cols==i)[0][0]].keys())
                rnd_match_prob=np.append(rnd_match_prob,1/len(
                    self.D_null[np.where(self.cols==i)[0][0]].keys()))
                max_match_prob=np.append(
                    max_match_prob,np.max(
                        list(D[np.where(
                            self.cols==i)[0][0]].values())))
                
            if allow_all_mutable:
                for m in mutable_vars:
                    MUTABLE[m]=1.0
                mutable_x=MUTABLE.values[0]
                base_frequency=mutable_x/mutable_x.sum()

            return s1,base_frequency,MASKrand,np.where(
                base_frequency)[0],np.mean(rnd_match_prob),np.mean(max_match_prob),s_rand
        else:
            raise ValueError(&#34;load_data first!&#34;)

    def randomMaskReconstruction(self,
                             return_dict,
                             sample=None,
                             index=None):
        &#34;&#34;&#34;
        reconstruct the masked sample by qsampling and comparing to original
        set self.mask_prob and self.steps if needed

        Args:
          index (int): index of sample to take
          return_dict ([type]): [description]
          sample ([type], optional): [description]. Defaults to None.
          index ([type], optional): [description]. Defaults to None.

        Raises:
          ValueError: [description]
          ValueError: [description]

        Returns:
          [type]: [description]
        &#34;&#34;&#34;
        if all(x is None for x in [sample, index]):
            raise ValueError(&#34;Must input either sample or index!&#34;)
        elif all(x is not None for x in [sample, index]):
            raise ValueError(&#34;Must input either sample or index not both!&#34;)
        elif sample is not None:
            s=pd.DataFrame(sample).fillna(&#39;&#39;).values.astype(str)[:]
        elif index is not None:
            s=self.samples_as_strings[index]
            
        s1,bp,mask_,maskindex,rmatch_u,rmatch,s_rand=self.getMaskedSample(s, 
                                                                          mask_prob=self.mask_prob)
        if np.isnan(bp).any():
            return_dict[index] = np.nan,np.nan,np.nan
            return np.nan,np.nan,np.nan

        qs=qsample(s1,self.qnet,self.steps,bp)

        dqestim=qdistance(s,qs,self.qnet,self.qnet)
        dactual=qdistance(s,s1,self.qnet,self.qnet)
        qdistance_time_end = time.time()

        return_dict[index] = (1 - (dqestim/dactual))*100,rmatch_u,rmatch
        return (1 - (dqestim/dactual))*100,rmatch_u,rmatch

    def predict_maskedsamples(self):
        &#39;&#39;&#39;
        runs and saves the results of the predicted masked sample

        Args:
        &#39;&#39;&#39;
        manager = mp.Manager()
        return_dict = manager.dict()
        processes = []
        
        for i in range(len(self.samples)):
            p = mp.Process(target=self.randomMaskReconstruction, args=(i, return_dict))
            processes.append(p)

        [x.start() for x in processes]
        [x.join() for x in processes]

        result=[x for x in return_dict.values() if isinstance(x, tuple)]
        result=pd.DataFrame(result,columns=[&#39;rederr&#39;,&#39;r_prob&#39;,&#39;rand_err&#39;])
        result.rederr=result.rederr.astype(float)

        if self.poles is not None:
            result.to_csv(&#39;Qnet_Constructor_tmp/rederror_first10_test&#39;+self.year+str(self.steps)+&#39;.csv&#39;)
        else:
            result.to_csv(&#39;Qnet_Constructor_tmp/polar_unrestrict_rederror&#39;+self.year+str(self.steps)+&#39;.csv&#39;)
        
        return result.rederr.mean(), result.rand_err.mean()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="cognet.cognet.cognet"><code class="flex name class">
<span>class <span class="ident">cognet</span></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate related Qnet functions</p>
<p>Init</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class cognet:
    &#34;&#34;&#34;Aggregate related Qnet functions
    &#34;&#34;&#34;

    def __init__(self):
        &#34;&#34;&#34;Init
        &#34;&#34;&#34;
        self.year = None
        self.n_jobs = 28
        self.qnet = None
        self.steps = 120
        self.num_qsamples = None
        self.samples = None
        self.samples_as_strings = None
        self.features = None
        self.cols = None
        self.immutable_vars = None
        self.mutable_vars = None
        self.poles = None
        self.polar_features = None
        self.polar_indices = None
        self.pL = None
        self.pR = None
        self.d0 = None
        self.qdistance_matrix_file = None
        self.dissonance_file = None
        self.s_null = None
        self.D_null = None
        self.mask_prob = 0.5
        self.variation_weight = None
        self.polar_matrix = None
    
    def load_from_model(self,
                        model,
                        im_vars=None,
                        m_vars=None):
        &#34;&#34;&#34;[summary]

        Args:
            model ([type]): [description]
            im_vars ([type], optional): [description]. Defaults to None.
            m_vars ([type], optional): [description]. Defaults to None.
        &#34;&#34;&#34;
        if model is not None:
            self.qnet = model.myQnet
            self.cols = model.features
            self.features = pd.DataFrame(columns=self.cols)
            self.immutable_vars = model.immutable_vars
            self.mutable_vars = model.mutable_vars
            
            samples = pd.DataFrame(model.samples)
            self.samples = pd.concat([samples,self.features], axis=0)
            self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]
            self.s_null=[&#39;&#39;]*len(self.samples_as_strings[0])
            self.D_null=self.qnet.predict_distributions(self.s_null)
            variation_weight = []
            for d in self.D_null:
                v=[]
                for val in d.values():
                    v=np.append(v,val)
                variation_weight.append(entropy(v,base=len(v)))
            self.variation_weight = variation_weight
            
    def load_data(self,
                  year,
                  features_by_year,
                  samples,
                  qnet):
        &#39;&#39;&#39;load cols, features, samples, and qnet.

        Args:
          year (str): to identify cols/features.
          features_by_year (str): file containing all features by year of the dataset.
          samples (str): file of samples for that year.
          Qnet (str): Qnet file location.
        &#39;&#39;&#39;
        self.qnet = load_qnet(qnet)
        self.year = year
        self.cols = np.array((pd.read_csv(features_by_year,
                               keep_default_na=True, 
                               index_col=0).set_index(
                                   &#39;year&#39;)).loc[int(year)].apply(
                                       eval).values[0])
        self.features = pd.DataFrame(columns=self.cols)
        self.mutable_vars = [x for x in self.cols]
        #[self.cols].fillna(&#39;&#39;).values.astype(str)[:]

        self.samples=pd.read_csv(samples)
        self.samples = pd.concat([self.samples,self.features], axis=0)
        self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]
        self.s_null=[&#39;&#39;]*len(self.samples_as_strings[0])
        self.D_null=self.qnet.predict_distributions(self.s_null)
        variation_weight = []
        for d in self.D_null:
            v=[]
            for val in d.values():
                v=np.append(v,val)
            variation_weight.append(entropy(v,base=len(v)))
        self.variation_weight = variation_weight

    def set_immutable_vars(self,
                           IMMUTABLE_FILE):
        &#39;&#39;&#39;
        set vars to immutable and mutable, 
        can prob combine this with the load_data func: only set the immutable vars if necessary

        Args:
          IMMUTABLE_FILE (str): file containing the immutable features/vars
        &#39;&#39;&#39;
        if self.cols is None:
            raise ValueError(&#34;load_data first!&#34;)
        self.immutable_vars = pd.read_csv(IMMUTABLE_FILE,index_col=0).transpose()
        self.mutable_vars = None
        self.mutable_vars = [x for x in self.cols
                             if x.upper() not in self.immutable_vars.columns]
    
    def set_nsamples(self,
                     num_samples):
        &#39;&#39;&#39;
        select a subset of the samples

        Args:
          num_samples (int): Set num of samples to subset
        &#39;&#39;&#39;
        
        if all(x is not None for x in [num_samples, self.samples]):
            if num_samples &gt; len(self.samples.index):
                string = &#39;The number of selected samples ({}) &#39; + \
                     &#39;is greater than the number of samples ({})!&#39;
                string = string.format(num_samples, len(self.samples.index))
                raise ValueError(string)

            if num_samples == len(self.samples.index):
                string = &#39;The number of selected samples ({}) &#39; + \
                     &#39;is equal the number of samples ({})!&#39;
                string = string.format(num_samples, len(self.samples.index))
                print(string)
            #self.samples = self.samples.sample(num_samples)
            self.samples = self.samples[:10]
            self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]

        elif self.samples is None:
            raise ValueError(&#34;load_data first!&#34;)

    def __variation_weight(self,
                           index):
        &#34;&#34;&#34;[summary]

        Args:
            index ([type]): [description]

        Returns:
            [type]: [description]
        &#34;&#34;&#34;
        d_=self.D_null[index]
        v=[]
        for val in d_.values():
            v=np.append(v,val)
        return entropy(v,base=len(v))
    
    def getBaseFrequency(self, 
                         sample):
        &#39;&#39;&#39;
        get frequency of the variables
        helper func for qsampling

        Args:
          sample (list[str]): vector of sample, must have the same dimensions as the qnet
        &#39;&#39;&#39;
        MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()
                
        for m in self.mutable_vars:
            MUTABLE[m]=1.0
        mutable_x=MUTABLE.values[0]
        base_frequency=mutable_x/mutable_x.sum()

        # commented out for now for testing using smaller qnet
        # for i in range(len(base_frequency)):
        #     if base_frequency[i]&gt;0.0:
        #         base_frequency[i]= self.__variation_weight(i)*base_frequency[i]

        return base_frequency/base_frequency.sum()

    def __getBaseFrequency_test(self, 
                         sample):
        &#39;&#39;&#39;
        get frequency of the variables
        helper func for qsampling

        Args:
          sample (list[str]): vector of sample, must have the same dimensions as the qnet
        &#39;&#39;&#39;
        MUTABLE=pd.DataFrame(np.zeros(len(sample)),index=sample).transpose()
                
        for m in sample:
            MUTABLE[m]=1.0
        mutable_x=MUTABLE.values[0]
        base_frequency=mutable_x/mutable_x.sum()

        # commented out for now for testing using smaller qnet
        for i in range(len(base_frequency)):
            if base_frequency[i]&gt;0.0:
                base_frequency[i]= self.variation_weight[i]*base_frequency[i]

        return base_frequency/base_frequency.sum()
    
    def qsampling(self,
                  sample,
                  steps,
                  immutable=False):
        &#39;&#39;&#39;
        perturb the sample based on thet qnet distributions and number of steps

        Args:
          sample (1d array-like): vector of sample, must have the same dimensions as the qnet
          steps (int): number of steps to qsample
          immutable (bool): are there variables that are immutable?
        &#39;&#39;&#39;
        if all(x is not None for x in [self.mutable_vars, self.immutable_vars, sample]):
            if immutable == True:
                return qsample(sample,self.qnet,steps,self.getBaseFrequency(self.samples))
            else:
                return qsample(sample,self.qnet,steps)
        elif self.mutable_vars is None:
            raise ValueError(&#34;load_data first!&#34;)
        elif self.immutable_vars is None:
            raise ValueError(&#34;load immutable variables first!&#34;)

    def set_poles(self,
                  POLEFILE,
                  steps=0,
                  mutable=False):
        &#39;&#39;&#39;
        set the poles and samples such that the samples contain features in poles


        Args:
          steps (int): number of steps to qsample
          POLEFILE (str): file containing poles samples and features
          mutable (boolean): Whether or not to set poles as the only mutable_vars
        &#39;&#39;&#39;
        invalid_count = 0
        if all(x is not None for x in [self.samples]):
            poles = pd.read_csv(POLEFILE, index_col=0)
            L=poles.L.to_dict()
            R=poles.R.to_dict()
            self.poles=poles.transpose()

            cols = [x for x in self.poles.columns if x in self.samples.columns]
            self.samples=self.samples[cols]
        
            for x in self.poles.columns:
                if x not in self.samples.columns:
                    invalid_count += 1
                    self.samples[x]=np.nan

            self.samples = pd.concat([self.samples,self.features], axis=0)
            self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]

            self.polar_features = pd.concat([self.poles, self.features], axis=0)
            pL= self.polar_features.loc[&#39;L&#39;][self.cols].fillna(&#39;&#39;).values.astype(str)[:]
            pR= self.polar_features.loc[&#39;R&#39;][self.cols].fillna(&#39;&#39;).values.astype(str)[:]

            self.pL=self.qsampling(pL,steps)
            self.pR=self.qsampling(pR,steps)
            if mutable:
                self.mutable_vars=[x for x in self.cols if x in self.poles.columns]
        elif self.samples is None:
            raise ValueError(&#34;load_data first!&#34;)
        
        print(&#34;{} pole features not found in sample features&#34;.format(invalid_count))

    def distance(self,
                 sample1,
                 sample2,
                 nsteps1=0,
                 nsteps2=0):
        &#34;&#34;&#34;[summary]

        Args:
            sample1 ([type]): [description]
            sample2 ([type]): [description]
            nsteps1 (int, optional): [description]. Defaults to 0.
            nsteps2 (int, optional): [description]. Defaults to 0.

        Raises:
            ValueError: [description]

        Returns:
            [type]: [description]
        &#34;&#34;&#34;
        if self.qnet is None:
            raise ValueError(&#34;load qnet first!&#34;)
        sample1 = pd.DataFrame(sample1).fillna(&#39;&#39;).values.astype(str)[:]
        sample2 = pd.DataFrame(sample1).fillna(&#39;&#39;).values.astype(str)[:]
        bp1 = self.__getBaseFrequency_test(sample1)
        bp2 = self.__getBaseFrequency_test(sample2)
        print(sample1)
        print(sample1.shape)
        print(bp1.shape)
        sample1 = qsample(sample1, self.qnet, nsteps1, baseline_prob=bp1)
        sample2 = qsample(sample2, self.qnet, nsteps2, baseline_prob=bp2)
        return qdistance(sample1, sample2)
    
    def __distfunc(self, 
                 x, 
                 y):
        &#39;&#39;&#39;
        Compute distance between two samples

        Args:
          x : first sample
          y : second sample
        &#39;&#39;&#39;
        d=qdistance(x,y,self.qnet,self.qnet)
        return d
    
    def polarDistance(self,
                      sample):
        &#34;&#34;&#34;[summary]

        Args:
            sample ([type]): [description]

        Returns:
            [type]: [description]
        &#34;&#34;&#34;
        distances = {}
        for index, row in self.poles.iterrows():
            distances[index] = distance(sample, row)
        return distances
            
    
    def distfunc_line(self,
                   row):
        &#39;&#39;&#39;
        compute the dist for a row, or vector of samples

        Args:
          k (int): row
        return:
          numpy.ndarray(float)
        &#39;&#39;&#39;
        if all(x is not None for x in [self.samples, self.features]):
            w = self.samples.index.size
            p_all = pd.concat([self.samples, self.features], axis=0)[cols].fillna(&#39;&#39;).values.astype(str)[:]
            line = np.zeros(w)
            y = p_all[row]
            for j in range(w):
                # only compute half of the distance matrix
                if j &gt; row:
                    x = p_all[j]
                    line[j] = self.__distfunc(x, y)
        else:
            raise ValueError(&#34;load_data first!&#34;)
        return line
    
    def polar_separation(self,
                         nsteps=0):
        &#34;&#34;&#34;[summary]

        Args:
            nsteps (int, optional): [description]. Defaults to 0.

        Returns:
            [type]: [description]
        &#34;&#34;&#34;
        polar_arraydata = self.polar_features[self.cols].fillna(&#39;&#39;).values.astype(str)[:]
        print(&#34;testing polar_separation&#34;)
        print(polar_arraydata)
        samples_ = []
        for vector in polar_arraydata:
            bp = self.getBaseFrequency(vector)
            sample = qsample(vector, self.qnet, nsteps, baseline_prob=bp)
            samples_.append(sample)
        self.polar_matrix = qdistance_matrix(samples_, samples_, self.qnet, self.qnet)
        return self.polar_matrix
        
    def embed(self,
              infile,
              name_pref,
              out_dir):
        &#39;&#39;&#39;
        embed data

        Args:
          infile (str): input file to be embedded
          name_pref (str): preferred name for output file
          out_dir (str): output dir for results
        &#39;&#39;&#39;
        if all(x is not None for x in [self.year]):
            yr = self.year
            PREF = name_pref
            FILE = infile

            EMBED = &#39;../GSS/bin/embed&#39;
            DATAFILE = &#39;data_&#39; +yr
            EFILE = out_dir + PREF + &#39;_E_&#39; +yr
            DFILE = out_dir + PREF + &#39;_D_&#39; +yr

            pd.read_csv(infile,header=None).to_csv(out_dir + DATAFILE,sep=&#39; &#39;,header=None,index=None)
            STR=EMBED+&#39; -f &#39;+DATAFILE+&#39; -E &#39;+EFILE+&#39; -D &#39;+DFILE
            subprocess.call(STR,shell=True)
        elif self.year is None:
            raise ValueError(&#34;load_data first!&#34;)
    
    def compute_DLI_sample(self,
                           i,):
        &#39;&#39;&#39;
        return ideology index, dL, dR, Qsd (std), Q (max) for one sample

        Args:
          i (int): index of sample
        &#39;&#39;&#39;
        p = self.samples_as_strings[i]
        dR = qdistance(self.pR, p, self.qnet, self.qnet)
        dL = qdistance(self.pL, p, self.qnet, self.qnet)
        ideology_index = (dR-dL)/self.d0
        
        Qset = [qsample(p, self.qnet, self.steps) for j in np.arange(self.num_qsamples)]
        Qset = np.array(Qset)

        matrix = (qdistance_matrix(Qset, Qset, self.qnet, self.qnet))
        Q = matrix.max()
        Qsd = matrix.std()

        return [ideology_index, dL, dR, Qsd, Q]
       
    def compute_DLI_samples(self,
                    num_qsamples,
                    outfile,
                    steps=5,
                    n_jobs=28):
        &#39;&#39;&#39;
        compute and save ideology index, dL, dR, Qsd (std), Q (max) for all samples

        Args:
          num_qsamples (int): number of qsamples to compute
          steps (int): number of steps to qsample
          outfile (str): output file for results
        &#39;&#39;&#39;
        if all(x is not None for x in [self.samples, self.features,
                                    self.pL, self.pR]):
            self.num_qsamples = num_qsamples
            self.steps = steps
            self.d0 = qdistance(self.pL, self.pR, self.qnet, self.qnet)

            result=pqdm(range(len(self.samples)), self.compute_DLI, n_jobs)
            pd.DataFrame(result,
                        columns=[&#39;ido&#39;, &#39;dL&#39;, &#39;dR&#39;, &#39;Qsd&#39;, &#39;Q&#39;]).to_csv(outfile)

        elif self.pL is None or self.pR is None:
            raise ValueError(&#34;set_poles first!&#34;)
        else:
            raise ValueError(&#34;load_data first!&#34;)
    
    def compute_polar_indices(self,
                              num_samples = None,
                              polar_comp = False,
                              POLEFILE = None,
                              steps = 5):
        &#39;&#39;&#39;
        set up polar indices for dissonance func

        Args:
          num_samples (int): subset of samples to take
          polar_comp (bool): whether or not to set poles
          POLEFILE (None): file containing pole samples and features
          steps (int): number of steps to qsample
        &#39;&#39;&#39;
        if all(x is not None for x in [self.samples, self.features, self.poles]):
            if num_samples is not None:
                self.set_nsamples(num_samples)

            # read sample data
            if polar_comp:
                self.set_poles(self.qnet, steps, POLEFILE)
            
            polar_features = pd.concat([self.poles, self.features], axis=0)
            self.polar_indices=np.where(polar_features[self.cols].fillna(&#39;XXXX&#39;).values[0]!=&#39;XXXX&#39;)[0]
        
        elif self.poles is None:
            raise ValueError(&#34;set_poles first!&#34;)
        else:
            raise ValueError(&#34;load_data first!&#34;)

    def dissonance(self,
                sample_index,
                MISSING_VAL=0.0):
        &#39;&#39;&#39;
        compute dissonance for each sample_index, helper function for all_dissonance
        
        Args:
          sample_index (int): index of the sample to compute dissonance
          MISSING_VAL (float): 
        &#39;&#39;&#39;
        if all(x is not None for x in [self.samples, self.features, 
                                       self.poles]):
            s = self.samples_as_strings[sample_index]
            if self.polar_indices is None:
                self.polar_indices = range(len(s))

            Ds=self.qnet.predict_distributions(s)
            
            diss=np.ones(len(Ds))*MISSING_VAL
            for i in self.polar_indices:
                if s[i] != &#39;&#39;:
                    if s[i] in Ds[i].keys():
                        diss[i]=1-Ds[i][s[i]]/np.max(
                            list(Ds[i].values())) 
                    else:
                        diss[i]=1.0
            return diss[self.polar_indices]

        elif self.poles is None:
            raise ValueError(&#34;set_poles first!&#34;)
        else:
            raise ValueError(&#34;load_data first!&#34;)
    
    def dissonance_matrix(self,
                          output_file=None,
                          n_jobs=28):
        &#39;&#39;&#39;
        get the dissonance for all samples

        Args:
          output_file (str): directory and/or file for output
          n_jobs (int): number of jobs for pdqm
        &#39;&#39;&#39;
        if output_file is None:
            output_file = &#39;DISSONANCE_&#39;+self.year+&#39;.csv&#39;
        result=pqdm(range(len(self.samples)), self.dissonance, n_jobs)
        out_file = output_file

        pd.DataFrame(result,
                    columns=self.polar_features[self.cols].dropna(
                    axis=1).columns).to_csv(out_file)
        self.dissonance_file = out_file
    
    def __choose_one(self,
                   X):
        &#39;&#39;&#39;
        returns a random element of X

        Args:
          X (1D array-like): vector from which random element is to be chosen
        &#39;&#39;&#39;
        X=list(X)
        if len(X)&gt;0:
            return X[np.random.randint(len(X))]
        return None

    def getMaskedSample(self,
                        s,
                        mask_prob=0.5,
                        allow_all_mutable=False):
        &#39;&#39;&#39;
        inputs a sample and randomly mask elements of the sample

        Args:
          s (list[str]): vector of sample, must have the same dimensions as the qnet
          mask_prob (float): float btwn 0 and 1, prob to mask element of sample
          allow_all_mutable (bool): whether or not all variables are mutable
        &#39;&#39;&#39;
        if self.samples is not None:   
            MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()
            WITHVAL=[x for x in self.cols[np.where(s)[0]] if x in self.mutable_vars ]
            MASKrand=[x for x in WITHVAL if random.random() &lt; mask_prob ]
            for m in MASKrand:
                MUTABLE[m]=1.0
            
            mutable_x=MUTABLE.values[0]
            base_frequency=mutable_x/mutable_x.sum()

            # if np.isnan(base_frequency).any():
            #     return np.nan,np.nan,np.nan
            #     return self.getMaskedSample(s)

            s1=s.copy()
            for i in range(len(base_frequency)):
                if base_frequency[i]&gt;0.0001:
                    s1[i]=&#39;&#39;
                    
            s_rand=np.copy(s)
            rnd_match_prob=[]        
            max_match_prob=[]        
            D=self.qnet.predict_distributions(s)
            for i in MASKrand:
                s_rand[np.where(
                    self.cols==i)[0][0]]=self.__choose_one(
                        self.D_null[np.where(self.cols==i)[0][0]].keys())
                rnd_match_prob=np.append(rnd_match_prob,1/len(
                    self.D_null[np.where(self.cols==i)[0][0]].keys()))
                max_match_prob=np.append(
                    max_match_prob,np.max(
                        list(D[np.where(
                            self.cols==i)[0][0]].values())))
                
            if allow_all_mutable:
                for m in mutable_vars:
                    MUTABLE[m]=1.0
                mutable_x=MUTABLE.values[0]
                base_frequency=mutable_x/mutable_x.sum()

            return s1,base_frequency,MASKrand,np.where(
                base_frequency)[0],np.mean(rnd_match_prob),np.mean(max_match_prob),s_rand
        else:
            raise ValueError(&#34;load_data first!&#34;)

    def randomMaskReconstruction(self,
                             return_dict,
                             sample=None,
                             index=None):
        &#34;&#34;&#34;
        reconstruct the masked sample by qsampling and comparing to original
        set self.mask_prob and self.steps if needed

        Args:
          index (int): index of sample to take
          return_dict ([type]): [description]
          sample ([type], optional): [description]. Defaults to None.
          index ([type], optional): [description]. Defaults to None.

        Raises:
          ValueError: [description]
          ValueError: [description]

        Returns:
          [type]: [description]
        &#34;&#34;&#34;
        if all(x is None for x in [sample, index]):
            raise ValueError(&#34;Must input either sample or index!&#34;)
        elif all(x is not None for x in [sample, index]):
            raise ValueError(&#34;Must input either sample or index not both!&#34;)
        elif sample is not None:
            s=pd.DataFrame(sample).fillna(&#39;&#39;).values.astype(str)[:]
        elif index is not None:
            s=self.samples_as_strings[index]
            
        s1,bp,mask_,maskindex,rmatch_u,rmatch,s_rand=self.getMaskedSample(s, 
                                                                          mask_prob=self.mask_prob)
        if np.isnan(bp).any():
            return_dict[index] = np.nan,np.nan,np.nan
            return np.nan,np.nan,np.nan

        qs=qsample(s1,self.qnet,self.steps,bp)

        dqestim=qdistance(s,qs,self.qnet,self.qnet)
        dactual=qdistance(s,s1,self.qnet,self.qnet)
        qdistance_time_end = time.time()

        return_dict[index] = (1 - (dqestim/dactual))*100,rmatch_u,rmatch
        return (1 - (dqestim/dactual))*100,rmatch_u,rmatch

    def predict_maskedsamples(self):
        &#39;&#39;&#39;
        runs and saves the results of the predicted masked sample

        Args:
        &#39;&#39;&#39;
        manager = mp.Manager()
        return_dict = manager.dict()
        processes = []
        
        for i in range(len(self.samples)):
            p = mp.Process(target=self.randomMaskReconstruction, args=(i, return_dict))
            processes.append(p)

        [x.start() for x in processes]
        [x.join() for x in processes]

        result=[x for x in return_dict.values() if isinstance(x, tuple)]
        result=pd.DataFrame(result,columns=[&#39;rederr&#39;,&#39;r_prob&#39;,&#39;rand_err&#39;])
        result.rederr=result.rederr.astype(float)

        if self.poles is not None:
            result.to_csv(&#39;Qnet_Constructor_tmp/rederror_first10_test&#39;+self.year+str(self.steps)+&#39;.csv&#39;)
        else:
            result.to_csv(&#39;Qnet_Constructor_tmp/polar_unrestrict_rederror&#39;+self.year+str(self.steps)+&#39;.csv&#39;)
        
        return result.rederr.mean(), result.rand_err.mean()</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="cognet.cognet.cognet.compute_DLI_sample"><code class="name flex">
<span>def <span class="ident">compute_DLI_sample</span></span>(<span>self, i)</span>
</code></dt>
<dd>
<div class="desc"><p>return ideology index, dL, dR, Qsd (std), Q (max) for one sample</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>i</code></strong> :&ensp;<code>int</code></dt>
<dd>index of sample</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_DLI_sample(self,
                       i,):
    &#39;&#39;&#39;
    return ideology index, dL, dR, Qsd (std), Q (max) for one sample

    Args:
      i (int): index of sample
    &#39;&#39;&#39;
    p = self.samples_as_strings[i]
    dR = qdistance(self.pR, p, self.qnet, self.qnet)
    dL = qdistance(self.pL, p, self.qnet, self.qnet)
    ideology_index = (dR-dL)/self.d0
    
    Qset = [qsample(p, self.qnet, self.steps) for j in np.arange(self.num_qsamples)]
    Qset = np.array(Qset)

    matrix = (qdistance_matrix(Qset, Qset, self.qnet, self.qnet))
    Q = matrix.max()
    Qsd = matrix.std()

    return [ideology_index, dL, dR, Qsd, Q]</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.compute_DLI_samples"><code class="name flex">
<span>def <span class="ident">compute_DLI_samples</span></span>(<span>self, num_qsamples, outfile, steps=5, n_jobs=28)</span>
</code></dt>
<dd>
<div class="desc"><p>compute and save ideology index, dL, dR, Qsd (std), Q (max) for all samples</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>num_qsamples</code></strong> :&ensp;<code>int</code></dt>
<dd>number of qsamples to compute</dd>
<dt><strong><code>steps</code></strong> :&ensp;<code>int</code></dt>
<dd>number of steps to qsample</dd>
<dt><strong><code>outfile</code></strong> :&ensp;<code>str</code></dt>
<dd>output file for results</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_DLI_samples(self,
                num_qsamples,
                outfile,
                steps=5,
                n_jobs=28):
    &#39;&#39;&#39;
    compute and save ideology index, dL, dR, Qsd (std), Q (max) for all samples

    Args:
      num_qsamples (int): number of qsamples to compute
      steps (int): number of steps to qsample
      outfile (str): output file for results
    &#39;&#39;&#39;
    if all(x is not None for x in [self.samples, self.features,
                                self.pL, self.pR]):
        self.num_qsamples = num_qsamples
        self.steps = steps
        self.d0 = qdistance(self.pL, self.pR, self.qnet, self.qnet)

        result=pqdm(range(len(self.samples)), self.compute_DLI, n_jobs)
        pd.DataFrame(result,
                    columns=[&#39;ido&#39;, &#39;dL&#39;, &#39;dR&#39;, &#39;Qsd&#39;, &#39;Q&#39;]).to_csv(outfile)

    elif self.pL is None or self.pR is None:
        raise ValueError(&#34;set_poles first!&#34;)
    else:
        raise ValueError(&#34;load_data first!&#34;)</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.compute_polar_indices"><code class="name flex">
<span>def <span class="ident">compute_polar_indices</span></span>(<span>self, num_samples=None, polar_comp=False, POLEFILE=None, steps=5)</span>
</code></dt>
<dd>
<div class="desc"><p>set up polar indices for dissonance func</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>num_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>subset of samples to take</dd>
<dt><strong><code>polar_comp</code></strong> :&ensp;<code>bool</code></dt>
<dd>whether or not to set poles</dd>
<dt><strong><code>POLEFILE</code></strong> :&ensp;<code>None</code></dt>
<dd>file containing pole samples and features</dd>
<dt><strong><code>steps</code></strong> :&ensp;<code>int</code></dt>
<dd>number of steps to qsample</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_polar_indices(self,
                          num_samples = None,
                          polar_comp = False,
                          POLEFILE = None,
                          steps = 5):
    &#39;&#39;&#39;
    set up polar indices for dissonance func

    Args:
      num_samples (int): subset of samples to take
      polar_comp (bool): whether or not to set poles
      POLEFILE (None): file containing pole samples and features
      steps (int): number of steps to qsample
    &#39;&#39;&#39;
    if all(x is not None for x in [self.samples, self.features, self.poles]):
        if num_samples is not None:
            self.set_nsamples(num_samples)

        # read sample data
        if polar_comp:
            self.set_poles(self.qnet, steps, POLEFILE)
        
        polar_features = pd.concat([self.poles, self.features], axis=0)
        self.polar_indices=np.where(polar_features[self.cols].fillna(&#39;XXXX&#39;).values[0]!=&#39;XXXX&#39;)[0]
    
    elif self.poles is None:
        raise ValueError(&#34;set_poles first!&#34;)
    else:
        raise ValueError(&#34;load_data first!&#34;)</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.dissonance"><code class="name flex">
<span>def <span class="ident">dissonance</span></span>(<span>self, sample_index, MISSING_VAL=0.0)</span>
</code></dt>
<dd>
<div class="desc"><p>compute dissonance for each sample_index, helper function for all_dissonance</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sample_index</code></strong> :&ensp;<code>int</code></dt>
<dd>index of the sample to compute dissonance</dd>
</dl>
<p>MISSING_VAL (float):</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dissonance(self,
            sample_index,
            MISSING_VAL=0.0):
    &#39;&#39;&#39;
    compute dissonance for each sample_index, helper function for all_dissonance
    
    Args:
      sample_index (int): index of the sample to compute dissonance
      MISSING_VAL (float): 
    &#39;&#39;&#39;
    if all(x is not None for x in [self.samples, self.features, 
                                   self.poles]):
        s = self.samples_as_strings[sample_index]
        if self.polar_indices is None:
            self.polar_indices = range(len(s))

        Ds=self.qnet.predict_distributions(s)
        
        diss=np.ones(len(Ds))*MISSING_VAL
        for i in self.polar_indices:
            if s[i] != &#39;&#39;:
                if s[i] in Ds[i].keys():
                    diss[i]=1-Ds[i][s[i]]/np.max(
                        list(Ds[i].values())) 
                else:
                    diss[i]=1.0
        return diss[self.polar_indices]

    elif self.poles is None:
        raise ValueError(&#34;set_poles first!&#34;)
    else:
        raise ValueError(&#34;load_data first!&#34;)</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.dissonance_matrix"><code class="name flex">
<span>def <span class="ident">dissonance_matrix</span></span>(<span>self, output_file=None, n_jobs=28)</span>
</code></dt>
<dd>
<div class="desc"><p>get the dissonance for all samples</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>output_file</code></strong> :&ensp;<code>str</code></dt>
<dd>directory and/or file for output</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code></dt>
<dd>number of jobs for pdqm</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dissonance_matrix(self,
                      output_file=None,
                      n_jobs=28):
    &#39;&#39;&#39;
    get the dissonance for all samples

    Args:
      output_file (str): directory and/or file for output
      n_jobs (int): number of jobs for pdqm
    &#39;&#39;&#39;
    if output_file is None:
        output_file = &#39;DISSONANCE_&#39;+self.year+&#39;.csv&#39;
    result=pqdm(range(len(self.samples)), self.dissonance, n_jobs)
    out_file = output_file

    pd.DataFrame(result,
                columns=self.polar_features[self.cols].dropna(
                axis=1).columns).to_csv(out_file)
    self.dissonance_file = out_file</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.distance"><code class="name flex">
<span>def <span class="ident">distance</span></span>(<span>self, sample1, sample2, nsteps1=0, nsteps2=0)</span>
</code></dt>
<dd>
<div class="desc"><p>[summary]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sample1</code></strong> :&ensp;<code>[type]</code></dt>
<dd>[description]</dd>
<dt><strong><code>sample2</code></strong> :&ensp;<code>[type]</code></dt>
<dd>[description]</dd>
<dt><strong><code>nsteps1</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>[description]. Defaults to 0.</dd>
<dt><strong><code>nsteps2</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>[description]. Defaults to 0.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>[description]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>[type]</code></dt>
<dd>[description]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def distance(self,
             sample1,
             sample2,
             nsteps1=0,
             nsteps2=0):
    &#34;&#34;&#34;[summary]

    Args:
        sample1 ([type]): [description]
        sample2 ([type]): [description]
        nsteps1 (int, optional): [description]. Defaults to 0.
        nsteps2 (int, optional): [description]. Defaults to 0.

    Raises:
        ValueError: [description]

    Returns:
        [type]: [description]
    &#34;&#34;&#34;
    if self.qnet is None:
        raise ValueError(&#34;load qnet first!&#34;)
    sample1 = pd.DataFrame(sample1).fillna(&#39;&#39;).values.astype(str)[:]
    sample2 = pd.DataFrame(sample1).fillna(&#39;&#39;).values.astype(str)[:]
    bp1 = self.__getBaseFrequency_test(sample1)
    bp2 = self.__getBaseFrequency_test(sample2)
    print(sample1)
    print(sample1.shape)
    print(bp1.shape)
    sample1 = qsample(sample1, self.qnet, nsteps1, baseline_prob=bp1)
    sample2 = qsample(sample2, self.qnet, nsteps2, baseline_prob=bp2)
    return qdistance(sample1, sample2)</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.distfunc_line"><code class="name flex">
<span>def <span class="ident">distfunc_line</span></span>(<span>self, row)</span>
</code></dt>
<dd>
<div class="desc"><p>compute the dist for a row, or vector of samples</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>k</code></strong> :&ensp;<code>int</code></dt>
<dd>row</dd>
</dl>
<p>return:
numpy.ndarray(float)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def distfunc_line(self,
               row):
    &#39;&#39;&#39;
    compute the dist for a row, or vector of samples

    Args:
      k (int): row
    return:
      numpy.ndarray(float)
    &#39;&#39;&#39;
    if all(x is not None for x in [self.samples, self.features]):
        w = self.samples.index.size
        p_all = pd.concat([self.samples, self.features], axis=0)[cols].fillna(&#39;&#39;).values.astype(str)[:]
        line = np.zeros(w)
        y = p_all[row]
        for j in range(w):
            # only compute half of the distance matrix
            if j &gt; row:
                x = p_all[j]
                line[j] = self.__distfunc(x, y)
    else:
        raise ValueError(&#34;load_data first!&#34;)
    return line</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.embed"><code class="name flex">
<span>def <span class="ident">embed</span></span>(<span>self, infile, name_pref, out_dir)</span>
</code></dt>
<dd>
<div class="desc"><p>embed data</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>infile</code></strong> :&ensp;<code>str</code></dt>
<dd>input file to be embedded</dd>
<dt><strong><code>name_pref</code></strong> :&ensp;<code>str</code></dt>
<dd>preferred name for output file</dd>
<dt><strong><code>out_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>output dir for results</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def embed(self,
          infile,
          name_pref,
          out_dir):
    &#39;&#39;&#39;
    embed data

    Args:
      infile (str): input file to be embedded
      name_pref (str): preferred name for output file
      out_dir (str): output dir for results
    &#39;&#39;&#39;
    if all(x is not None for x in [self.year]):
        yr = self.year
        PREF = name_pref
        FILE = infile

        EMBED = &#39;../GSS/bin/embed&#39;
        DATAFILE = &#39;data_&#39; +yr
        EFILE = out_dir + PREF + &#39;_E_&#39; +yr
        DFILE = out_dir + PREF + &#39;_D_&#39; +yr

        pd.read_csv(infile,header=None).to_csv(out_dir + DATAFILE,sep=&#39; &#39;,header=None,index=None)
        STR=EMBED+&#39; -f &#39;+DATAFILE+&#39; -E &#39;+EFILE+&#39; -D &#39;+DFILE
        subprocess.call(STR,shell=True)
    elif self.year is None:
        raise ValueError(&#34;load_data first!&#34;)</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.getBaseFrequency"><code class="name flex">
<span>def <span class="ident">getBaseFrequency</span></span>(<span>self, sample)</span>
</code></dt>
<dd>
<div class="desc"><p>get frequency of the variables
helper func for qsampling</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sample</code></strong> :&ensp;<code>list[str]</code></dt>
<dd>vector of sample, must have the same dimensions as the qnet</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getBaseFrequency(self, 
                     sample):
    &#39;&#39;&#39;
    get frequency of the variables
    helper func for qsampling

    Args:
      sample (list[str]): vector of sample, must have the same dimensions as the qnet
    &#39;&#39;&#39;
    MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()
            
    for m in self.mutable_vars:
        MUTABLE[m]=1.0
    mutable_x=MUTABLE.values[0]
    base_frequency=mutable_x/mutable_x.sum()

    # commented out for now for testing using smaller qnet
    # for i in range(len(base_frequency)):
    #     if base_frequency[i]&gt;0.0:
    #         base_frequency[i]= self.__variation_weight(i)*base_frequency[i]

    return base_frequency/base_frequency.sum()</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.getMaskedSample"><code class="name flex">
<span>def <span class="ident">getMaskedSample</span></span>(<span>self, s, mask_prob=0.5, allow_all_mutable=False)</span>
</code></dt>
<dd>
<div class="desc"><p>inputs a sample and randomly mask elements of the sample</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>s</code></strong> :&ensp;<code>list[str]</code></dt>
<dd>vector of sample, must have the same dimensions as the qnet</dd>
<dt><strong><code>mask_prob</code></strong> :&ensp;<code>float</code></dt>
<dd>float btwn 0 and 1, prob to mask element of sample</dd>
<dt><strong><code>allow_all_mutable</code></strong> :&ensp;<code>bool</code></dt>
<dd>whether or not all variables are mutable</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getMaskedSample(self,
                    s,
                    mask_prob=0.5,
                    allow_all_mutable=False):
    &#39;&#39;&#39;
    inputs a sample and randomly mask elements of the sample

    Args:
      s (list[str]): vector of sample, must have the same dimensions as the qnet
      mask_prob (float): float btwn 0 and 1, prob to mask element of sample
      allow_all_mutable (bool): whether or not all variables are mutable
    &#39;&#39;&#39;
    if self.samples is not None:   
        MUTABLE=pd.DataFrame(np.zeros(len(self.cols)),index=self.cols).transpose()
        WITHVAL=[x for x in self.cols[np.where(s)[0]] if x in self.mutable_vars ]
        MASKrand=[x for x in WITHVAL if random.random() &lt; mask_prob ]
        for m in MASKrand:
            MUTABLE[m]=1.0
        
        mutable_x=MUTABLE.values[0]
        base_frequency=mutable_x/mutable_x.sum()

        # if np.isnan(base_frequency).any():
        #     return np.nan,np.nan,np.nan
        #     return self.getMaskedSample(s)

        s1=s.copy()
        for i in range(len(base_frequency)):
            if base_frequency[i]&gt;0.0001:
                s1[i]=&#39;&#39;
                
        s_rand=np.copy(s)
        rnd_match_prob=[]        
        max_match_prob=[]        
        D=self.qnet.predict_distributions(s)
        for i in MASKrand:
            s_rand[np.where(
                self.cols==i)[0][0]]=self.__choose_one(
                    self.D_null[np.where(self.cols==i)[0][0]].keys())
            rnd_match_prob=np.append(rnd_match_prob,1/len(
                self.D_null[np.where(self.cols==i)[0][0]].keys()))
            max_match_prob=np.append(
                max_match_prob,np.max(
                    list(D[np.where(
                        self.cols==i)[0][0]].values())))
            
        if allow_all_mutable:
            for m in mutable_vars:
                MUTABLE[m]=1.0
            mutable_x=MUTABLE.values[0]
            base_frequency=mutable_x/mutable_x.sum()

        return s1,base_frequency,MASKrand,np.where(
            base_frequency)[0],np.mean(rnd_match_prob),np.mean(max_match_prob),s_rand
    else:
        raise ValueError(&#34;load_data first!&#34;)</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.load_data"><code class="name flex">
<span>def <span class="ident">load_data</span></span>(<span>self, year, features_by_year, samples, qnet)</span>
</code></dt>
<dd>
<div class="desc"><p>load cols, features, samples, and qnet.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>year</code></strong> :&ensp;<code>str</code></dt>
<dd>to identify cols/features.</dd>
<dt><strong><code>features_by_year</code></strong> :&ensp;<code>str</code></dt>
<dd>file containing all features by year of the dataset.</dd>
<dt><strong><code>samples</code></strong> :&ensp;<code>str</code></dt>
<dd>file of samples for that year.</dd>
<dt><strong><code>Qnet</code></strong> :&ensp;<code>str</code></dt>
<dd>Qnet file location.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_data(self,
              year,
              features_by_year,
              samples,
              qnet):
    &#39;&#39;&#39;load cols, features, samples, and qnet.

    Args:
      year (str): to identify cols/features.
      features_by_year (str): file containing all features by year of the dataset.
      samples (str): file of samples for that year.
      Qnet (str): Qnet file location.
    &#39;&#39;&#39;
    self.qnet = load_qnet(qnet)
    self.year = year
    self.cols = np.array((pd.read_csv(features_by_year,
                           keep_default_na=True, 
                           index_col=0).set_index(
                               &#39;year&#39;)).loc[int(year)].apply(
                                   eval).values[0])
    self.features = pd.DataFrame(columns=self.cols)
    self.mutable_vars = [x for x in self.cols]
    #[self.cols].fillna(&#39;&#39;).values.astype(str)[:]

    self.samples=pd.read_csv(samples)
    self.samples = pd.concat([self.samples,self.features], axis=0)
    self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]
    self.s_null=[&#39;&#39;]*len(self.samples_as_strings[0])
    self.D_null=self.qnet.predict_distributions(self.s_null)
    variation_weight = []
    for d in self.D_null:
        v=[]
        for val in d.values():
            v=np.append(v,val)
        variation_weight.append(entropy(v,base=len(v)))
    self.variation_weight = variation_weight</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.load_from_model"><code class="name flex">
<span>def <span class="ident">load_from_model</span></span>(<span>self, model, im_vars=None, m_vars=None)</span>
</code></dt>
<dd>
<div class="desc"><p>[summary]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>[type]</code></dt>
<dd>[description]</dd>
<dt><strong><code>im_vars</code></strong> :&ensp;<code>[type]</code>, optional</dt>
<dd>[description]. Defaults to None.</dd>
<dt><strong><code>m_vars</code></strong> :&ensp;<code>[type]</code>, optional</dt>
<dd>[description]. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_from_model(self,
                    model,
                    im_vars=None,
                    m_vars=None):
    &#34;&#34;&#34;[summary]

    Args:
        model ([type]): [description]
        im_vars ([type], optional): [description]. Defaults to None.
        m_vars ([type], optional): [description]. Defaults to None.
    &#34;&#34;&#34;
    if model is not None:
        self.qnet = model.myQnet
        self.cols = model.features
        self.features = pd.DataFrame(columns=self.cols)
        self.immutable_vars = model.immutable_vars
        self.mutable_vars = model.mutable_vars
        
        samples = pd.DataFrame(model.samples)
        self.samples = pd.concat([samples,self.features], axis=0)
        self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]
        self.s_null=[&#39;&#39;]*len(self.samples_as_strings[0])
        self.D_null=self.qnet.predict_distributions(self.s_null)
        variation_weight = []
        for d in self.D_null:
            v=[]
            for val in d.values():
                v=np.append(v,val)
            variation_weight.append(entropy(v,base=len(v)))
        self.variation_weight = variation_weight</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.polarDistance"><code class="name flex">
<span>def <span class="ident">polarDistance</span></span>(<span>self, sample)</span>
</code></dt>
<dd>
<div class="desc"><p>[summary]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sample</code></strong> :&ensp;<code>[type]</code></dt>
<dd>[description]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>[type]</code></dt>
<dd>[description]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def polarDistance(self,
                  sample):
    &#34;&#34;&#34;[summary]

    Args:
        sample ([type]): [description]

    Returns:
        [type]: [description]
    &#34;&#34;&#34;
    distances = {}
    for index, row in self.poles.iterrows():
        distances[index] = distance(sample, row)
    return distances</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.polar_separation"><code class="name flex">
<span>def <span class="ident">polar_separation</span></span>(<span>self, nsteps=0)</span>
</code></dt>
<dd>
<div class="desc"><p>[summary]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>nsteps</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>[description]. Defaults to 0.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>[type]</code></dt>
<dd>[description]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def polar_separation(self,
                     nsteps=0):
    &#34;&#34;&#34;[summary]

    Args:
        nsteps (int, optional): [description]. Defaults to 0.

    Returns:
        [type]: [description]
    &#34;&#34;&#34;
    polar_arraydata = self.polar_features[self.cols].fillna(&#39;&#39;).values.astype(str)[:]
    print(&#34;testing polar_separation&#34;)
    print(polar_arraydata)
    samples_ = []
    for vector in polar_arraydata:
        bp = self.getBaseFrequency(vector)
        sample = qsample(vector, self.qnet, nsteps, baseline_prob=bp)
        samples_.append(sample)
    self.polar_matrix = qdistance_matrix(samples_, samples_, self.qnet, self.qnet)
    return self.polar_matrix</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.predict_maskedsamples"><code class="name flex">
<span>def <span class="ident">predict_maskedsamples</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>runs and saves the results of the predicted masked sample</p>
<p>Args:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_maskedsamples(self):
    &#39;&#39;&#39;
    runs and saves the results of the predicted masked sample

    Args:
    &#39;&#39;&#39;
    manager = mp.Manager()
    return_dict = manager.dict()
    processes = []
    
    for i in range(len(self.samples)):
        p = mp.Process(target=self.randomMaskReconstruction, args=(i, return_dict))
        processes.append(p)

    [x.start() for x in processes]
    [x.join() for x in processes]

    result=[x for x in return_dict.values() if isinstance(x, tuple)]
    result=pd.DataFrame(result,columns=[&#39;rederr&#39;,&#39;r_prob&#39;,&#39;rand_err&#39;])
    result.rederr=result.rederr.astype(float)

    if self.poles is not None:
        result.to_csv(&#39;Qnet_Constructor_tmp/rederror_first10_test&#39;+self.year+str(self.steps)+&#39;.csv&#39;)
    else:
        result.to_csv(&#39;Qnet_Constructor_tmp/polar_unrestrict_rederror&#39;+self.year+str(self.steps)+&#39;.csv&#39;)
    
    return result.rederr.mean(), result.rand_err.mean()</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.qsampling"><code class="name flex">
<span>def <span class="ident">qsampling</span></span>(<span>self, sample, steps, immutable=False)</span>
</code></dt>
<dd>
<div class="desc"><p>perturb the sample based on thet qnet distributions and number of steps</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sample</code></strong> :&ensp;<code>1d array-like</code></dt>
<dd>vector of sample, must have the same dimensions as the qnet</dd>
<dt><strong><code>steps</code></strong> :&ensp;<code>int</code></dt>
<dd>number of steps to qsample</dd>
<dt><strong><code>immutable</code></strong> :&ensp;<code>bool</code></dt>
<dd>are there variables that are immutable?</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def qsampling(self,
              sample,
              steps,
              immutable=False):
    &#39;&#39;&#39;
    perturb the sample based on thet qnet distributions and number of steps

    Args:
      sample (1d array-like): vector of sample, must have the same dimensions as the qnet
      steps (int): number of steps to qsample
      immutable (bool): are there variables that are immutable?
    &#39;&#39;&#39;
    if all(x is not None for x in [self.mutable_vars, self.immutable_vars, sample]):
        if immutable == True:
            return qsample(sample,self.qnet,steps,self.getBaseFrequency(self.samples))
        else:
            return qsample(sample,self.qnet,steps)
    elif self.mutable_vars is None:
        raise ValueError(&#34;load_data first!&#34;)
    elif self.immutable_vars is None:
        raise ValueError(&#34;load immutable variables first!&#34;)</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.randomMaskReconstruction"><code class="name flex">
<span>def <span class="ident">randomMaskReconstruction</span></span>(<span>self, return_dict, sample=None, index=None)</span>
</code></dt>
<dd>
<div class="desc"><p>reconstruct the masked sample by qsampling and comparing to original
set self.mask_prob and self.steps if needed</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>index</code></strong> :&ensp;<code>int</code></dt>
<dd>index of sample to take</dd>
<dt><strong><code>return_dict</code></strong> :&ensp;<code>[type]</code></dt>
<dd>[description]</dd>
<dt><strong><code>sample</code></strong> :&ensp;<code>[type]</code>, optional</dt>
<dd>[description]. Defaults to None.</dd>
<dt><strong><code>index</code></strong> :&ensp;<code>[type]</code>, optional</dt>
<dd>[description]. Defaults to None.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>[description]</dd>
<dt><code>ValueError</code></dt>
<dd>[description]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>[type]</code></dt>
<dd>[description]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def randomMaskReconstruction(self,
                         return_dict,
                         sample=None,
                         index=None):
    &#34;&#34;&#34;
    reconstruct the masked sample by qsampling and comparing to original
    set self.mask_prob and self.steps if needed

    Args:
      index (int): index of sample to take
      return_dict ([type]): [description]
      sample ([type], optional): [description]. Defaults to None.
      index ([type], optional): [description]. Defaults to None.

    Raises:
      ValueError: [description]
      ValueError: [description]

    Returns:
      [type]: [description]
    &#34;&#34;&#34;
    if all(x is None for x in [sample, index]):
        raise ValueError(&#34;Must input either sample or index!&#34;)
    elif all(x is not None for x in [sample, index]):
        raise ValueError(&#34;Must input either sample or index not both!&#34;)
    elif sample is not None:
        s=pd.DataFrame(sample).fillna(&#39;&#39;).values.astype(str)[:]
    elif index is not None:
        s=self.samples_as_strings[index]
        
    s1,bp,mask_,maskindex,rmatch_u,rmatch,s_rand=self.getMaskedSample(s, 
                                                                      mask_prob=self.mask_prob)
    if np.isnan(bp).any():
        return_dict[index] = np.nan,np.nan,np.nan
        return np.nan,np.nan,np.nan

    qs=qsample(s1,self.qnet,self.steps,bp)

    dqestim=qdistance(s,qs,self.qnet,self.qnet)
    dactual=qdistance(s,s1,self.qnet,self.qnet)
    qdistance_time_end = time.time()

    return_dict[index] = (1 - (dqestim/dactual))*100,rmatch_u,rmatch
    return (1 - (dqestim/dactual))*100,rmatch_u,rmatch</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.set_immutable_vars"><code class="name flex">
<span>def <span class="ident">set_immutable_vars</span></span>(<span>self, IMMUTABLE_FILE)</span>
</code></dt>
<dd>
<div class="desc"><p>set vars to immutable and mutable,
can prob combine this with the load_data func: only set the immutable vars if necessary</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>IMMUTABLE_FILE</code></strong> :&ensp;<code>str</code></dt>
<dd>file containing the immutable features/vars</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_immutable_vars(self,
                       IMMUTABLE_FILE):
    &#39;&#39;&#39;
    set vars to immutable and mutable, 
    can prob combine this with the load_data func: only set the immutable vars if necessary

    Args:
      IMMUTABLE_FILE (str): file containing the immutable features/vars
    &#39;&#39;&#39;
    if self.cols is None:
        raise ValueError(&#34;load_data first!&#34;)
    self.immutable_vars = pd.read_csv(IMMUTABLE_FILE,index_col=0).transpose()
    self.mutable_vars = None
    self.mutable_vars = [x for x in self.cols
                         if x.upper() not in self.immutable_vars.columns]</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.set_nsamples"><code class="name flex">
<span>def <span class="ident">set_nsamples</span></span>(<span>self, num_samples)</span>
</code></dt>
<dd>
<div class="desc"><p>select a subset of the samples</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>num_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>Set num of samples to subset</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_nsamples(self,
                 num_samples):
    &#39;&#39;&#39;
    select a subset of the samples

    Args:
      num_samples (int): Set num of samples to subset
    &#39;&#39;&#39;
    
    if all(x is not None for x in [num_samples, self.samples]):
        if num_samples &gt; len(self.samples.index):
            string = &#39;The number of selected samples ({}) &#39; + \
                 &#39;is greater than the number of samples ({})!&#39;
            string = string.format(num_samples, len(self.samples.index))
            raise ValueError(string)

        if num_samples == len(self.samples.index):
            string = &#39;The number of selected samples ({}) &#39; + \
                 &#39;is equal the number of samples ({})!&#39;
            string = string.format(num_samples, len(self.samples.index))
            print(string)
        #self.samples = self.samples.sample(num_samples)
        self.samples = self.samples[:10]
        self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]

    elif self.samples is None:
        raise ValueError(&#34;load_data first!&#34;)</code></pre>
</details>
</dd>
<dt id="cognet.cognet.cognet.set_poles"><code class="name flex">
<span>def <span class="ident">set_poles</span></span>(<span>self, POLEFILE, steps=0, mutable=False)</span>
</code></dt>
<dd>
<div class="desc"><p>set the poles and samples such that the samples contain features in poles</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>steps</code></strong> :&ensp;<code>int</code></dt>
<dd>number of steps to qsample</dd>
<dt><strong><code>POLEFILE</code></strong> :&ensp;<code>str</code></dt>
<dd>file containing poles samples and features</dd>
<dt><strong><code>mutable</code></strong> :&ensp;<code>boolean</code></dt>
<dd>Whether or not to set poles as the only mutable_vars</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_poles(self,
              POLEFILE,
              steps=0,
              mutable=False):
    &#39;&#39;&#39;
    set the poles and samples such that the samples contain features in poles


    Args:
      steps (int): number of steps to qsample
      POLEFILE (str): file containing poles samples and features
      mutable (boolean): Whether or not to set poles as the only mutable_vars
    &#39;&#39;&#39;
    invalid_count = 0
    if all(x is not None for x in [self.samples]):
        poles = pd.read_csv(POLEFILE, index_col=0)
        L=poles.L.to_dict()
        R=poles.R.to_dict()
        self.poles=poles.transpose()

        cols = [x for x in self.poles.columns if x in self.samples.columns]
        self.samples=self.samples[cols]
    
        for x in self.poles.columns:
            if x not in self.samples.columns:
                invalid_count += 1
                self.samples[x]=np.nan

        self.samples = pd.concat([self.samples,self.features], axis=0)
        self.samples_as_strings = self.samples[self.cols].fillna(&#39;&#39;).values.astype(str)[:]

        self.polar_features = pd.concat([self.poles, self.features], axis=0)
        pL= self.polar_features.loc[&#39;L&#39;][self.cols].fillna(&#39;&#39;).values.astype(str)[:]
        pR= self.polar_features.loc[&#39;R&#39;][self.cols].fillna(&#39;&#39;).values.astype(str)[:]

        self.pL=self.qsampling(pL,steps)
        self.pR=self.qsampling(pR,steps)
        if mutable:
            self.mutable_vars=[x for x in self.cols if x in self.poles.columns]
    elif self.samples is None:
        raise ValueError(&#34;load_data first!&#34;)
    
    print(&#34;{} pole features not found in sample features&#34;.format(invalid_count))</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<img src="logozed_nowhite.png" alt="drawing" style="width:400px;"/>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cognet" href="index.html">cognet</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="cognet.cognet.cognet" href="#cognet.cognet.cognet">cognet</a></code></h4>
<ul class="">
<li><code><a title="cognet.cognet.cognet.compute_DLI_sample" href="#cognet.cognet.cognet.compute_DLI_sample">compute_DLI_sample</a></code></li>
<li><code><a title="cognet.cognet.cognet.compute_DLI_samples" href="#cognet.cognet.cognet.compute_DLI_samples">compute_DLI_samples</a></code></li>
<li><code><a title="cognet.cognet.cognet.compute_polar_indices" href="#cognet.cognet.cognet.compute_polar_indices">compute_polar_indices</a></code></li>
<li><code><a title="cognet.cognet.cognet.dissonance" href="#cognet.cognet.cognet.dissonance">dissonance</a></code></li>
<li><code><a title="cognet.cognet.cognet.dissonance_matrix" href="#cognet.cognet.cognet.dissonance_matrix">dissonance_matrix</a></code></li>
<li><code><a title="cognet.cognet.cognet.distance" href="#cognet.cognet.cognet.distance">distance</a></code></li>
<li><code><a title="cognet.cognet.cognet.distfunc_line" href="#cognet.cognet.cognet.distfunc_line">distfunc_line</a></code></li>
<li><code><a title="cognet.cognet.cognet.embed" href="#cognet.cognet.cognet.embed">embed</a></code></li>
<li><code><a title="cognet.cognet.cognet.getBaseFrequency" href="#cognet.cognet.cognet.getBaseFrequency">getBaseFrequency</a></code></li>
<li><code><a title="cognet.cognet.cognet.getMaskedSample" href="#cognet.cognet.cognet.getMaskedSample">getMaskedSample</a></code></li>
<li><code><a title="cognet.cognet.cognet.load_data" href="#cognet.cognet.cognet.load_data">load_data</a></code></li>
<li><code><a title="cognet.cognet.cognet.load_from_model" href="#cognet.cognet.cognet.load_from_model">load_from_model</a></code></li>
<li><code><a title="cognet.cognet.cognet.polarDistance" href="#cognet.cognet.cognet.polarDistance">polarDistance</a></code></li>
<li><code><a title="cognet.cognet.cognet.polar_separation" href="#cognet.cognet.cognet.polar_separation">polar_separation</a></code></li>
<li><code><a title="cognet.cognet.cognet.predict_maskedsamples" href="#cognet.cognet.cognet.predict_maskedsamples">predict_maskedsamples</a></code></li>
<li><code><a title="cognet.cognet.cognet.qsampling" href="#cognet.cognet.cognet.qsampling">qsampling</a></code></li>
<li><code><a title="cognet.cognet.cognet.randomMaskReconstruction" href="#cognet.cognet.cognet.randomMaskReconstruction">randomMaskReconstruction</a></code></li>
<li><code><a title="cognet.cognet.cognet.set_immutable_vars" href="#cognet.cognet.cognet.set_immutable_vars">set_immutable_vars</a></code></li>
<li><code><a title="cognet.cognet.cognet.set_nsamples" href="#cognet.cognet.cognet.set_nsamples">set_nsamples</a></code></li>
<li><code><a title="cognet.cognet.cognet.set_poles" href="#cognet.cognet.cognet.set_poles">set_poles</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
Author: Lynn Zheng, Jin Li and Ishanu Chattopadhyay <a href="https://zed.uchicago.edu"> Zero Knowledge Discovery, University of Chicago</a>. Email: ishanu@uchicago.edu
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>